# Implement step 1 of research proposal
_Exported on 11/09/2025 at 18:33:33 BST from Cursor (1.4.5)_

---

**User**

You are a language model, working as part of a team to implement a research proposal. Please take the time to read the ResearchPlan.md.

You have been tasked with implementing 'step 1' of the plan. Please go ahead and get started.

---

**Cursor**

I'll start by organizing and scaffolding Step 1: create the environment module, a shared core for movement, a BFS solver, and unit tests, plus minimal dependencies. Then I'll implement the Gymnasium-compatible `RicochetRobotsEnv`, the solver, and tests using a deterministic fixed layout to validate movement and goal conditions.

I'll create the project scaffolding and implement the core movement utilities, the Gymnasium-compatible environment, a BFS solver, and unit tests. Then I'll run a quick lint check to ensure no obvious issues.

```pip-requirements
*** Begin Patch
*** Add File: requirements.txt
numpy>=1.26
gymnasium>=0.29
pytest>=8.0
*** End Patch
```

Creating initial scaffolding and core implementation for Step 1 now: dependencies, utilities, environment, solver, and tests.

```pip-requirements
*** Begin Patch
*** Add File: requirements.txt
numpy>=1.26
gymnasium>=0.29
pytest>=8.0
*** End Patch
```

I'll create the initial files for Step 1: core movement, environment, and scaffolding. Then I'll update the TODOs and proceed to add the solver and tests.

```pip-requirements
numpy>=1.26
gymnasium>=0.29
pytest>=8.0
```

```python
# Package for Ricochet Robots environment
```

```python
from __future__ import annotations

from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple

import numpy as np

# Directions encoded as (dr, dc)
DIRECTIONS: List[Tuple[int, int]] = [
    (-1, 0),  # up
    (1, 0),   # down
    (0, -1),  # left
    (0, 1),   # right
]

UP, DOWN, LEFT, RIGHT = 0, 1, 2, 3


@dataclass
class Board:
    height: int
    width: int
    # walls[r, c] == True if cell is a wall/blocked
    walls: np.ndarray  # shape (H, W), dtype=bool
    # robots indexed 0..N-1
    robot_positions: Dict[int, Tuple[int, int]]
    # goal location and which robot is the target
    goal_position: Tuple[int, int]
    target_robot: int

    def __post_init__(self) -> None:
        assert self.walls.shape == (self.height, self.width)
        for robot_id, (r, c) in self.robot_positions.items():
            assert 0 <= r < self.height and 0 <= c < self.width, "Robot out of bounds"
            assert not self.walls[r, c], "Robot cannot occupy a wall cell"
        gr, gc = self.goal_position
        assert 0 <= gr < self.height and 0 <= gc < self.width, "Goal out of bounds"

    @property
    def num_robots(self) -> int:
        return len(self.robot_positions)

    def is_occupied(self, row: int, col: int, ignore_robot: Optional[int] = None) -> bool:
        if self.walls[row, col]:
            return True
        for rid, (rr, cc) in self.robot_positions.items():
            if ignore_robot is not None and rid == ignore_robot:
                continue
            if rr == row and cc == col:
                return True
        return False

    def clone(self) -> "Board":
        return Board(
            height=self.height,
            width=self.width,
            walls=self.walls.copy(),
            robot_positions=dict(self.robot_positions),
            goal_position=tuple(self.goal_position),
            target_robot=self.target_robot,
        )


def slide_until_blocked(board: Board, robot_id: int, direction: int) -> Tuple[int, int]:
    """
    Slide the specified robot in the given direction until hitting a wall, edge, or another robot.
    Returns the final (row, col) position after sliding.
    """
    assert 0 <= direction < 4
    start_r, start_c = board.robot_positions[robot_id]
    dr, dc = DIRECTIONS[direction]

    r, c = start_r, start_c
    # Precompute occupied positions excluding the moving robot
    occupied = np.zeros((board.height, board.width), dtype=bool)
    occupied |= board.walls
    for rid, (rr, cc) in board.robot_positions.items():
        if rid == robot_id:
            continue
        occupied[rr, cc] = True

    # Move step by step until next cell would be blocked or out of bounds
    while True:
        nr, nc = r + dr, c + dc
        if nr < 0 or nr >= board.height or nc < 0 or nc >= board.width:
            break
        if occupied[nr, nc]:
            break
        r, c = nr, nc

    return r, c


def apply_action(board: Board, robot_id: int, direction: int) -> Board:
    """Return a new Board after applying the action. If no movement occurs, board is unchanged."""
    new_board = board.clone()
    end_r, end_c = slide_until_blocked(new_board, robot_id, direction)
    new_board.robot_positions[robot_id] = (end_r, end_c)
    return new_board


def reached_goal(board: Board) -> bool:
    r, c = board.robot_positions[board.target_robot]
    return (r, c) == board.goal_position


def render_ascii(board: Board) -> str:
    canvas = np.full((board.height, board.width), fill_value='.', dtype=object)
    canvas[board.walls] = '#'
    gr, gc = board.goal_position
    canvas[gr, gc] = 'G' if canvas[gr, gc] == '.' else 'X'
    for rid, (r, c) in board.robot_positions.items():
        label = chr(ord('A') + rid)
        canvas[r, c] = label if canvas[r, c] == '.' else '*'
    lines = [''.join(str(x) for x in row) for row in canvas]
    return '\n'.join(lines)
```

---

**User**

Please keep going

---

**Cursor**

I'll implement the Gymnasium-compatible environment, a BFS solver using the shared movement logic, and unit tests. Then I'll mark the core utilities task complete and set the environment task to in progress, followed by a quick lint check.

I implemented core utilities. Now I'll add the Gymnasium environment, the BFS solver, and unit tests in parallel.

```python
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple, List

import gymnasium as gym
import numpy as np
from gymnasium import spaces

from .ricochet_core import Board, apply_action, reached_goal, render_ascii, UP, DOWN, LEFT, RIGHT


@dataclass
class FixedLayout:
    height: int
    width: int
    walls: np.ndarray  # (H,W) bool
    robot_positions: Dict[int, Tuple[int, int]]
    goal_position: Tuple[int, int]
    target_robot: int


class RicochetRobotsEnv(gym.Env):
    metadata = {"render_modes": ["ascii"], "render_fps": 4}

    def __init__(
        self,
        height: int = 8,
        width: int = 8,
        num_robots: int = 2,
        include_noop: bool = True,
        step_penalty: float = -0.01,
        goal_reward: float = 1.0,
        max_steps: int = 100,
        fixed_layout: Optional[FixedLayout] = None,
        seed: Optional[int] = None,
        ensure_solvable: bool = False,
        solver_max_depth: int = 30,
        solver_max_nodes: int = 20000,
    ) -> None:
        super().__init__()
        self.height = height
        self.width = width
        self.num_robots = num_robots
        self.include_noop = include_noop
        self.step_penalty = step_penalty
        self.goal_reward = goal_reward
        self.max_steps = max_steps
        self.fixed_layout = fixed_layout
        self.ensure_solvable = ensure_solvable
        self.solver_max_depth = solver_max_depth
        self.solver_max_nodes = solver_max_nodes

        self._rng = np.random.RandomState(seed)
        self._board: Optional[Board] = None
        self._num_steps = 0

        # Observation: channels = 1 (walls) + 1 (goal) + num_robots (one-hot per robot)
        self._num_channels = 2 + self.num_robots
        self.observation_space = spaces.Box(
            low=0.0,
            high=1.0,
            shape=(self.height, self.width, self._num_channels),
            dtype=np.float32,
        )

        # Action space: num_robots * 4 directions (+ 1 for noop)
        self._noop_action = self.num_robots * 4 if include_noop else None
        self.action_space = spaces.Discrete(self.num_robots * 4 + (1 if include_noop else 0))

    # Gymnasium API
    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):
        if seed is not None:
            self._rng.seed(seed)
        self._num_steps = 0

        if self.fixed_layout is not None:
            self._board = Board(
                height=self.fixed_layout.height,
                width=self.fixed_layout.width,
                walls=self.fixed_layout.walls.copy(),
                robot_positions=dict(self.fixed_layout.robot_positions),
                goal_position=self.fixed_layout.goal_position,
                target_robot=self.fixed_layout.target_robot,
            )
            obs = self._board_to_obs(self._board)
            return obs, {}

        # Otherwise, generate random board, optionally ensure solvable via solver
        attempts = 0
        while True:
            attempts += 1
            board = self._generate_random_board()
            if not self.ensure_solvable:
                self._board = board
                break
            try:
                # Lazy import to avoid circular dependency
                from .solver import solve_bfs
                solution = solve_bfs(board, max_depth=self.solver_max_depth, max_nodes=self.solver_max_nodes)
                if solution is not None:
                    self._board = board
                    break
            except Exception:
                # If solver not available, proceed without guaranteeing solvability
                self._board = board
                break
            if attempts >= 20:
                self._board = board
                break

        obs = self._board_to_obs(self._board)
        return obs, {}

    def step(self, action: int):
        assert self._board is not None, "Call reset() first"
        self._num_steps += 1

        reward = self.step_penalty
        terminated = False
        truncated = False
        info = {}

        if self.include_noop and action == self._noop_action:
            # no state change
            pass
        else:
            robot_id, direction = self._decode_action(action)
            self._board = apply_action(self._board, robot_id, direction)

        if reached_goal(self._board):
            reward += self.goal_reward
            terminated = True
            info["success"] = True

        if self._num_steps >= self.max_steps:
            truncated = True

        obs = self._board_to_obs(self._board)
        return obs, reward, terminated, truncated, info

    def render(self):
        if self._board is None:
            return ""
        return render_ascii(self._board)

    # Helpers
    def _decode_action(self, action: int) -> Tuple[int, int]:
        assert 0 <= action < self.action_space.n
        robot_id = action // 4
        direction = action % 4
        if robot_id >= self.num_robots:
            # Should only happen if action is noop and include_noop=True
            robot_id = 0
            direction = UP
        return robot_id, direction

    def _board_to_obs(self, board: Board) -> np.ndarray:
        h, w = board.height, board.width
        obs = np.zeros((h, w, self._num_channels), dtype=np.float32)
        # walls channel 0
        obs[:, :, 0] = board.walls.astype(np.float32)
        # goal channel 1
        gr, gc = board.goal_position
        obs[gr, gc, 1] = 1.0
        # robot channels
        for rid, (r, c) in board.robot_positions.items():
            obs[r, c, 2 + rid] = 1.0
        return obs

    def _generate_random_board(self) -> Board:
        h, w = self.height, self.width
        walls = np.zeros((h, w), dtype=bool)
        # Add random perimeter walls disabled; keep simple open grid, occasional internal walls
        num_internal_walls = self._rng.randint(0, max(1, (h * w) // 10))
        for _ in range(num_internal_walls):
            r = self._rng.randint(0, h)
            c = self._rng.randint(0, w)
            walls[r, c] = True
        # Ensure at least one free cell for goal and robots
        free_cells: List[Tuple[int, int]] = [(r, c) for r in range(h) for c in range(w) if not walls[r, c]]
        self._rng.shuffle(free_cells)
        assert len(free_cells) >= self.num_robots + 1, "Not enough free cells"
        goal = free_cells.pop()
        robot_positions: Dict[int, Tuple[int, int]] = {}
        for rid in range(self.num_robots):
            robot_positions[rid] = free_cells.pop()
        target_robot = self._rng.randint(0, self.num_robots)
        board = Board(height=h, width=w, walls=walls, robot_positions=robot_positions, goal_position=goal, target_robot=target_robot)
        # Avoid placing goal on a robot by chance (already avoided), but ensure distinct
        return board
```

```python
from __future__ import annotations

from collections import deque
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple

from .ricochet_core import Board, apply_action, reached_goal, UP, DOWN, LEFT, RIGHT

Action = Tuple[int, int]  # (robot_id, direction)


def serialize(board: Board) -> Tuple[Tuple[Tuple[int, int], ...]]:
    # Serialize only robot positions; walls and goal considered constant per instance
    order = tuple(board.robot_positions[rid] for rid in sorted(board.robot_positions.keys()))
    return (order,)


@dataclass
class SolveResult:
    actions: List[Action]


def neighbors(board: Board) -> List[Tuple[Board, Action]]:
    results: List[Tuple[Board, Action]] = []
    for rid in board.robot_positions.keys():
        for d in (UP, DOWN, LEFT, RIGHT):
            next_board = apply_action(board, rid, d)
            if next_board.robot_positions[rid] != board.robot_positions[rid]:
                results.append((next_board, (rid, d)))
    return results


def solve_bfs(
    start: Board,
    max_depth: int = 30,
    max_nodes: int = 20000,
) -> Optional[List[Action]]:
    """Find a sequence of actions to reach the goal using BFS up to limits."""
    if reached_goal(start):
        return []

    start_key = serialize(start)
    visited = {start_key}
    queue = deque()
    queue.append((start, []))
    nodes_expanded = 0

    while queue:
        board, path = queue.popleft()
        if len(path) >= max_depth:
            continue
        for nb, act in neighbors(board):
            nodes_expanded += 1
            if nodes_expanded > max_nodes:
                return None
            key = serialize(nb)
            if key in visited:
                continue
            new_path = path + [act]
            if reached_goal(nb):
                return new_path
            visited.add(key)
            queue.append((nb, new_path))
    return None
```

```python
import numpy as np

from env.ricochet_core import Board, UP, DOWN, LEFT, RIGHT, render_ascii
from env.ricochet_env import RicochetRobotsEnv, FixedLayout


def make_simple_layout():
    H, W = 5, 5
    walls = np.zeros((H, W), dtype=bool)
    # Add a wall at (1,2)
    walls[1, 2] = True
    robots = {0: (3, 2)}
    goal = (0, 2)
    target_robot = 0
    return FixedLayout(height=H, width=W, walls=walls, robot_positions=robots, goal_position=goal, target_robot=target_robot)


def test_slide_and_stop():
    layout = make_simple_layout()
    env = RicochetRobotsEnv(fixed_layout=layout, include_noop=False, step_penalty=0.0)
    obs, info = env.reset()
    # Move up: robot at (3,2) should stop at (2,2) due to wall at (1,2)
    # action encoding: rid*4 + dir
    action_up = 0 * 4 + UP
    obs, reward, terminated, truncated, info = env.step(action_up)
    # Next, move up again: should stop at (2,2) because wall still blocks
    obs, reward, terminated, truncated, info = env.step(action_up)
    # Now move right until edge: from (2,2) to (2,4)
    action_right = 0 * 4 + RIGHT
    obs, reward, terminated, truncated, info = env.step(action_right)
    # Move left to (2,0)
    action_left = 0 * 4 + LEFT
    obs, reward, terminated, truncated, info = env.step(action_left)
    # Move up to goal at (0,0)? No, goal is (0,2); ensure not terminated yet
    assert not terminated


def test_goal_termination_and_reward():
    layout = make_simple_layout()
    env = RicochetRobotsEnv(fixed_layout=layout, include_noop=False, step_penalty=-0.01, goal_reward=1.0)
    obs, info = env.reset()
    # Move up to (2,2)
    obs, r1, term, trunc, info = env.step(0 * 4 + UP)
    # Move up to (2,2) again (blocked): no change, still not at goal
    obs, r2, term, trunc, info = env.step(0 * 4 + UP)
    # Move up is still blocked; go down to (3,2)
    obs, r3, term, trunc, info = env.step(0 * 4 + DOWN)
    # Move up blocked path doesn't reach goal; instead go left to (3,0), then up to (0,0), then right to (0,2)
    obs, r4, term, trunc, info = env.step(0 * 4 + LEFT)
    obs, r5, term, trunc, info = env.step(0 * 4 + UP)
    obs, r6, term, trunc, info = env.step(0 * 4 + RIGHT)
    assert term
    assert info.get("success", False)
    # Sum of rewards should include step penalties and final goal reward
    total_reward = r1 + r2 + r3 + r4 + r5 + r6
    assert total_reward > 0.9  # near 1.0 minus small penalties
```

```python
import numpy as np

from env.ricochet_core import Board, apply_action, reached_goal, UP, DOWN, LEFT, RIGHT
from env.solver import solve_bfs


def test_bfs_finds_solution_on_simple_board():
    H, W = 5, 5
    walls = np.zeros((H, W), dtype=bool)
    # Place a single wall above the robot to force pathing
    walls[1, 2] = True
    robots = {0: (3, 2)}
    goal = (0, 2)
    board = Board(height=H, width=W, walls=walls, robot_positions=robots, goal_position=goal, target_robot=0)

    actions = solve_bfs(board, max_depth=20, max_nodes=10000)
    assert actions is not None

    # Apply actions and verify goal reached
    cur = board
    for rid, d in actions:
        cur = apply_action(cur, rid, d)
    assert reached_goal(cur)
```

I'll fix linter errors: replace RandomState with numpy Generator, adjust RNG calls, narrow exception handling, add type ignores for optional imports, and remove unused imports/variables in tests. Then I'll add a minimal README scaffold and mark the scaffolding todo done.

```python
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple, List

import gymnasium as gym  # type: ignore
import numpy as np
from gymnasium import spaces  # type: ignore

from .ricochet_core import Board, apply_action, reached_goal, render_ascii, UP, DOWN, LEFT, RIGHT


@dataclass
class FixedLayout:
    height: int
    width: int
    walls: np.ndarray  # (H,W) bool
    robot_positions: Dict[int, Tuple[int, int]]
    goal_position: Tuple[int, int]
    target_robot: int


class RicochetRobotsEnv(gym.Env):
    metadata = {"render_modes": ["ascii"], "render_fps": 4}

    def __init__(
        self,
        height: int = 8,
        width: int = 8,
        num_robots: int = 2,
        include_noop: bool = True,
        step_penalty: float = -0.01,
        goal_reward: float = 1.0,
        max_steps: int = 100,
        fixed_layout: Optional[FixedLayout] = None,
        seed: Optional[int] = None,
        ensure_solvable: bool = False,
        solver_max_depth: int = 30,
        solver_max_nodes: int = 20000,
    ) -> None:
        super().__init__()
        self.height = height
        self.width = width
        self.num_robots = num_robots
        self.include_noop = include_noop
        self.step_penalty = step_penalty
        self.goal_reward = goal_reward
        self.max_steps = max_steps
        self.fixed_layout = fixed_layout
        self.ensure_solvable = ensure_solvable
        self.solver_max_depth = solver_max_depth
        self.solver_max_nodes = solver_max_nodes

        self._rng: np.random.Generator = np.random.default_rng(seed)
        self._board: Optional[Board] = None
        self._num_steps = 0

        # Observation: channels = 1 (walls) + 1 (goal) + num_robots (one-hot per robot)
        self._num_channels = 2 + self.num_robots
        self.observation_space = spaces.Box(
            low=0.0,
            high=1.0,
            shape=(self.height, self.width, self._num_channels),
            dtype=np.float32,
        )

        # Action space: num_robots * 4 directions (+ 1 for noop)
        self._noop_action = self.num_robots * 4 if include_noop else None
        self.action_space = spaces.Discrete(self.num_robots * 4 + (1 if include_noop else 0))

    # Gymnasium API
    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):
        if seed is not None:
            self._rng = np.random.default_rng(seed)
        self._num_steps = 0

        if self.fixed_layout is not None:
            self._board = Board(
                height=self.fixed_layout.height,
                width=self.fixed_layout.width,
                walls=self.fixed_layout.walls.copy(),
                robot_positions=dict(self.fixed_layout.robot_positions),
                goal_position=self.fixed_layout.goal_position,
                target_robot=self.fixed_layout.target_robot,
            )
            obs = self._board_to_obs(self._board)
            return obs, {}

        # Otherwise, generate random board, optionally ensure solvable via solver
        attempts = 0
        while True:
            attempts += 1
            board = self._generate_random_board()
            if not self.ensure_solvable:
                self._board = board
                break
            try:
                # Lazy import to avoid circular dependency
                from .solver import solve_bfs  # type: ignore
                solution = solve_bfs(board, max_depth=self.solver_max_depth, max_nodes=self.solver_max_nodes)
                if solution is not None:
                    self._board = board
                    break
            except ImportError:
                # If solver not available, proceed without guaranteeing solvability
                self._board = board
                break
            if attempts >= 20:
                self._board = board
                break

        obs = self._board_to_obs(self._board)
        return obs, {}

    def step(self, action: int):
        assert self._board is not None, "Call reset() first"
        self._num_steps += 1

        reward = self.step_penalty
        terminated = False
        truncated = False
        info = {}

        if self.include_noop and action == self._noop_action:
            # no state change
            pass
        else:
            robot_id, direction = self._decode_action(action)
            self._board = apply_action(self._board, robot_id, direction)

        if reached_goal(self._board):
            reward += self.goal_reward
            terminated = True
            info["success"] = True

        if self._num_steps >= self.max_steps:
            truncated = True

        obs = self._board_to_obs(self._board)
        return obs, reward, terminated, truncated, info

    def render(self):
        if self._board is None:
            return ""
        return render_ascii(self._board)

    # Helpers
    def _decode_action(self, action: int) -> Tuple[int, int]:
        assert 0 <= action < self.action_space.n
        robot_id = action // 4
        direction = action % 4
        if robot_id >= self.num_robots:
            # Should only happen if action is noop and include_noop=True
            robot_id = 0
            direction = UP
        return robot_id, direction

    def _board_to_obs(self, board: Board) -> np.ndarray:
        h, w = board.height, board.width
        obs = np.zeros((h, w, self._num_channels), dtype=np.float32)
        # walls channel 0
        obs[:, :, 0] = board.walls.astype(np.float32)
        # goal channel 1
        gr, gc = board.goal_position
        obs[gr, gc, 1] = 1.0
        # robot channels
        for rid, (r, c) in board.robot_positions.items():
            obs[r, c, 2 + rid] = 1.0
        return obs

    def _generate_random_board(self) -> Board:
        h, w = self.height, self.width
        walls = np.zeros((h, w), dtype=bool)
        # Simple random internal walls
        max_internal = max(1, (h * w) // 10)
        num_internal_walls = int(self._rng.integers(0, max_internal))
        for _ in range(num_internal_walls):
            r = int(self._rng.integers(0, h))
            c = int(self._rng.integers(0, w))
            walls[r, c] = True
        # Ensure free cells for goal and robots
        free_cells: List[Tuple[int, int]] = [(r, c) for r in range(h) for c in range(w) if not walls[r, c]]
        self._rng.shuffle(free_cells)
        assert len(free_cells) >= self.num_robots + 1, "Not enough free cells"
        goal = free_cells.pop()
        robot_positions: Dict[int, Tuple[int, int]] = {}
        for rid in range(self.num_robots):
            robot_positions[rid] = free_cells.pop()
        target_robot = int(self._rng.integers(0, self.num_robots))
        board = Board(height=h, width=w, walls=walls, robot_positions=robot_positions, goal_position=goal, target_robot=target_robot)
        return board

```

```python
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple, List

import numpy as np

# Directions encoded as (dr, dc)
DIRECTIONS: List[Tuple[int, int]] = [
    (-1, 0),  # up
    (1, 0),   # down
    (0, -1),  # left
    (0, 1),   # right
]

UP, DOWN, LEFT, RIGHT = 0, 1, 2, 3


@dataclass
class Board:
    height: int
    width: int
    # walls[r, c] == True if cell is a wall/blocked
    walls: np.ndarray  # shape (H, W), dtype=bool
    # robots indexed 0..N-1
    robot_positions: Dict[int, Tuple[int, int]]
    # goal location and which robot is the target
    goal_position: Tuple[int, int]
    target_robot: int

    def __post_init__(self) -> None:
        assert self.walls.shape == (self.height, self.width)
        for _, (r, c) in self.robot_positions.items():
            assert 0 <= r < self.height and 0 <= c < self.width, "Robot out of bounds"
            assert not self.walls[r, c], "Robot cannot occupy a wall cell"
        gr, gc = self.goal_position
        assert 0 <= gr < self.height and 0 <= gc < self.width, "Goal out of bounds"

    @property
    def num_robots(self) -> int:
        return len(self.robot_positions)

    def is_occupied(self, row: int, col: int, ignore_robot: Optional[int] = None) -> bool:
        if self.walls[row, col]:
            return True
        for rid, (rr, cc) in self.robot_positions.items():
            if ignore_robot is not None and rid == ignore_robot:
                continue
            if rr == row and cc == col:
                return True
        return False

    def clone(self) -> "Board":
        return Board(
            height=self.height,
            width=self.width,
            walls=self.walls.copy(),
            robot_positions=dict(self.robot_positions),
            goal_position=tuple(self.goal_position),
            target_robot=self.target_robot,
        )


def slide_until_blocked(board: Board, robot_id: int, direction: int) -> Tuple[int, int]:
    """
    Slide the specified robot in the given direction until hitting a wall, edge, or another robot.
    Returns the final (row, col) position after sliding.
    """
    assert 0 <= direction < 4
    start_r, start_c = board.robot_positions[robot_id]
    dr, dc = DIRECTIONS[direction]

    r, c = start_r, start_c
    # Precompute occupied positions excluding the moving robot
    occupied = np.zeros((board.height, board.width), dtype=bool)
    occupied |= board.walls
    for rid, (rr, cc) in board.robot_positions.items():
        if rid == robot_id:
            continue
        occupied[rr, cc] = True

    # Move step by step until next cell would be blocked or out of bounds
    while True:
        nr, nc = r + dr, c + dc
        if nr < 0 or nr >= board.height or nc < 0 or nc >= board.width:
            break
        if occupied[nr, nc]:
            break
        r, c = nr, nc

    return r, c


def apply_action(board: Board, robot_id: int, direction: int) -> Board:
    """Return a new Board after applying the action. If no movement occurs, board is unchanged."""
    new_board = board.clone()
    end_r, end_c = slide_until_blocked(new_board, robot_id, direction)
    new_board.robot_positions[robot_id] = (end_r, end_c)
    return new_board


def reached_goal(board: Board) -> bool:
    r, c = board.robot_positions[board.target_robot]
    return (r, c) == board.goal_position


def render_ascii(board: Board) -> str:
    canvas = np.full((board.height, board.width), fill_value='.', dtype=object)
    canvas[board.walls] = '#'
    gr, gc = board.goal_position
    canvas[gr, gc] = 'G' if canvas[gr, gc] == '.' else 'X'
    for rid, (r, c) in board.robot_positions.items():
        label = chr(ord('A') + rid)
        canvas[r, c] = label if canvas[r, c] == '.' else '*'
    lines = [''.join(str(x) for x in row) for row in canvas]
    return '\n'.join(lines)

```

```python
from __future__ import annotations

from collections import deque
from dataclasses import dataclass
from typing import List, Optional, Tuple

from .ricochet_core import Board, apply_action, reached_goal, UP, DOWN, LEFT, RIGHT

Action = Tuple[int, int]  # (robot_id, direction)


def serialize(board: Board) -> Tuple[Tuple[Tuple[int, int], ...]]:
    # Serialize only robot positions; walls and goal considered constant per instance
    order = tuple(board.robot_positions[rid] for rid in sorted(board.robot_positions.keys()))
    return (order,)


@dataclass
class SolveResult:
    actions: List[Action]


def neighbors(board: Board) -> List[Tuple[Board, Action]]:
    results: List[Tuple[Board, Action]] = []
    for rid in board.robot_positions.keys():
        for d in (UP, DOWN, LEFT, RIGHT):
            next_board = apply_action(board, rid, d)
            if next_board.robot_positions[rid] != board.robot_positions[rid]:
                results.append((next_board, (rid, d)))
    return results


def solve_bfs(
    start: Board,
    max_depth: int = 30,
    max_nodes: int = 20000,
) -> Optional[List[Action]]:
    """Find a sequence of actions to reach the goal using BFS up to limits."""
    if reached_goal(start):
        return []

    start_key = serialize(start)
    visited = {start_key}
    queue = deque()
    queue.append((start, []))
    nodes_expanded = 0

    while queue:
        board, path = queue.popleft()
        if len(path) >= max_depth:
            continue
        for nb, act in neighbors(board):
            nodes_expanded += 1
            if nodes_expanded > max_nodes:
                return None
            key = serialize(nb)
            if key in visited:
                continue
            new_path = path + [act]
            if reached_goal(nb):
                return new_path
            visited.add(key)
            queue.append((nb, new_path))
    return None

```

```python
import numpy as np

from env.ricochet_env import RicochetRobotsEnv, FixedLayout
from env.ricochet_core import UP, LEFT, RIGHT, DOWN


def make_simple_layout():
    H, W = 5, 5
    walls = np.zeros((H, W), dtype=bool)
    # Add a wall at (1,2)
    walls[1, 2] = True
    robots = {0: (3, 2)}
    goal = (0, 2)
    target_robot = 0
    return FixedLayout(height=H, width=W, walls=walls, robot_positions=robots, goal_position=goal, target_robot=target_robot)


def test_slide_and_stop():
    layout = make_simple_layout()
    env = RicochetRobotsEnv(fixed_layout=layout, include_noop=False, step_penalty=0.0)
    _, _ = env.reset()
    action_up = 0 * 4 + UP
    _, _, _, _, _ = env.step(action_up)
    _, _, _, _, _ = env.step(action_up)
    action_right = 0 * 4 + RIGHT
    _, _, _, _, _ = env.step(action_right)
    action_left = 0 * 4 + LEFT
    _, _, terminated, _, _ = env.step(action_left)
    assert not terminated


def test_goal_termination_and_reward():
    layout = make_simple_layout()
    env = RicochetRobotsEnv(fixed_layout=layout, include_noop=False, step_penalty=-0.01, goal_reward=1.0)
    _, _ = env.reset()
    _, r1, term, trunc, info = env.step(0 * 4 + UP)
    _, r2, term, trunc, info = env.step(0 * 4 + UP)
    _, r3, term, trunc, info = env.step(0 * 4 + DOWN)
    _, r4, term, trunc, info = env.step(0 * 4 + LEFT)
    _, r5, term, trunc, info = env.step(0 * 4 + UP)
    _, r6, term, trunc, info = env.step(0 * 4 + RIGHT)
    assert term
    assert info.get("success", False)
    total_reward = r1 + r2 + r3 + r4 + r5 + r6
    assert total_reward > 0.9

```

```python
import numpy as np

from env.ricochet_core import Board, apply_action, reached_goal
from env.solver import solve_bfs


def test_bfs_finds_solution_on_simple_board():
    H, W = 5, 5
    walls = np.zeros((H, W), dtype=bool)
    # Place a single wall above the robot to force pathing
    walls[1, 2] = True
    robots = {0: (3, 2)}
    goal = (0, 2)
    board = Board(height=H, width=W, walls=walls, robot_positions=robots, goal_position=goal, target_robot=0)

    actions = solve_bfs(board, max_depth=20, max_nodes=10000)
    assert actions is not None

    # Apply actions and verify goal reached
    cur = board
    for rid, d in actions:
        cur = apply_action(cur, rid, d)
    assert reached_goal(cur)

```

```markdown
# Ricochet Robots RL Environment (Step 1)

This repository contains a custom Gymnasium-compatible environment for the Ricochet Robots puzzle, a BFS solver for validation/curriculum, and unit tests.

## Setup

Install dependencies:

```bash
pip install -r requirements.txt
```

## Run Tests

```bash
pytest -q
```

## Usage Example

```python
from env.ricochet_env import RicochetRobotsEnv

env = RicochetRobotsEnv(height=8, width=8, num_robots=2)
obs, info = env.reset()
action = 0  # robot 0 up
obs, reward, terminated, truncated, info = env.step(action)
print(env.render())
```
```

```python
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple, List

try:
    import gymnasium as gym  # type: ignore
    from gymnasium import spaces  # type: ignore
except Exception:  # pragma: no cover
    class _Dummy:
        pass
    gym = _Dummy()  # type: ignore
    spaces = _Dummy()  # type: ignore
    gym.Env = object  # type: ignore

import numpy as np

from .ricochet_core import Board, apply_action, reached_goal, UP


@dataclass
class FixedLayout:
    height: int
    width: int
    walls: np.ndarray  # (H,W) bool
    robot_positions: Dict[int, Tuple[int, int]]
    goal_position: Tuple[int, int]
    target_robot: int


class RicochetRobotsEnv(gym.Env):
    metadata = {"render_modes": ["ascii"], "render_fps": 4}

    def __init__(
        self,
        height: int = 8,
        width: int = 8,
        num_robots: int = 2,
        include_noop: bool = True,
        step_penalty: float = -0.01,
        goal_reward: float = 1.0,
        max_steps: int = 100,
        fixed_layout: Optional[FixedLayout] = None,
        seed: Optional[int] = None,
        ensure_solvable: bool = False,
        solver_max_depth: int = 30,
        solver_max_nodes: int = 20000,
    ) -> None:
        super().__init__()
        self.height = height
        self.width = width
        self.num_robots = num_robots
        self.include_noop = include_noop
        self.step_penalty = step_penalty
        self.goal_reward = goal_reward
        self.max_steps = max_steps
        self.fixed_layout = fixed_layout
        self.ensure_solvable = ensure_solvable
        self.solver_max_depth = solver_max_depth
        self.solver_max_nodes = solver_max_nodes

        self._rng: np.random.Generator = np.random.default_rng(seed)
        self._board: Optional[Board] = None
        self._num_steps = 0

        # Observation: channels = 1 (walls) + 1 (goal) + num_robots (one-hot per robot)
        self._num_channels = 2 + self.num_robots
        self.observation_space = spaces.Box(
            low=0.0,
            high=1.0,
            shape=(self.height, self.width, self._num_channels),
            dtype=np.float32,
        )

        # Action space: num_robots * 4 directions (+ 1 for noop)
        self._noop_action = self.num_robots * 4 if include_noop else None
        self.action_space = spaces.Discrete(self.num_robots * 4 + (1 if include_noop else 0))

    # Gymnasium API
    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):
        if seed is not None:
            self._rng = np.random.default_rng(seed)
        self._num_steps = 0

        if self.fixed_layout is not None:
            self._board = Board(
                height=self.fixed_layout.height,
                width=self.fixed_layout.width,
                walls=self.fixed_layout.walls.copy(),
                robot_positions=dict(self.fixed_layout.robot_positions),
                goal_position=self.fixed_layout.goal_position,
                target_robot=self.fixed_layout.target_robot,
            )
            obs = self._board_to_obs(self._board)
            return obs, {}

        # Otherwise, generate random board, optionally ensure solvable via solver
        attempts = 0
        while True:
            attempts += 1
            board = self._generate_random_board()
            if not self.ensure_solvable:
                self._board = board
                break
            try:
                # Lazy import to avoid circular dependency
                from .solver import solve_bfs  # type: ignore
                solution = solve_bfs(board, max_depth=self.solver_max_depth, max_nodes=self.solver_max_nodes)
                if solution is not None:
                    self._board = board
                    break
            except ImportError:
                # If solver not available, proceed without guaranteeing solvability
                self._board = board
                break
            if attempts >= 20:
                self._board = board
                break

        obs = self._board_to_obs(self._board)
        return obs, {}

    def step(self, action: int):
        assert self._board is not None, "Call reset() first"
        self._num_steps += 1

        reward = self.step_penalty
        terminated = False
        truncated = False
        info = {}

        if self.include_noop and action == self._noop_action:
            # no state change
            pass
        else:
            robot_id, direction = self._decode_action(action)
            self._board = apply_action(self._board, robot_id, direction)

        if reached_goal(self._board):
            reward += self.goal_reward
            terminated = True
            info["success"] = True

        if self._num_steps >= self.max_steps:
            truncated = True

        obs = self._board_to_obs(self._board)
        return obs, reward, terminated, truncated, info

    def render(self):
        if self._board is None:
            return ""
        from .ricochet_core import render_ascii  # local import to avoid circulars in lints
        return render_ascii(self._board)

    # Helpers
    def _decode_action(self, action: int) -> Tuple[int, int]:
        assert 0 <= action < self.action_space.n
        robot_id = action // 4
        direction = action % 4
        if robot_id >= self.num_robots:
            # Should only happen if action is noop and include_noop=True
            robot_id = 0
            direction = UP
        return robot_id, direction

    def _board_to_obs(self, board: Board) -> np.ndarray:
        h, w = board.height, board.width
        obs = np.zeros((h, w, self._num_channels), dtype=np.float32)
        # walls channel 0
        obs[:, :, 0] = board.walls.astype(np.float32)
        # goal channel 1
        gr, gc = board.goal_position
        obs[gr, gc, 1] = 1.0
        # robot channels
        for rid, (r, c) in board.robot_positions.items():
            obs[r, c, 2 + rid] = 1.0
        return obs

    def _generate_random_board(self) -> Board:
        h, w = self.height, self.width
        walls = np.zeros((h, w), dtype=bool)
        # Simple random internal walls
        max_internal = max(1, (h * w) // 10)
        num_internal_walls = int(self._rng.integers(0, max_internal))
        for _ in range(num_internal_walls):
            r = int(self._rng.integers(0, h))
            c = int(self._rng.integers(0, w))
            walls[r, c] = True
        # Ensure free cells for goal and robots
        free_cells: List[Tuple[int, int]] = [(r, c) for r in range(h) for c in range(w) if not walls[r, c]]
        self._rng.shuffle(free_cells)
        assert len(free_cells) >= self.num_robots + 1, "Not enough free cells"
        goal = free_cells.pop()
        robot_positions: Dict[int, Tuple[int, int]] = {}
        for rid in range(self.num_robots):
            robot_positions[rid] = free_cells.pop()
        target_robot = int(self._rng.integers(0, self.num_robots))
        board = Board(height=h, width=w, walls=walls, robot_positions=robot_positions, goal_position=goal, target_robot=target_robot)
        return board

```

```python
import numpy as np

from env.ricochet_env import RicochetRobotsEnv, FixedLayout
from env.ricochet_core import UP, LEFT, RIGHT, DOWN


def make_simple_layout():
    H, W = 5, 5
    walls = np.zeros((H, W), dtype=bool)
    # Add a wall at (1,2)
    walls[1, 2] = True
    robots = {0: (3, 2)}
    goal = (0, 2)
    target_robot = 0
    return FixedLayout(height=H, width=W, walls=walls, robot_positions=robots, goal_position=goal, target_robot=target_robot)


def test_slide_and_stop():
    layout = make_simple_layout()
    env = RicochetRobotsEnv(fixed_layout=layout, include_noop=False, step_penalty=0.0)
    _, _ = env.reset()
    action_up = 0 * 4 + UP
    _, _, _, _, _ = env.step(action_up)
    _, _, _, _, _ = env.step(action_up)
    action_right = 0 * 4 + RIGHT
    _, _, _, _, _ = env.step(action_right)
    action_left = 0 * 4 + LEFT
    _, _, terminated, _, _ = env.step(action_left)
    assert not terminated


def test_goal_termination_and_reward():
    layout = make_simple_layout()
    env = RicochetRobotsEnv(fixed_layout=layout, include_noop=False, step_penalty=-0.01, goal_reward=1.0)
    _, _ = env.reset()
    _, r1, term, _, info = env.step(0 * 4 + UP)
    _, r2, term, _, info = env.step(0 * 4 + UP)
    _, r3, term, _, info = env.step(0 * 4 + DOWN)
    _, r4, term, _, info = env.step(0 * 4 + LEFT)
    _, r5, term, _, info = env.step(0 * 4 + UP)
    _, r6, term, _, info = env.step(0 * 4 + RIGHT)
    assert term
    assert info.get("success", False)
    total_reward = r1 + r2 + r3 + r4 + r5 + r6
    assert total_reward > 0.9

```

```python
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple, List

import numpy as np

from .ricochet_core import Board, apply_action, reached_goal, UP

# Provide a runtime gymnasium binding if available, otherwise a minimal fallback
try:  # pragma: no cover
    import importlib
    _gym = importlib.import_module("gymnasium")  # type: ignore
    _spaces = importlib.import_module("gymnasium.spaces")  # type: ignore
    GymEnvBase = _gym.Env  # type: ignore
    spaces = _spaces  # type: ignore
except Exception:  # pragma: no cover
    class GymEnvBase(object):
        pass
    class _SpacesDummy:  # minimal placeholders to satisfy type usage
        class Box:  # type: ignore
            def __init__(self, *_, **__):
                pass
        class Discrete:  # type: ignore
            def __init__(self, *_, **__):
                self.n = 0
    spaces = _SpacesDummy()  # type: ignore


@dataclass
class FixedLayout:
    height: int
    width: int
    walls: np.ndarray  # (H,W) bool
    robot_positions: Dict[int, Tuple[int, int]]
    goal_position: Tuple[int, int]
    target_robot: int


class RicochetRobotsEnv(GymEnvBase):
    metadata = {"render_modes": ["ascii"], "render_fps": 4}

    def __init__(
        self,
        height: int = 8,
        width: int = 8,
        num_robots: int = 2,
        include_noop: bool = True,
        step_penalty: float = -0.01,
        goal_reward: float = 1.0,
        max_steps: int = 100,
        fixed_layout: Optional[FixedLayout] = None,
        seed: Optional[int] = None,
        ensure_solvable: bool = False,
        solver_max_depth: int = 30,
        solver_max_nodes: int = 20000,
    ) -> None:
        super().__init__()
        self.height = height
        self.width = width
        self.num_robots = num_robots
        self.include_noop = include_noop
        self.step_penalty = step_penalty
        self.goal_reward = goal_reward
        self.max_steps = max_steps
        self.fixed_layout = fixed_layout
        self.ensure_solvable = ensure_solvable
        self.solver_max_depth = solver_max_depth
        self.solver_max_nodes = solver_max_nodes

        self._rng: np.random.Generator = np.random.default_rng(seed)
        self._board: Optional[Board] = None
        self._num_steps = 0

        # Observation: channels = 1 (walls) + 1 (goal) + num_robots (one-hot per robot)
        self._num_channels = 2 + self.num_robots
        self.observation_space = spaces.Box(
            low=0.0,
            high=1.0,
            shape=(self.height, self.width, self._num_channels),
            dtype=np.float32,
        )

        # Action space: num_robots * 4 directions (+ 1 for noop)
        self._noop_action = self.num_robots * 4 if include_noop else None
        self.action_space = spaces.Discrete(self.num_robots * 4 + (1 if include_noop else 0))

    # Gymnasium API
    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):
        if seed is not None:
            self._rng = np.random.default_rng(seed)
        _ = options  # silence unused
        self._num_steps = 0

        if self.fixed_layout is not None:
            self._board = Board(
                height=self.fixed_layout.height,
                width=self.fixed_layout.width,
                walls=self.fixed_layout.walls.copy(),
                robot_positions=dict(self.fixed_layout.robot_positions),
                goal_position=self.fixed_layout.goal_position,
                target_robot=self.fixed_layout.target_robot,
            )
            obs = self._board_to_obs(self._board)
            return obs, {}

        # Otherwise, generate random board, optionally ensure solvable via solver
        attempts = 0
        while True:
            attempts += 1
            board = self._generate_random_board()
            if not self.ensure_solvable:
                self._board = board
                break
            try:
                # Lazy import to avoid circular dependency
                from .solver import solve_bfs  # type: ignore
                solution = solve_bfs(board, max_depth=self.solver_max_depth, max_nodes=self.solver_max_nodes)
                if solution is not None:
                    self._board = board
                    break
            except ImportError:
                # If solver not available, proceed without guaranteeing solvability
                self._board = board
                break
            if attempts >= 20:
                self._board = board
                break

        obs = self._board_to_obs(self._board)
        return obs, {}

    def step(self, action: int):
        assert self._board is not None, "Call reset() first"
        self._num_steps += 1

        reward = self.step_penalty
        terminated = False
        truncated = False
        info = {}

        if self.include_noop and action == self._noop_action:
            # no state change
            pass
        else:
            robot_id, direction = self._decode_action(action)
            self._board = apply_action(self._board, robot_id, direction)

        if reached_goal(self._board):
            reward += self.goal_reward
            terminated = True
            info["success"] = True

        if self._num_steps >= self.max_steps:
            truncated = True

        obs = self._board_to_obs(self._board)
        return obs, reward, terminated, truncated, info

    def render(self):
        if self._board is None:
            return ""
        from .ricochet_core import render_ascii  # local import to avoid circulars in lints
        return render_ascii(self._board)

    # Helpers
    def _decode_action(self, action: int) -> Tuple[int, int]:
        assert 0 <= action < self.action_space.n
        robot_id = action // 4
        direction = action % 4
        if robot_id >= self.num_robots:
            # Should only happen if action is noop and include_noop=True
            robot_id = 0
            direction = UP
        return robot_id, direction

    def _board_to_obs(self, board: Board) -> np.ndarray:
        h, w = board.height, board.width
        obs = np.zeros((h, w, self._num_channels), dtype=np.float32)
        # walls channel 0
        obs[:, :, 0] = board.walls.astype(np.float32)
        # goal channel 1
        gr, gc = board.goal_position
        obs[gr, gc, 1] = 1.0
        # robot channels
        for rid, (r, c) in board.robot_positions.items():
            obs[r, c, 2 + rid] = 1.0
        return obs

    def _generate_random_board(self) -> Board:
        h, w = self.height, self.width
        walls = np.zeros((h, w), dtype=bool)
        # Simple random internal walls
        max_internal = max(1, (h * w) // 10)
        num_internal_walls = int(self._rng.integers(0, max_internal))
        for _ in range(num_internal_walls):
            r = int(self._rng.integers(0, h))
            c = int(self._rng.integers(0, w))
            walls[r, c] = True
        # Ensure free cells for goal and robots
        free_cells: List[Tuple[int, int]] = [(r, c) for r in range(h) for c in range(w) if not walls[r, c]]
        self._rng.shuffle(free_cells)
        assert len(free_cells) >= self.num_robots + 1, "Not enough free cells"
        goal = free_cells.pop()
        robot_positions: Dict[int, Tuple[int, int]] = {}
        for rid in range(self.num_robots):
            robot_positions[rid] = free_cells.pop()
        target_robot = int(self._rng.integers(0, self.num_robots))
        board = Board(height=h, width=w, walls=walls, robot_positions=robot_positions, goal_position=goal, target_robot=target_robot)
        return board

```

- I implemented core utilities, the Gym-compatible environment with fixed-layout and no-op support, a BFS solver, tests, and a README. I also resolved lints except for a benign warning about broad exception fallback in optional gym import.

What Ill do next if you want:
- Run pytest locally and fix any runtime issues.
- Add a simple CLI demo to step through a board and print ASCII renders.

Changes:
- Added `env/ricochet_core.py` with `Board`, slide/apply logic, goal check, and ASCII render.
- Added `env/ricochet_env.py` implementing `RicochetRobotsEnv` (image obs, discrete actions, no-op, fixed layout, optional solvability check).
- Added `env/solver.py` with BFS using shared movement.
- Added tests `tests/test_env.py`, `tests/test_solver.py`.
- Added `requirements.txt` and `README.md`.

Example usage:
```python
from env.ricochet_env import RicochetRobotsEnv
env = RicochetRobotsEnv(height=8, width=8, num_robots=2)
obs, info = env.reset()
obs, reward, terminated, truncated, info = env.step(0)  # robot 0 up
print(env.render())
```

```python
from env.ricochet_env import RicochetRobotsEnv
env = RicochetRobotsEnv(height=8, width=8, num_robots=2)
obs, info = env.reset()
obs, reward, terminated, truncated, info = env.step(0)  # robot 0 up
print(env.render())
```

---

**User**

Yes please go ahead and run pytest, and write the CLI demo to step through a board and print ASCII renders.

---

**Cursor**

I'll add a small CLI demo script to step through a fixed board rendering ASCII after each action, then run pytest to verify everything passes.

Installing dependencies, then running the tests. After that, Ill add a CLI demo script to interactively step through a fixed board and print ASCII renders.

---

**User**

Read the cursor rules rule about python environment

---

**Cursor**

Let me pull in the workspace rule for the Python environment so I can follow it before running anything.

I'll activate the specified Python environment `rlenv` and run the test suite.

I'll fix the failing tests by adjusting the deterministic layout to be solvable under Ricochet Robots mechanics (add a wall to allow stopping at the goal), then re-run pytest. I'll also add a simple CLI demo script to step through a fixed board and print ASCII renders.

```python
import numpy as np

from env.ricochet_env import RicochetRobotsEnv, FixedLayout
from env.ricochet_core import UP, LEFT, RIGHT, DOWN


def make_simple_layout():
    H, W = 5, 5
    walls = np.zeros((H, W), dtype=bool)
    # Add a wall at (1,2) to block upward motion from below
    walls[1, 2] = True
    # Add a stopper to the right of the goal so sliding right can stop on goal
    walls[0, 3] = True
    robots = {0: (3, 2)}
    goal = (0, 2)
    target_robot = 0
    return FixedLayout(height=H, width=W, walls=walls, robot_positions=robots, goal_position=goal, target_robot=target_robot)


def test_slide_and_stop():
    layout = make_simple_layout()
    env = RicochetRobotsEnv(fixed_layout=layout, include_noop=False, step_penalty=0.0)
    _, _ = env.reset()
    action_up = 0 * 4 + UP
    _, _, _, _, _ = env.step(action_up)
    _, _, _, _, _ = env.step(action_up)
    action_right = 0 * 4 + RIGHT
    _, _, _, _, _ = env.step(action_right)
    action_left = 0 * 4 + LEFT
    _, _, terminated, _, _ = env.step(action_left)
    assert not terminated


def test_goal_termination_and_reward():
    layout = make_simple_layout()
    env = RicochetRobotsEnv(fixed_layout=layout, include_noop=False, step_penalty=-0.01, goal_reward=1.0)
    _, _ = env.reset()
    # Move up to (2,2)
    _, r1, term, _, info = env.step(0 * 4 + UP)
    # Still blocked above, move left to reach (2,0)
    _, r2, term, _, info = env.step(0 * 4 + LEFT)
    # Move up to (0,0)
    _, r3, term, _, info = env.step(0 * 4 + UP)
    # Move right; stopper at (0,3) causes stop at (0,2) which is goal
    _, r4, term, _, info = env.step(0 * 4 + RIGHT)
    assert term
    assert info.get("success", False)
    total_reward = r1 + r2 + r3 + r4
    assert total_reward > 0.9

```

```python
import numpy as np

from env.ricochet_core import Board, apply_action, reached_goal
from env.solver import solve_bfs


def test_bfs_finds_solution_on_simple_board():
    H, W = 5, 5
    walls = np.zeros((H, W), dtype=bool)
    # Place a wall above the robot and a stopper to the right of the goal
    walls[1, 2] = True
    walls[0, 3] = True
    robots = {0: (3, 2)}
    goal = (0, 2)
    board = Board(height=H, width=W, walls=walls, robot_positions=robots, goal_position=goal, target_robot=0)

    actions = solve_bfs(board, max_depth=20, max_nodes=10000)
    assert actions is not None

    # Apply actions and verify goal reached
    cur = board
    for rid, d in actions:
        cur = apply_action(cur, rid, d)
    assert reached_goal(cur)

```

```python
import os
import sys

# Ensure project root is on sys.path so 'env' package can be imported in tests
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)
```

```python
import sys
import argparse

import numpy as np

from env.ricochet_env import RicochetRobotsEnv, FixedLayout
from env.ricochet_core import UP, DOWN, LEFT, RIGHT

ACTIONS_HELP = """
Enter an action:
  u  -> move robot 0 up
  d  -> move robot 0 down
  l  -> move robot 0 left
  r  -> move robot 0 right
  n  -> no-op (if enabled)
  q  -> quit
"""

def make_fixed_env() -> RicochetRobotsEnv:
    H, W = 5, 5
    walls = np.zeros((H, W), dtype=bool)
    # Deterministic layout matching tests: stopper to the right of goal
    walls[1, 2] = True
    walls[0, 3] = True
    robots = {0: (3, 2)}
    goal = (0, 2)
    layout = FixedLayout(height=H, width=W, walls=walls, robot_positions=robots, goal_position=goal, target_robot=0)
    env = RicochetRobotsEnv(fixed_layout=layout, include_noop=True, step_penalty=0.0, goal_reward=1.0, max_steps=50)
    return env


def main(argv=None):
    parser = argparse.ArgumentParser(description="Ricochet Robots CLI Demo")
    args = parser.parse_args(argv)

    env = make_fixed_env()
    obs, info = env.reset()
    print("Initial board:")
    print(env.render())
    print(ACTIONS_HELP)

    action_map = {
        'u': 0 * 4 + UP,
        'd': 0 * 4 + DOWN,
        'l': 0 * 4 + LEFT,
        'r': 0 * 4 + RIGHT,
    }

    while True:
        try:
            s = input("Action (u/d/l/r/n/q): ").strip().lower()
        except EOFError:
            print()
            break
        if s == 'q':
            break
        if s == 'n':
            # noop is last action index
            action = env._noop_action if env._noop_action is not None else 0
        elif s in action_map:
            action = action_map[s]
        else:
            print("Unknown input. Try again.")
            continue

        obs, reward, terminated, truncated, info = env.step(action)
        print(env.render())
        print(f"reward={reward:.3f} terminated={terminated} truncated={truncated} info={info}")
        if terminated or truncated:
            print("Episode ended. Resetting.\n")
            obs, info = env.reset()
            print(env.render())


if __name__ == "__main__":
    sys.exit(main())
```

- Activated `rlenv`, fixed deterministic boards, and ran tests: all passing (3 passed).
- Added `demo_cli.py` to interactively step through a fixed board and print ASCII after each action.

Run tests:
- Use the project env.
- Command: `source /Users/sidbaines/Documents/Code/20250911_RLNew/rlenv/bin/activate && pytest -q`

Run the CLI demo:
- Command: `source /Users/sidbaines/Documents/Code/20250911_RLNew/rlenv/bin/activate && python demo_cli.py`
- Controls: u/d/l/r for robot 0, n = no-op, q = quit.

All Step 1 tasks are implemented and verified.

---

**User**

You have been given the attached feedback on your work. Please address the comments

---

**Cursor**

```python
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple, List, Literal

import numpy as np

from .ricochet_core import Board, apply_action, reached_goal, UP

# Provide a runtime gymnasium binding if available, otherwise a minimal fallback
try:  # pragma: no cover
    import importlib
    _gym = importlib.import_module("gymnasium")  # type: ignore
    _spaces = importlib.import_module("gymnasium.spaces")  # type: ignore
    GymEnvBase = _gym.Env  # type: ignore
    spaces = _spaces  # type: ignore
except Exception:  # pragma: no cover
    class GymEnvBase(object):
        pass
    class _SpacesDummy:  # minimal placeholders to satisfy type usage
        class Box:  # type: ignore
            def __init__(self, low=None, high=None, shape=None, dtype=None):
                self.low = low
                self.high = high
                self.shape = shape
                self.dtype = dtype
        class Discrete:  # type: ignore
            def __init__(self, n: int):
                self.n = n
    spaces = _SpacesDummy()  # type: ignore


@dataclass
class FixedLayout:
    height: int
    width: int
    walls: np.ndarray  # (H,W) bool
    robot_positions: Dict[int, Tuple[int, int]]
    goal_position: Tuple[int, int]
    target_robot: int


ObsMode = Literal["image", "symbolic"]


class RicochetRobotsEnv(GymEnvBase):
    metadata = {"render_modes": ["ascii"], "render_fps": 4}

    def __init__(
        self,
        height: int = 8,
        width: int = 8,
        num_robots: int = 2,
        include_noop: bool = True,
        step_penalty: float = -0.01,
        goal_reward: float = 1.0,
        noop_penalty: Optional[float] = None,
        max_steps: int = 100,
        fixed_layout: Optional[FixedLayout] = None,
        seed: Optional[int] = None,
        ensure_solvable: bool = False,
        solver_max_depth: int = 30,
        solver_max_nodes: int = 20000,
        obs_mode: ObsMode = "image",
        channels_first: bool = False,
    ) -> None:
        super().__init__()
        self.height = height
        self.width = width
        self.num_robots = num_robots
        self.include_noop = include_noop
        self.step_penalty = step_penalty
        self.goal_reward = goal_reward
        self.noop_penalty = step_penalty if noop_penalty is None else noop_penalty
        self.max_steps = max_steps
        self.fixed_layout = fixed_layout
        self.ensure_solvable = ensure_solvable
        self.solver_max_depth = solver_max_depth
        self.solver_max_nodes = solver_max_nodes
        self.obs_mode: ObsMode = obs_mode
        self.channels_first = channels_first

        self._rng: np.random.Generator = np.random.default_rng(seed)
        self._board: Optional[Board] = None
        self._num_steps = 0

        # Observation spaces
        if self.obs_mode == "image":
            # channels: walls(0), goal(1), target_mask(2), robots(3..)
            self._num_channels = 3 + self.num_robots
            if self.channels_first:
                obs_shape = (self._num_channels, self.height, self.width)
            else:
                obs_shape = (self.height, self.width, self._num_channels)
            self.observation_space = spaces.Box(
                low=0.0,
                high=1.0,
                shape=obs_shape,
                dtype=np.float32,
            )
        elif self.obs_mode == "symbolic":
            # vector: [goal_r, goal_c, target_id_one_hot(num_robots), robots_flat(num_robots*2)]
            vec_len = 2 + self.num_robots + (self.num_robots * 2)
            self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(vec_len,), dtype=np.float32)
        else:
            raise ValueError(f"Unknown obs_mode: {self.obs_mode}")

        # Action space: num_robots * 4 directions (+ 1 for noop)
        self._noop_action = self.num_robots * 4 if include_noop else None
        self.action_space = spaces.Discrete(self.num_robots * 4 + (1 if include_noop else 0))

    # Gymnasium API
    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):
        if seed is not None:
            self._rng = np.random.default_rng(seed)
        _ = options  # silence unused
        self._num_steps = 0

        if self.fixed_layout is not None:
            self._board = Board(
                height=self.fixed_layout.height,
                width=self.fixed_layout.width,
                walls=self.fixed_layout.walls.copy(),
                robot_positions=dict(self.fixed_layout.robot_positions),
                goal_position=self.fixed_layout.goal_position,
                target_robot=self.fixed_layout.target_robot,
            )
            obs = self._make_obs(self._board)
            info = {"level_solvable": True, "target_robot": self._board.target_robot}
            return obs, info

        # Otherwise, generate random board, optionally ensure solvable via solver
        attempts = 0
        last_board: Optional[Board] = None
        while True:
            attempts += 1
            board = self._generate_random_board()
            last_board = board
            if not self.ensure_solvable:
                self._board = board
                break
            try:
                from .solver import solve_bfs  # type: ignore
                solution = solve_bfs(board, max_depth=self.solver_max_depth, max_nodes=self.solver_max_nodes)
                if solution is not None:
                    self._board = board
                    break
            except ImportError:
                # Strict: if ensure_solvable requested but solver unavailable, raise
                raise RuntimeError("ensure_solvable=True but solver unavailable (ImportError)")
            if attempts >= 50:
                # Strict: fail instead of silently proceeding
                raise RuntimeError("Failed to generate solvable board within attempt limit")

        obs = self._make_obs(self._board)
        info = {"level_solvable": True if not self.ensure_solvable else True, "target_robot": self._board.target_robot}
        return obs, info

    def step(self, action: int):
        assert self._board is not None, "Call reset() first"
        self._num_steps += 1

        terminated = False
        truncated = False
        info: Dict[str, object] = {}

        reward = self.step_penalty
        if self.include_noop and action == self._noop_action:
            reward = self.noop_penalty
        else:
            robot_id, direction = self._decode_action(action)
            self._board = apply_action(self._board, robot_id, direction)

        if reached_goal(self._board):
            reward += self.goal_reward
            terminated = True
            info["success"] = True

        if self._num_steps >= self.max_steps:
            truncated = True

        obs = self._make_obs(self._board)
        info["steps"] = self._num_steps
        info["target_robot"] = self._board.target_robot
        return obs, reward, terminated, truncated, info

    def render(self):
        if self._board is None:
            return ""
        from .ricochet_core import render_ascii  # local import to avoid circulars in lints
        return render_ascii(self._board)

    # Helpers
    def _decode_action(self, action: int) -> Tuple[int, int]:
        if not (0 <= action < self.action_space.n):
            raise ValueError(f"Invalid action {action}")
        if self.include_noop and action == self._noop_action:
            raise ValueError("_decode_action called on noop action")
        robot_id = action // 4
        direction = action % 4
        if robot_id >= self.num_robots:
            raise ValueError(f"Invalid robot_id {robot_id} for action {action}")
        return robot_id, direction

    def _make_obs(self, board: Board) -> np.ndarray:
        if self.obs_mode == "image":
            return self._board_to_image_obs(board)
        return self._board_to_symbolic_obs(board)

    def _board_to_image_obs(self, board: Board) -> np.ndarray:
        h, w = board.height, board.width
        obs = np.zeros((h, w, self._num_channels), dtype=np.float32)
        # walls channel 0
        obs[:, :, 0] = board.walls.astype(np.float32)
        # goal channel 1
        gr, gc = board.goal_position
        obs[gr, gc, 1] = 1.0
        # target mask channel 2 (1 at target robot position)
        tr = board.target_robot
        tr_r, tr_c = board.robot_positions[tr]
        obs[tr_r, tr_c, 2] = 1.0
        # robot channels start at 3
        base = 3
        for rid, (r, c) in board.robot_positions.items():
            obs[r, c, base + rid] = 1.0
        if self.channels_first:
            obs = np.transpose(obs, (2, 0, 1))
        return obs

    def _board_to_symbolic_obs(self, board: Board) -> np.ndarray:
        # vector: [goal_r, goal_c, target_id_one_hot(num_robots), robots_flat(num_robots*2)]
        gr, gc = board.goal_position
        target_one_hot = np.zeros((self.num_robots,), dtype=np.float32)
        target_one_hot[board.target_robot] = 1.0
        robots_vec: List[float] = []
        for rid in range(self.num_robots):
            r, c = board.robot_positions[rid]
            robots_vec.extend([float(r), float(c)])
        vec = np.concatenate([
            np.array([float(gr), float(gc)], dtype=np.float32),
            target_one_hot.astype(np.float32),
            np.array(robots_vec, dtype=np.float32),
        ])
        return vec

    def _generate_random_board(self) -> Board:
        h, w = self.height, self.width
        walls = np.zeros((h, w), dtype=bool)
        # Simple random internal walls
        max_internal = max(1, (h * w) // 10)
        num_internal_walls = int(self._rng.integers(0, max_internal))
        for _ in range(num_internal_walls):
            r = int(self._rng.integers(0, h))
            c = int(self._rng.integers(0, w))
            walls[r, c] = True
        # Ensure free cells for goal and robots
        free_cells: List[Tuple[int, int]] = [(r, c) for r in range(h) for c in range(w) if not walls[r, c]]
        self._rng.shuffle(free_cells)
        assert len(free_cells) >= self.num_robots + 1, "Not enough free cells"
        goal = free_cells.pop()
        robot_positions: Dict[int, Tuple[int, int]] = {}
        for rid in range(self.num_robots):
            robot_positions[rid] = free_cells.pop()
        target_robot = int(self._rng.integers(0, self.num_robots))
        board = Board(height=h, width=w, walls=walls, robot_positions=robot_positions, goal_position=goal, target_robot=target_robot)
        return board

```

```python
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple, List

import numpy as np

# Directions encoded as (dr, dc)
DIRECTIONS: List[Tuple[int, int]] = [
    (-1, 0),  # up
    (1, 0),   # down
    (0, -1),  # left
    (0, 1),   # right
]

UP, DOWN, LEFT, RIGHT = 0, 1, 2, 3


@dataclass
class Board:
    height: int
    width: int
    # walls[r, c] == True if cell is a wall/blocked
    walls: np.ndarray  # shape (H, W), dtype=bool
    # robots indexed 0..N-1
    robot_positions: Dict[int, Tuple[int, int]]
    # goal location and which robot is the target
    goal_position: Tuple[int, int]
    target_robot: int

    def __post_init__(self) -> None:
        assert self.walls.shape == (self.height, self.width)
        for _, (r, c) in self.robot_positions.items():
            assert 0 <= r < self.height and 0 <= c < self.width, "Robot out of bounds"
            assert not self.walls[r, c], "Robot cannot occupy a wall cell"
        gr, gc = self.goal_position
        assert 0 <= gr < self.height and 0 <= gc < self.width, "Goal out of bounds"

    @property
    def num_robots(self) -> int:
        return len(self.robot_positions)

    def is_occupied(self, row: int, col: int, ignore_robot: Optional[int] = None) -> bool:
        if self.walls[row, col]:
            return True
        for rid, (rr, cc) in self.robot_positions.items():
            if ignore_robot is not None and rid == ignore_robot:
                continue
            if rr == row and cc == col:
                return True
        return False

    def clone(self) -> "Board":
        return Board(
            height=self.height,
            width=self.width,
            walls=self.walls.copy(),
            robot_positions=dict(self.robot_positions),
            goal_position=tuple(self.goal_position),
            target_robot=self.target_robot,
        )


def slide_until_blocked(board: Board, robot_id: int, direction: int) -> Tuple[int, int]:
    """
    Slide the specified robot in the given direction until hitting a wall, edge, or another robot.
    Returns the final (row, col) position after sliding.
    """
    assert 0 <= direction < 4
    start_r, start_c = board.robot_positions[robot_id]
    dr, dc = DIRECTIONS[direction]

    r, c = start_r, start_c
    # Precompute occupied positions excluding the moving robot
    occupied = np.zeros((board.height, board.width), dtype=bool)
    occupied |= board.walls
    for rid, (rr, cc) in board.robot_positions.items():
        if rid == robot_id:
            continue
        occupied[rr, cc] = True

    # Move step by step until next cell would be blocked or out of bounds
    while True:
        nr, nc = r + dr, c + dc
        if nr < 0 or nr >= board.height or nc < 0 or nc >= board.width:
            break
        if occupied[nr, nc]:
            break
        r, c = nr, nc

    return r, c


def apply_action(board: Board, robot_id: int, direction: int) -> Board:
    """
    Return a new Board after applying the action. If slide results in no movement,
    the robot's position remains the same (board state equal to input aside from copy).
    """
    new_board = board.clone()
    end_r, end_c = slide_until_blocked(new_board, robot_id, direction)
    new_board.robot_positions[robot_id] = (end_r, end_c)
    return new_board


def reached_goal(board: Board) -> bool:
    r, c = board.robot_positions[board.target_robot]
    return (r, c) == board.goal_position


def render_ascii(board: Board) -> str:
    canvas = np.full((board.height, board.width), fill_value='.', dtype=object)
    canvas[board.walls] = '#'
    gr, gc = board.goal_position
    canvas[gr, gc] = 'G' if canvas[gr, gc] == '.' else 'X'
    for rid, (r, c) in board.robot_positions.items():
        label = chr(ord('A') + rid)
        canvas[r, c] = label if canvas[r, c] == '.' else '*'
    lines = [''.join(str(x) for x in row) for row in canvas]
    return '\n'.join(lines)

```

```python
import numpy as np

from env.ricochet_env import RicochetRobotsEnv, FixedLayout
from env.ricochet_core import UP, LEFT, RIGHT, DOWN


def make_simple_layout():
    H, W = 5, 5
    walls = np.zeros((H, W), dtype=bool)
    # Add a wall at (1,2) to block upward motion from below
    walls[1, 2] = True
    # Add a stopper to the right of the goal so sliding right can stop on goal
    walls[0, 3] = True
    robots = {0: (3, 2)}
    goal = (0, 2)
    target_robot = 0
    return FixedLayout(height=H, width=W, walls=walls, robot_positions=robots, goal_position=goal, target_robot=target_robot)


def test_slide_and_stop():
    layout = make_simple_layout()
    env = RicochetRobotsEnv(fixed_layout=layout, include_noop=False, step_penalty=0.0)
    _, _ = env.reset()
    action_up = 0 * 4 + UP
    _, _, _, _, _ = env.step(action_up)
    _, _, _, _, _ = env.step(action_up)
    action_right = 0 * 4 + RIGHT
    _, _, _, _, _ = env.step(action_right)
    action_left = 0 * 4 + LEFT
    _, _, terminated, _, _ = env.step(action_left)
    assert not terminated


def test_goal_termination_and_reward():
    layout = make_simple_layout()
    env = RicochetRobotsEnv(fixed_layout=layout, include_noop=False, step_penalty=-0.01, goal_reward=1.0)
    _, _ = env.reset()
    # Move up to (2,2)
    _, r1, term, _, info = env.step(0 * 4 + UP)
    # Still blocked above, move left to reach (2,0)
    _, r2, term, _, info = env.step(0 * 4 + LEFT)
    # Move up to (0,0)
    _, r3, term, _, info = env.step(0 * 4 + UP)
    # Move right; stopper at (0,3) causes stop at (0,2) which is goal
    _, r4, term, _, info = env.step(0 * 4 + RIGHT)
    assert term
    assert info.get("success", False)
    total_reward = r1 + r2 + r3 + r4
    assert total_reward > 0.9


def test_multi_robot_blocking_and_truncation():
    H, W = 5, 5
    walls = np.zeros((H, W), dtype=bool)
    # Two robots in same column; robot 1 above robot 0 acts as bumper
    robots = {0: (4, 2), 1: (2, 2)}
    goal = (0, 0)
    layout = FixedLayout(height=H, width=W, walls=walls, robot_positions=robots, goal_position=goal, target_robot=0)
    env = RicochetRobotsEnv(fixed_layout=layout, include_noop=False, step_penalty=0.0, max_steps=3)
    _, _ = env.reset()
    # Move robot 0 up; should stop at (3,2) because robot 1 at (2,2)
    obs, _, term, trunc, info = env.step(0 * 4 + UP)
    # Move robot 1 left, then right; episode should truncate due to max_steps
    obs, _, term, trunc, info = env.step(1 * 4 + LEFT)
    obs, _, term, trunc, info = env.step(1 * 4 + RIGHT)
    assert not term
    assert trunc

```

```python
import sys
import argparse

import numpy as np

from env.ricochet_env import RicochetRobotsEnv, FixedLayout
from env.ricochet_core import UP, DOWN, LEFT, RIGHT

ACTIONS_HELP = """
Enter an action:
  u/d/l/r  -> move current robot up/down/left/right
  s <id>   -> switch current robot (0-based)
  n        -> no-op (if enabled)
  q        -> quit
"""

def make_fixed_env() -> RicochetRobotsEnv:
    H, W = 5, 5
    walls = np.zeros((H, W), dtype=bool)
    # Deterministic layout matching tests: stopper to the right of goal
    walls[1, 2] = True
    walls[0, 3] = True
    robots = {0: (3, 2), 1: (4, 4)}
    goal = (0, 2)
    layout = FixedLayout(height=H, width=W, walls=walls, robot_positions=robots, goal_position=goal, target_robot=0)
    env = RicochetRobotsEnv(fixed_layout=layout, include_noop=True, step_penalty=0.0, goal_reward=1.0, max_steps=50)
    return env


def main(argv=None):
    parser = argparse.ArgumentParser(description="Ricochet Robots CLI Demo")
    args = parser.parse_args(argv)

    env = make_fixed_env()
    obs, info = env.reset()
    current_robot = 0
    print("Initial board:")
    print(env.render())
    print(ACTIONS_HELP)

    def to_action(robot_id: int, dir_code: int) -> int:
        return robot_id * 4 + dir_code

    while True:
        try:
            s = input(f"[robot {current_robot}] Action (u/d/l/r/s <id>/n/q): ").strip().lower()
        except EOFError:
            print()
            break
        if s == 'q':
            break
        if s.startswith('s'):
            parts = s.split()
            if len(parts) == 2 and parts[1].isdigit():
                new_id = int(parts[1])
                current_robot = max(0, min(new_id, env.num_robots - 1))  # type: ignore[attr-defined]
            else:
                print("Usage: s <robot_id>")
            continue
        if s == 'n':
            action = env._noop_action if getattr(env, "_noop_action", None) is not None else 0
        elif s == 'u':
            action = to_action(current_robot, UP)
        elif s == 'd':
            action = to_action(current_robot, DOWN)
        elif s == 'l':
            action = to_action(current_robot, LEFT)
        elif s == 'r':
            action = to_action(current_robot, RIGHT)
        else:
            print("Unknown input. Try again.")
            continue

        obs, reward, terminated, truncated, info = env.step(action)
        print(env.render())
        print(f"reward={reward:.3f} terminated={terminated} truncated={truncated} info={info}")
        if terminated or truncated:
            print("Episode ended. Resetting.\n")
            obs, info = env.reset()
            print(env.render())


if __name__ == "__main__":
    sys.exit(main())

```

```python
import sys
import argparse

import numpy as np

from env.ricochet_env import RicochetRobotsEnv, FixedLayout
from env.ricochet_core import UP, DOWN, LEFT, RIGHT

ACTIONS_HELP = """
Enter an action:
  u/d/l/r  -> move current robot up/down/left/right
  s <id>   -> switch current robot (0-based)
  n        -> no-op (if enabled)
  q        -> quit
"""

def make_fixed_env() -> RicochetRobotsEnv:
    H, W = 5, 5
    walls = np.zeros((H, W), dtype=bool)
    # Deterministic layout matching tests: stopper to the right of goal
    walls[1, 2] = True
    walls[0, 3] = True
    robots = {0: (3, 2), 1: (4, 4)}
    goal = (0, 2)
    layout = FixedLayout(height=H, width=W, walls=walls, robot_positions=robots, goal_position=goal, target_robot=0)
    env = RicochetRobotsEnv(fixed_layout=layout, include_noop=True, step_penalty=0.0, goal_reward=1.0, max_steps=50)
    return env


def main(argv=None):
    parser = argparse.ArgumentParser(description="Ricochet Robots CLI Demo")
    _ = parser.parse_args(argv)

    env = make_fixed_env()
    _, _ = env.reset()
    current_robot = 0
    print("Initial board:")
    print(env.render())
    print(ACTIONS_HELP)

    def to_action(robot_id: int, dir_code: int) -> int:
        return robot_id * 4 + dir_code

    while True:
        try:
            s = input(f"[robot {current_robot}] Action (u/d/l/r/s <id>/n/q): ").strip().lower()
        except EOFError:
            print()
            break
        if s == 'q':
            break
        if s.startswith('s'):
            parts = s.split()
            if len(parts) == 2 and parts[1].isdigit():
                new_id = int(parts[1])
                # type: ignore[attr-defined]
                current_robot = max(0, min(new_id, getattr(env, 'num_robots', 1) - 1))
            else:
                print("Usage: s <robot_id>")
            continue
        if s == 'n':
            # use last discrete index as noop if enabled
            action = env.action_space.n - 1  # type: ignore[attr-defined]
        elif s == 'u':
            action = to_action(current_robot, UP)
        elif s == 'd':
            action = to_action(current_robot, DOWN)
        elif s == 'l':
            action = to_action(current_robot, LEFT)
        elif s == 'r':
            action = to_action(current_robot, RIGHT)
        else:
            print("Unknown input. Try again.")
            continue

        _, reward, terminated, truncated, info = env.step(action)
        print(env.render())
        print(f"reward={reward:.3f} terminated={terminated} truncated={truncated} info={info}")
        if terminated or truncated:
            print("Episode ended. Resetting.\n")
            _, _ = env.reset()
            print(env.render())


if __name__ == "__main__":
    sys.exit(main())

```

```python
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple, List, Literal

import numpy as np

from .ricochet_core import Board, apply_action, reached_goal

# Provide a runtime gymnasium binding if available, otherwise a minimal fallback
try:  # pragma: no cover
    import importlib
    _gym = importlib.import_module("gymnasium")  # type: ignore
    _spaces = importlib.import_module("gymnasium.spaces")  # type: ignore
    GymEnvBase = _gym.Env  # type: ignore
    spaces = _spaces  # type: ignore
except Exception:  # pragma: no cover
    class GymEnvBase(object):
        pass
    class _SpacesDummy:  # minimal placeholders to satisfy type usage
        class Box:  # type: ignore
            def __init__(self, low=None, high=None, shape=None, dtype=None):
                self.low = low
                self.high = high
                self.shape = shape
                self.dtype = dtype
        class Discrete:  # type: ignore
            def __init__(self, n: int):
                self.n = n
    spaces = _SpacesDummy()  # type: ignore


@dataclass
class FixedLayout:
    height: int
    width: int
    walls: np.ndarray  # (H,W) bool
    robot_positions: Dict[int, Tuple[int, int]]
    goal_position: Tuple[int, int]
    target_robot: int


ObsMode = Literal["image", "symbolic"]


class RicochetRobotsEnv(GymEnvBase):
    metadata = {"render_modes": ["ascii"], "render_fps": 4}

    def __init__(
        self,
        height: int = 8,
        width: int = 8,
        num_robots: int = 2,
        include_noop: bool = True,
        step_penalty: float = -0.01,
        goal_reward: float = 1.0,
        noop_penalty: Optional[float] = None,
        max_steps: int = 100,
        fixed_layout: Optional[FixedLayout] = None,
        seed: Optional[int] = None,
        ensure_solvable: bool = False,
        solver_max_depth: int = 30,
        solver_max_nodes: int = 20000,
        obs_mode: ObsMode = "image",
        channels_first: bool = False,
    ) -> None:
        super().__init__()
        self.height = height
        self.width = width
        self.num_robots = num_robots
        self.include_noop = include_noop
        self.step_penalty = step_penalty
        self.goal_reward = goal_reward
        self.noop_penalty = step_penalty if noop_penalty is None else noop_penalty
        self.max_steps = max_steps
        self.fixed_layout = fixed_layout
        self.ensure_solvable = ensure_solvable
        self.solver_max_depth = solver_max_depth
        self.solver_max_nodes = solver_max_nodes
        self.obs_mode: ObsMode = obs_mode
        self.channels_first = channels_first

        self._rng: np.random.Generator = np.random.default_rng(seed)
        self._board: Optional[Board] = None
        self._num_steps = 0

        # Observation spaces
        if self.obs_mode == "image":
            # channels: walls(0), goal(1), target_mask(2), robots(3..)
            self._num_channels = 3 + self.num_robots
            if self.channels_first:
                obs_shape = (self._num_channels, self.height, self.width)
            else:
                obs_shape = (self.height, self.width, self._num_channels)
            self.observation_space = spaces.Box(
                low=0.0,
                high=1.0,
                shape=obs_shape,
                dtype=np.float32,
            )
        elif self.obs_mode == "symbolic":
            # vector: [goal_r, goal_c, target_id_one_hot(num_robots), robots_flat(num_robots*2)]
            vec_len = 2 + self.num_robots + (self.num_robots * 2)
            self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(vec_len,), dtype=np.float32)
        else:
            raise ValueError(f"Unknown obs_mode: {self.obs_mode}")

        # Action space: num_robots * 4 directions (+ 1 for noop)
        self._noop_action = self.num_robots * 4 if include_noop else None
        self.action_space = spaces.Discrete(self.num_robots * 4 + (1 if include_noop else 0))

    # Gymnasium API
    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):
        if seed is not None:
            self._rng = np.random.default_rng(seed)
        _ = options  # silence unused
        self._num_steps = 0

        if self.fixed_layout is not None:
            self._board = Board(
                height=self.fixed_layout.height,
                width=self.fixed_layout.width,
                walls=self.fixed_layout.walls.copy(),
                robot_positions=dict(self.fixed_layout.robot_positions),
                goal_position=self.fixed_layout.goal_position,
                target_robot=self.fixed_layout.target_robot,
            )
            obs = self._make_obs(self._board)
            info = {"level_solvable": True, "target_robot": self._board.target_robot}
            return obs, info

        # Otherwise, generate random board, optionally ensure solvable via solver
        attempts = 0
        while True:
            attempts += 1
            board = self._generate_random_board()
            if not self.ensure_solvable:
                self._board = board
                break
            try:
                from .solver import solve_bfs  # type: ignore
                solution = solve_bfs(board, max_depth=self.solver_max_depth, max_nodes=self.solver_max_nodes)
                if solution is not None:
                    self._board = board
                    break
            except ImportError as exc:
                raise RuntimeError("ensure_solvable=True but solver unavailable (ImportError)") from exc
            if attempts >= 50:
                # Strict: fail instead of silently proceeding
                raise RuntimeError("Failed to generate solvable board within attempt limit")

        obs = self._make_obs(self._board)
        info = {"level_solvable": True, "target_robot": self._board.target_robot}
        return obs, info

    def step(self, action: int):
        assert self._board is not None, "Call reset() first"
        self._num_steps += 1

        terminated = False
        truncated = False
        info: Dict[str, object] = {}

        reward = self.step_penalty
        if self.include_noop and action == self._noop_action:
            reward = self.noop_penalty
        else:
            robot_id, direction = self._decode_action(action)
            self._board = apply_action(self._board, robot_id, direction)

        if reached_goal(self._board):
            reward += self.goal_reward
            terminated = True
            info["success"] = True

        if self._num_steps >= self.max_steps:
            truncated = True

        obs = self._make_obs(self._board)
        info["steps"] = self._num_steps
        info["target_robot"] = self._board.target_robot
        return obs, reward, terminated, truncated, info

    def render(self):
        if self._board is None:
            return ""
        from .ricochet_core import render_ascii  # local import to avoid circulars in lints
        return render_ascii(self._board)

    # Helpers
    def _decode_action(self, action: int) -> Tuple[int, int]:
        if not (0 <= action < self.action_space.n):
            raise ValueError(f"Invalid action {action}")
        if self.include_noop and action == self._noop_action:
            raise ValueError("_decode_action called on noop action")
        robot_id = action // 4
        direction = action % 4
        if robot_id >= self.num_robots:
            raise ValueError(f"Invalid robot_id {robot_id} for action {action}")
        return robot_id, direction

    def _make_obs(self, board: Board) -> np.ndarray:
        if self.obs_mode == "image":
            return self._board_to_image_obs(board)
        return self._board_to_symbolic_obs(board)

    def _board_to_image_obs(self, board: Board) -> np.ndarray:
        h, w = board.height, board.width
        obs = np.zeros((h, w, self._num_channels), dtype=np.float32)
        # walls channel 0
        obs[:, :, 0] = board.walls.astype(np.float32)
        # goal channel 1
        gr, gc = board.goal_position
        obs[gr, gc, 1] = 1.0
        # target mask channel 2 (1 at target robot position)
        tr = board.target_robot
        tr_r, tr_c = board.robot_positions[tr]
        obs[tr_r, tr_c, 2] = 1.0
        # robot channels start at 3
        base = 3
        for rid, (r, c) in board.robot_positions.items():
            obs[r, c, base + rid] = 1.0
        if self.channels_first:
            obs = np.transpose(obs, (2, 0, 1))
        return obs

    def _board_to_symbolic_obs(self, board: Board) -> np.ndarray:
        # vector: [goal_r, goal_c, target_id_one_hot(num_robots), robots_flat(num_robots*2)]
        gr, gc = board.goal_position
        target_one_hot = np.zeros((self.num_robots,), dtype=np.float32)
        target_one_hot[board.target_robot] = 1.0
        robots_vec: List[float] = []
        for rid in range(self.num_robots):
            r, c = board.robot_positions[rid]
            robots_vec.extend([float(r), float(c)])
        vec = np.concatenate([
            np.array([float(gr), float(gc)], dtype=np.float32),
            target_one_hot.astype(np.float32),
            np.array(robots_vec, dtype=np.float32),
        ])
        return vec

    def _generate_random_board(self) -> Board:
        h, w = self.height, self.width
        walls = np.zeros((h, w), dtype=bool)
        # Simple random internal walls
        max_internal = max(1, (h * w) // 10)
        num_internal_walls = int(self._rng.integers(0, max_internal))
        for _ in range(num_internal_walls):
            r = int(self._rng.integers(0, h))
            c = int(self._rng.integers(0, w))
            walls[r, c] = True
        # Ensure free cells for goal and robots
        free_cells: List[Tuple[int, int]] = [(r, c) for r in range(h) for c in range(w) if not walls[r, c]]
        self._rng.shuffle(free_cells)
        assert len(free_cells) >= self.num_robots + 1, "Not enough free cells"
        goal = free_cells.pop()
        robot_positions: Dict[int, Tuple[int, int]] = {}
        for rid in range(self.num_robots):
            robot_positions[rid] = free_cells.pop()
        target_robot = int(self._rng.integers(0, self.num_robots))
        board = Board(height=h, width=w, walls=walls, robot_positions=robot_positions, goal_position=goal, target_robot=target_robot)
        return board

```

```python
import numpy as np

from env.ricochet_env import RicochetRobotsEnv, FixedLayout
from env.ricochet_core import UP, LEFT, RIGHT


def make_simple_layout():
    H, W = 5, 5
    walls = np.zeros((H, W), dtype=bool)
    # Add a wall at (1,2) to block upward motion from below
    walls[1, 2] = True
    # Add a stopper to the right of the goal so sliding right can stop on goal
    walls[0, 3] = True
    robots = {0: (3, 2)}
    goal = (0, 2)
    target_robot = 0
    return FixedLayout(height=H, width=W, walls=walls, robot_positions=robots, goal_position=goal, target_robot=target_robot)


def test_slide_and_stop():
    layout = make_simple_layout()
    env = RicochetRobotsEnv(fixed_layout=layout, include_noop=False, step_penalty=0.0)
    _, _ = env.reset()
    action_up = 0 * 4 + UP
    _, _, _, _, _ = env.step(action_up)
    _, _, _, _, _ = env.step(action_up)
    action_right = 0 * 4 + RIGHT
    _, _, _, _, _ = env.step(action_right)
    action_left = 0 * 4 + LEFT
    _, _, terminated, _, _ = env.step(action_left)
    assert not terminated


def test_goal_termination_and_reward():
    layout = make_simple_layout()
    env = RicochetRobotsEnv(fixed_layout=layout, include_noop=False, step_penalty=-0.01, goal_reward=1.0)
    _, _ = env.reset()
    # Move up to (2,2)
    _, r1, term, _, _ = env.step(0 * 4 + UP)
    # Still blocked above, move left to reach (2,0)
    _, r2, term, _, _ = env.step(0 * 4 + LEFT)
    # Move up to (0,0)
    _, r3, term, _, _ = env.step(0 * 4 + UP)
    # Move right; stopper at (0,3) causes stop at (0,2) which is goal
    _, r4, term, _, info = env.step(0 * 4 + RIGHT)
    assert term
    assert info.get("success", False)
    total_reward = r1 + r2 + r3 + r4
    assert total_reward > 0.9


def test_multi_robot_blocking_and_truncation():
    H, W = 5, 5
    walls = np.zeros((H, W), dtype=bool)
    # Two robots in same column; robot 1 above robot 0 acts as bumper
    robots = {0: (4, 2), 1: (2, 2)}
    goal = (0, 0)
    layout = FixedLayout(height=H, width=W, walls=walls, robot_positions=robots, goal_position=goal, target_robot=0)
    env = RicochetRobotsEnv(fixed_layout=layout, include_noop=False, step_penalty=0.0, max_steps=3)
    _, _ = env.reset()
    # Move robot 0 up; should stop at (3,2) because robot 1 at (2,2)
    _, _, _, _, _ = env.step(0 * 4 + UP)
    # Move robot 1 left, then right; episode should truncate due to max_steps
    _, _, _, _, _ = env.step(1 * 4 + LEFT)
    _, _, term, trunc, _ = env.step(1 * 4 + RIGHT)
    assert not term
    assert trunc

```

- Addressed observation issues: added target-robot exposure and `channels_first` option; added `symbolic` obs mode.
- Action handling: strict validation; `noop_penalty` separate from `step_penalty`.
- Solvability: `ensure_solvable=True` is now strict (raises on failure/import issue) and `info` includes diagnostics.
- Dummy gym fallback improved to carry `shape`, `dtype`, and `n`.
- Clarified `apply_action` doc; logic unchanged.
- Tests: added multi-robot blocking and `max_steps` truncation; updated boards for solvability.
- CLI: supports switching robots; avoids using protected members.

Run tests:
- `source /Users/sidbaines/Documents/Code/20250911_RLNew/rlenv/bin/activate && pytest -q`

Run demo:
- `source /Users/sidbaines/Documents/Code/20250911_RLNew/rlenv/bin/activate && python demo_cli.py`

Key updates in:
- `env/ricochet_env.py` (obs channels, modes, penalties, strictness).
- `env/ricochet_core.py` (doc).
- `tests/test_env.py` (new tests).
- `demo_cli.py` (multi-robot control).

