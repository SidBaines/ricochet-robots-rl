# Implement changes for research proposal feedback
_Exported on 12/09/2025 at 11:19:55 BST from Cursor (1.4.5)_

---

**User**

You are a language model, working as part of a team to implement a research proposal. Please take the time to read the ResearchPlan.md. 
Your colleagues have implemented steps 1.1 - 1.4 of the plan, and steps 1.1-1.2 have been checked and are deemed completed. 
The code has been given the following feedback when measured against the spec (in ResearchPlan.md) for step 1.3. 
Your job is to implement changes to address this feedback. 

---

**Cursor**

I'll scan the environment code and research plan to pinpoint what's required, then create a short todo list and start implementing the highest-impact fixes (render_mode compliance, seeding protocol, close/seed, registration, info consistency, caching walls).

I'll start by updating the environment to comply with Gymnasium seeding and rendering conventions, add close/seed helpers, tighten the symbolic observation space, cache wall channels, improve step info and action validation, add a registration helper, and add brief docstrings. Then I'll update the README with registration and render_mode usage.

```python
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple, List, Literal

import numpy as np

from .ricochet_core import Board, apply_action, reached_goal

# Provide a runtime gymnasium binding if available, otherwise a minimal fallback
try:  # pragma: no cover
    import importlib
    _gym = importlib.import_module("gymnasium")  # type: ignore
    _spaces = importlib.import_module("gymnasium.spaces")  # type: ignore
    _seeding = importlib.import_module("gymnasium.utils.seeding")  # type: ignore
    GymEnvBase = _gym.Env  # type: ignore
    spaces = _spaces  # type: ignore
except Exception:  # pragma: no cover
    class GymEnvBase(object):
        pass
    class _SpacesDummy:  # minimal placeholders to satisfy type usage
        class Box:  # type: ignore
            def __init__(self, low=None, high=None, shape=None, dtype=None):
                self.low = low
                self.high = high
                self.shape = shape
                self.dtype = dtype
        class Discrete:  # type: ignore
            def __init__(self, n: int):
                self.n = n
    spaces = _SpacesDummy()  # type: ignore


@dataclass
class FixedLayout:
    height: int
    width: int
    # Edge walls
    h_walls: np.ndarray  # (H+1, W) bool
    v_walls: np.ndarray  # (H, W+1) bool
    robot_positions: Dict[int, Tuple[int, int]]
    goal_position: Tuple[int, int]
    target_robot: int


ObsMode = Literal["image", "symbolic"]


class RicochetRobotsEnv(GymEnvBase):
    metadata = {"render_modes": ["ascii"], "render_fps": 4}

    def __init__(
        self,
        height: int = 8,
        width: int = 8,
        num_robots: int = 2,
        include_noop: bool = True,
        step_penalty: float = -0.01,
        goal_reward: float = 1.0,
        noop_penalty: Optional[float] = None,
        max_steps: int = 100,
        fixed_layout: Optional[FixedLayout] = None,
        seed: Optional[int] = None,
        ensure_solvable: bool = False,
        solver_max_depth: int = 30,
        solver_max_nodes: int = 20000,
        obs_mode: ObsMode = "image",
        channels_first: bool = False,
        render_mode: Optional[str] = None,
    ) -> None:
        super().__init__()
        self.height = height
        self.width = width
        self.num_robots = num_robots
        self.include_noop = include_noop
        self.step_penalty = step_penalty
        self.goal_reward = goal_reward
        self.noop_penalty = step_penalty if noop_penalty is None else noop_penalty
        self.max_steps = max_steps
        self.fixed_layout = fixed_layout
        self.ensure_solvable = ensure_solvable
        self.solver_max_depth = solver_max_depth
        self.solver_max_nodes = solver_max_nodes
        self.obs_mode: ObsMode = obs_mode
        self.channels_first = channels_first
        # Render API
        self.render_mode = render_mode
        if self.render_mode is not None and self.render_mode not in self.metadata["render_modes"]:
            raise ValueError(f"Unsupported render_mode {self.render_mode}. Supported: {self.metadata['render_modes']}")

        # Seeding: adopt Gymnasium convention with self.np_random
        self.np_random: np.random.Generator
        self._episode_seed: Optional[int] = None
        try:  # gymnasium present
            # _seeding.np_random returns (rng, seed)
            self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
            self._episode_seed = int(used_seed) if used_seed is not None else None
        except Exception:
            self.np_random = np.random.default_rng(seed)
            self._episode_seed = int(seed) if seed is not None else None
        self._board: Optional[Board] = None
        self._num_steps = 0
        self._cached_wall_obs: Optional[np.ndarray] = None  # (H,W,4) float32 for wall channels

        # Observation spaces
        if self.obs_mode == "image":
            # channels: up_wall, down_wall, left_wall, right_wall, goal, target_mask, robots...
            self._base_wall_channels = 4
            self._base_misc_channels = 2  # goal, target
            self._num_channels = self._base_wall_channels + self._base_misc_channels + self.num_robots
            if self.channels_first:
                obs_shape = (self._num_channels, self.height, self.width)
            else:
                obs_shape = (self.height, self.width, self._num_channels)
            self.observation_space = spaces.Box(
                low=0.0,
                high=1.0,
                shape=obs_shape,
                dtype=np.float32,
            )
        elif self.obs_mode == "symbolic":
            # [goal_r, goal_c] in [0..H-1], [0..W-1]; one-hot target in [0,1]; robots positions in bounds
            vec_len = 2 + self.num_robots + (self.num_robots * 2)
            low = np.full((vec_len,), 0.0, dtype=np.float32)
            high = np.full((vec_len,), 1.0, dtype=np.float32)
            # goal bounds
            low[0] = 0.0
            high[0] = float(self.height - 1)
            low[1] = 0.0
            high[1] = float(self.width - 1)
            # target one-hot already [0,1]
            # robots positions
            base = 2 + self.num_robots
            for i in range(self.num_robots):
                low[base + 2 * i] = 0.0
                high[base + 2 * i] = float(self.height - 1)
                low[base + 2 * i + 1] = 0.0
                high[base + 2 * i + 1] = float(self.width - 1)
            self.observation_space = spaces.Box(low=low, high=high, shape=(vec_len,), dtype=np.float32)
        else:
            raise ValueError(f"Unknown obs_mode: {self.obs_mode}")

        # Action space: num_robots * 4 directions (+ 1 for noop)
        self._noop_action = self.num_robots * 4 if include_noop else None
        self.action_space = spaces.Discrete(self.num_robots * 4 + (1 if include_noop else 0))

    # Gymnasium API
    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):
        """Reset the environment and start a new episode.

        Returns (obs, info) per Gymnasium API. info contains keys: 'target_robot',
        'level_solvable' (optional), 'optimal_length' (if ensured), 'solver_limits' (if ensured),
        and 'episode_seed' with the seed used for this episode.
        """
        # Standard seeding protocol
        if seed is not None:
            try:
                self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
                self._episode_seed = int(used_seed) if used_seed is not None else None
            except Exception:
                self.np_random = np.random.default_rng(seed)
                self._episode_seed = int(seed)
        _ = options  # silence unused
        self._num_steps = 0

        if self.fixed_layout is not None:
            self._board = Board(
                height=self.fixed_layout.height,
                width=self.fixed_layout.width,
                h_walls=self.fixed_layout.h_walls.copy(),
                v_walls=self.fixed_layout.v_walls.copy(),
                robot_positions=dict(self.fixed_layout.robot_positions),
                goal_position=self.fixed_layout.goal_position,
                target_robot=self.fixed_layout.target_robot,
            )
            # cache static walls for this layout
            self._build_cached_walls(self._board)
            obs = self._make_obs(self._board)
            info = {"level_solvable": None, "target_robot": self._board.target_robot, "episode_seed": self._episode_seed}
            return obs, info

        # Otherwise, generate random board, optionally ensure solvable via solver
        attempts = 0
        while True:
            attempts += 1
            board = self._generate_random_board()
            if not self.ensure_solvable:
                self._board = board
                break
            try:
                from .solver import solve_bfs  # type: ignore
                solution = solve_bfs(board, max_depth=self.solver_max_depth, max_nodes=self.solver_max_nodes)
                if solution is not None:
                    self._board = board
                    optimal_length = len(solution)
                    break
            except ImportError as exc:
                raise RuntimeError("ensure_solvable=True but solver unavailable (ImportError)") from exc
            if attempts >= 50:
                raise RuntimeError("Failed to generate solvable board within attempt limit")

        # cache static walls for this layout
        assert self._board is not None
        self._build_cached_walls(self._board)
        obs = self._make_obs(self._board)
        # Note: solver None during attempts may be due to cutoffs (depth/nodes), not true unsolvability.
        info = {"level_solvable": True if self.ensure_solvable else None, "target_robot": self._board.target_robot, "episode_seed": self._episode_seed}
        if self.ensure_solvable:
            info["optimal_length"] = optimal_length
            info["solver_limits"] = {"max_depth": self.solver_max_depth, "max_nodes": self.solver_max_nodes}
        return obs, info

    def step(self, action: int):
        """Apply an action and return (obs, reward, terminated, truncated, info).

        info always includes 'steps', 'target_robot', and 'is_success' (bool). When truncated due to
        max steps, info includes 'TimeLimit.truncated'=True.
        """
        assert self._board is not None, "Call reset() first"
        self._num_steps += 1

        terminated = False
        truncated = False
        info: Dict[str, object] = {}

        reward = self.step_penalty
        # Validate action range early
        if not (0 <= action < self.action_space.n):
            raise ValueError(f"Invalid action {action}")

        if self.include_noop and action == self._noop_action:
            reward = self.noop_penalty
        else:
            robot_id, direction = self._decode_action(action)
            self._board = apply_action(self._board, robot_id, direction)

        if reached_goal(self._board):
            reward += self.goal_reward
            terminated = True
            info["success"] = True
            info["is_success"] = True

        if not terminated and self._num_steps >= self.max_steps:
            truncated = True
            info["TimeLimit.truncated"] = True

        obs = self._make_obs(self._board)
        info["steps"] = self._num_steps
        info["target_robot"] = self._board.target_robot
        if "is_success" not in info:
            info["is_success"] = False
        return obs, reward, terminated, truncated, info

    def render(self):
        """Render according to render_mode.

        - render_mode=="ascii": returns a string frame.
        - render_mode is None or unsupported: returns None.
        """
        if self.render_mode != "ascii":
            return None
        if self._board is None:
            return ""
        from .ricochet_core import render_ascii  # local import to avoid circulars in lints
        return render_ascii(self._board)

    def close(self) -> None:
        """Close environment resources (no-op)."""
        return None

    def seed(self, seed: Optional[int] = None):  # legacy convenience
        """Legacy seeding helper returning [seed]. Prefer reset(seed=...)."""
        if seed is None:
            return [self._episode_seed]
        try:
            self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
            self._episode_seed = int(used_seed) if used_seed is not None else int(seed)
        except Exception:
            self.np_random = np.random.default_rng(seed)
            self._episode_seed = int(seed)
        return [self._episode_seed]

    # Helpers
    def _decode_action(self, action: int) -> Tuple[int, int]:
        if not (0 <= action < self.action_space.n):
            raise ValueError(f"Invalid action {action}")
        if self.include_noop and action == self._noop_action:
            raise ValueError("_decode_action called on noop action")
        robot_id = action // 4
        direction = action % 4
        if robot_id >= self.num_robots:
            raise ValueError(f"Invalid robot_id {robot_id} for action {action}")
        return robot_id, direction

    def _make_obs(self, board: Board) -> np.ndarray:
        if self.obs_mode == "image":
            return self._board_to_image_obs(board)
        return self._board_to_symbolic_obs(board)

    def _board_to_image_obs(self, board: Board) -> np.ndarray:
        h, w = board.height, board.width
        C = self._num_channels
        obs = np.zeros((h, w, C), dtype=np.float32)
        # wall channels 0..3 from cache
        if self._cached_wall_obs is not None:
            obs[:, :, 0:4] = self._cached_wall_obs
        else:
            # Fallback if cache not built (should not happen)
            for r in range(h):
                for c in range(w):
                    obs[r, c, 0] = 1.0 if board.has_wall_up(r, c) else 0.0
                    obs[r, c, 1] = 1.0 if board.has_wall_down(r, c) else 0.0
                    obs[r, c, 2] = 1.0 if board.has_wall_left(r, c) else 0.0
                    obs[r, c, 3] = 1.0 if board.has_wall_right(r, c) else 0.0
        # goal channel 4
        gr, gc = board.goal_position
        obs[gr, gc, 4] = 1.0
        # target mask channel 5
        tr = board.target_robot
        tr_r, tr_c = board.robot_positions[tr]
        obs[tr_r, tr_c, 5] = 1.0
        # robot channels start at 6
        base = 6
        for rid, (r, c) in board.robot_positions.items():
            obs[r, c, base + rid] = 1.0
        if self.channels_first:
            obs = np.transpose(obs, (2, 0, 1))
        return obs

    def _board_to_symbolic_obs(self, board: Board) -> np.ndarray:
        gr, gc = board.goal_position
        target_one_hot = np.zeros((self.num_robots,), dtype=np.float32)
        target_one_hot[board.target_robot] = 1.0
        robots_vec: List[float] = []
        for rid in range(self.num_robots):
            r, c = board.robot_positions[rid]
            robots_vec.extend([float(r), float(c)])
        vec = np.concatenate([
            np.array([float(gr), float(gc)], dtype=np.float32),
            target_one_hot.astype(np.float32),
            np.array(robots_vec, dtype=np.float32),
        ])
        return vec

    def _generate_random_board(self) -> Board:
        h, w = self.height, self.width
        # Start with open grid, then add random interior edge walls, and border walls
        h_walls = np.zeros((h + 1, w), dtype=bool)
        v_walls = np.zeros((h, w + 1), dtype=bool)
        # Borders
        h_walls[0, :] = True
        h_walls[h, :] = True
        v_walls[:, 0] = True
        v_walls[:, w] = True
        # Random interior edges
        max_edges = max(1, (h * w) // 6)
        num_edges = int(self.np_random.integers(0, max_edges))
        for _ in range(num_edges):
            if self.np_random.integers(0, 2) == 0:
                rr = int(self.np_random.integers(1, h))
                cc = int(self.np_random.integers(0, w))
                h_walls[rr, cc] = True
            else:
                rr = int(self.np_random.integers(0, h))
                cc = int(self.np_random.integers(1, w))
                v_walls[rr, cc] = True
        # Place goal and robots in free cells
        free_cells: List[Tuple[int, int]] = [(r, c) for r in range(h) for c in range(w)]
        self.np_random.shuffle(free_cells)
        goal = free_cells.pop()
        robot_positions: Dict[int, Tuple[int, int]] = {}
        for rid in range(self.num_robots):
            robot_positions[rid] = free_cells.pop()
        target_robot = int(self.np_random.integers(0, self.num_robots))
        return Board(height=h, width=w, h_walls=h_walls, v_walls=v_walls, robot_positions=robot_positions, goal_position=goal, target_robot=target_robot)

    # Public channel names for image observations
    @property
    def channel_names(self) -> List[str]:
        names = ["wall_up", "wall_down", "wall_left", "wall_right", "goal", "target_robot_mask"]
        names.extend([f"robot_{i}" for i in range(self.num_robots)])
        return names

    def _build_cached_walls(self, board: Board) -> None:
        """Precompute static wall indicator channels (H,W,4)."""
        h, w = board.height, board.width
        wall = np.zeros((h, w, 4), dtype=np.float32)
        for r in range(h):
            for c in range(w):
                wall[r, c, 0] = 1.0 if board.has_wall_up(r, c) else 0.0
                wall[r, c, 1] = 1.0 if board.has_wall_down(r, c) else 0.0
                wall[r, c, 2] = 1.0 if board.has_wall_left(r, c) else 0.0
                wall[r, c, 3] = 1.0 if board.has_wall_right(r, c) else 0.0
        self._cached_wall_obs = wall


# Optional helper for registration with gymnasium
def register_env(env_id: str = "RicochetRobots-v0") -> None:
    """Register this environment with gymnasium so it can be created via gym.make(env_id)."""
    try:
        import gymnasium as gym  # type: ignore
        from gymnasium.envs.registration import register  # type: ignore
        # Avoid double registration
        if env_id in gym.registry:  # type: ignore[attr-defined]
            return
        register(
            id=env_id,
            entry_point="env.ricochet_env:RicochetRobotsEnv",
        )
    except Exception:
        # Silently ignore if gymnasium not available
        pass

```

```markdown
# Ricochet Robots RL Environment (Step 1)

This repository contains a custom Gymnasium-compatible environment for the Ricochet Robots puzzle, a BFS solver for validation/curriculum, and unit tests.

## Setup

Install dependencies:

```bash
pip install -r requirements.txt
```

## Run Tests

```bash
pytest -q
```

## Usage Example

```python
from env.ricochet_env import RicochetRobotsEnv

env = RicochetRobotsEnv(height=8, width=8, num_robots=2, render_mode="ascii")
obs, info = env.reset(seed=123)
action = 0  # robot 0 up
obs, reward, terminated, truncated, info = env.step(action)
print(env.render())
```

### Gymnasium Registration (optional)

To create the env via gym.make:

```python
import gymnasium as gym
from env.ricochet_env import register_env

register_env("RicochetRobots-v0")
env = gym.make("RicochetRobots-v0", height=8, width=8, num_robots=2, render_mode="ascii")
```

### Notes on API compliance

- Seeding follows Gymnasium: use `reset(seed=...)`. The used seed is provided in `info["episode_seed"]`.
- Rendering uses `render_mode`. With `render_mode="ascii"`, `render()` returns a string; otherwise it returns `None`.
- The `info` dict includes `is_success` each step, and `TimeLimit.truncated` when the episode hits `max_steps`.

```

```python
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple, List, Literal

import numpy as np

from .ricochet_core import Board, apply_action, reached_goal

# Provide a runtime gymnasium binding if available, otherwise a minimal fallback
try:  # pragma: no cover
    import importlib
    _gym = importlib.import_module("gymnasium")  # type: ignore
    _spaces = importlib.import_module("gymnasium.spaces")  # type: ignore
    _seeding = importlib.import_module("gymnasium.utils.seeding")  # type: ignore
    GymEnvBase = _gym.Env  # type: ignore
    spaces = _spaces  # type: ignore
except Exception:  # pragma: no cover
    class GymEnvBase(object):
        pass
    class _SpacesDummy:  # minimal placeholders to satisfy type usage
        class Box:  # type: ignore
            def __init__(self, low=None, high=None, shape=None, dtype=None):
                self.low = low
                self.high = high
                self.shape = shape
                self.dtype = dtype
        class Discrete:  # type: ignore
            def __init__(self, n: int):
                self.n = n
    spaces = _SpacesDummy()  # type: ignore


@dataclass
class FixedLayout:
    height: int
    width: int
    # Edge walls
    h_walls: np.ndarray  # (H+1, W) bool
    v_walls: np.ndarray  # (H, W+1) bool
    robot_positions: Dict[int, Tuple[int, int]]
    goal_position: Tuple[int, int]
    target_robot: int


ObsMode = Literal["image", "symbolic"]


class RicochetRobotsEnv(GymEnvBase):
    metadata = {"render_modes": ["ascii"], "render_fps": 4}

    def __init__(
        self,
        height: int = 8,
        width: int = 8,
        num_robots: int = 2,
        include_noop: bool = True,
        step_penalty: float = -0.01,
        goal_reward: float = 1.0,
        noop_penalty: Optional[float] = None,
        max_steps: int = 100,
        fixed_layout: Optional[FixedLayout] = None,
        seed: Optional[int] = None,
        ensure_solvable: bool = False,
        solver_max_depth: int = 30,
        solver_max_nodes: int = 20000,
        obs_mode: ObsMode = "image",
        channels_first: bool = False,
        render_mode: Optional[str] = None,
    ) -> None:
        super().__init__()
        self.height = height
        self.width = width
        self.num_robots = num_robots
        self.include_noop = include_noop
        self.step_penalty = step_penalty
        self.goal_reward = goal_reward
        self.noop_penalty = step_penalty if noop_penalty is None else noop_penalty
        self.max_steps = max_steps
        self.fixed_layout = fixed_layout
        self.ensure_solvable = ensure_solvable
        self.solver_max_depth = solver_max_depth
        self.solver_max_nodes = solver_max_nodes
        self.obs_mode: ObsMode = obs_mode
        self.channels_first = channels_first
        # Render API
        self.render_mode = render_mode
        if self.render_mode is not None and self.render_mode not in self.metadata["render_modes"]:
            raise ValueError(f"Unsupported render_mode {self.render_mode}. Supported: {self.metadata['render_modes']}")

        # Seeding: adopt Gymnasium convention with self.np_random
        self.np_random: np.random.Generator
        self._episode_seed: Optional[int] = None
        try:  # gymnasium present
            # _seeding.np_random returns (rng, seed)
            self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
            self._episode_seed = int(used_seed) if used_seed is not None else None
        except Exception:
            self.np_random = np.random.default_rng(seed)
            self._episode_seed = int(seed) if seed is not None else None
        self._board: Optional[Board] = None
        self._num_steps = 0
        self._cached_wall_obs: Optional[np.ndarray] = None  # (H,W,4) float32 for wall channels

        # Observation spaces
        if self.obs_mode == "image":
            # channels: up_wall, down_wall, left_wall, right_wall, goal, target_mask, robots...
            self._base_wall_channels = 4
            self._base_misc_channels = 2  # goal, target
            self._num_channels = self._base_wall_channels + self._base_misc_channels + self.num_robots
            if self.channels_first:
                obs_shape = (self._num_channels, self.height, self.width)
            else:
                obs_shape = (self.height, self.width, self._num_channels)
            self.observation_space = spaces.Box(
                low=0.0,
                high=1.0,
                shape=obs_shape,
                dtype=np.float32,
            )
        elif self.obs_mode == "symbolic":
            # [goal_r, goal_c] in [0..H-1], [0..W-1]; one-hot target in [0,1]; robots positions in bounds
            vec_len = 2 + self.num_robots + (self.num_robots * 2)
            low = np.full((vec_len,), 0.0, dtype=np.float32)
            high = np.full((vec_len,), 1.0, dtype=np.float32)
            # goal bounds
            low[0] = 0.0
            high[0] = float(self.height - 1)
            low[1] = 0.0
            high[1] = float(self.width - 1)
            # target one-hot already [0,1]
            # robots positions
            base = 2 + self.num_robots
            for i in range(self.num_robots):
                low[base + 2 * i] = 0.0
                high[base + 2 * i] = float(self.height - 1)
                low[base + 2 * i + 1] = 0.0
                high[base + 2 * i + 1] = float(self.width - 1)
            self.observation_space = spaces.Box(low=low, high=high, shape=(vec_len,), dtype=np.float32)
        else:
            raise ValueError(f"Unknown obs_mode: {self.obs_mode}")

        # Action space: num_robots * 4 directions (+ 1 for noop)
        self._noop_action = self.num_robots * 4 if include_noop else None
        self.action_space = spaces.Discrete(self.num_robots * 4 + (1 if include_noop else 0))

    # Gymnasium API
    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):
        """Reset the environment and start a new episode.

        Returns (obs, info) per Gymnasium API. info contains keys: 'target_robot',
        'level_solvable' (optional), 'optimal_length' (if ensured), 'solver_limits' (if ensured),
        and 'episode_seed' with the seed used for this episode.
        """
        # Standard seeding protocol
        if seed is not None:
            try:
                self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
                self._episode_seed = int(used_seed) if used_seed is not None else None
            except Exception:
                self.np_random = np.random.default_rng(seed)
                self._episode_seed = int(seed)
        _ = options  # silence unused
        self._num_steps = 0

        if self.fixed_layout is not None:
            self._board = Board(
                height=self.fixed_layout.height,
                width=self.fixed_layout.width,
                h_walls=self.fixed_layout.h_walls.copy(),
                v_walls=self.fixed_layout.v_walls.copy(),
                robot_positions=dict(self.fixed_layout.robot_positions),
                goal_position=self.fixed_layout.goal_position,
                target_robot=self.fixed_layout.target_robot,
            )
            # cache static walls for this layout
            self._build_cached_walls(self._board)
            obs = self._make_obs(self._board)
            info = {"level_solvable": None, "target_robot": self._board.target_robot, "episode_seed": self._episode_seed}
            return obs, info

        # Otherwise, generate random board, optionally ensure solvable via solver
        attempts = 0
        while True:
            attempts += 1
            board = self._generate_random_board()
            if not self.ensure_solvable:
                self._board = board
                break
            try:
                from .solver import solve_bfs  # type: ignore
                solution = solve_bfs(board, max_depth=self.solver_max_depth, max_nodes=self.solver_max_nodes)
                if solution is not None:
                    self._board = board
                    optimal_length = len(solution)
                    break
            except ImportError as exc:
                raise RuntimeError("ensure_solvable=True but solver unavailable (ImportError)") from exc
            if attempts >= 50:
                raise RuntimeError("Failed to generate solvable board within attempt limit")

        # cache static walls for this layout
        assert self._board is not None
        self._build_cached_walls(self._board)
        obs = self._make_obs(self._board)
        # Note: solver None during attempts may be due to cutoffs (depth/nodes), not true unsolvability.
        info = {"level_solvable": True if self.ensure_solvable else None, "target_robot": self._board.target_robot, "episode_seed": self._episode_seed}
        if self.ensure_solvable:
            info["optimal_length"] = optimal_length
            info["solver_limits"] = {"max_depth": self.solver_max_depth, "max_nodes": self.solver_max_nodes}
        return obs, info

    def step(self, action: int):
        """Apply an action and return (obs, reward, terminated, truncated, info).

        info always includes 'steps', 'target_robot', and 'is_success' (bool). When truncated due to
        max steps, info includes 'TimeLimit.truncated'=True.
        """
        assert self._board is not None, "Call reset() first"
        self._num_steps += 1

        terminated = False
        truncated = False
        info: Dict[str, object] = {}

        reward = self.step_penalty
        # Validate action range early
        if not (0 <= action < self.action_space.n):
            raise ValueError(f"Invalid action {action}")

        if self.include_noop and action == self._noop_action:
            reward = self.noop_penalty
        else:
            robot_id, direction = self._decode_action(action)
            self._board = apply_action(self._board, robot_id, direction)

        if reached_goal(self._board):
            reward += self.goal_reward
            terminated = True
            info["success"] = True
            info["is_success"] = True

        if not terminated and self._num_steps >= self.max_steps:
            truncated = True
            info["TimeLimit.truncated"] = True

        obs = self._make_obs(self._board)
        info["steps"] = self._num_steps
        info["target_robot"] = self._board.target_robot
        if "is_success" not in info:
            info["is_success"] = False
        return obs, reward, terminated, truncated, info

    def render(self):
        """Render according to render_mode.

        - render_mode=="ascii": returns a string frame.
        - render_mode is None or unsupported: returns None.
        """
        if self.render_mode != "ascii":
            return None
        if self._board is None:
            return ""
        from .ricochet_core import render_ascii  # local import to avoid circulars in lints
        return render_ascii(self._board)

    def close(self) -> None:
        """Close environment resources (no-op)."""
        return None

    def seed(self, seed: Optional[int] = None):  # legacy convenience
        """Legacy seeding helper returning [seed]. Prefer reset(seed=...)."""
        if seed is None:
            return [self._episode_seed]
        try:
            self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
            self._episode_seed = int(used_seed) if used_seed is not None else int(seed)
        except Exception:
            self.np_random = np.random.default_rng(seed)
            self._episode_seed = int(seed)
        return [self._episode_seed]

    # Helpers
    def _decode_action(self, action: int) -> Tuple[int, int]:
        if not (0 <= action < self.action_space.n):
            raise ValueError(f"Invalid action {action}")
        if self.include_noop and action == self._noop_action:
            raise ValueError("_decode_action called on noop action")
        robot_id = action // 4
        direction = action % 4
        if robot_id >= self.num_robots:
            raise ValueError(f"Invalid robot_id {robot_id} for action {action}")
        return robot_id, direction

    def _make_obs(self, board: Board) -> np.ndarray:
        if self.obs_mode == "image":
            return self._board_to_image_obs(board)
        return self._board_to_symbolic_obs(board)

    def _board_to_image_obs(self, board: Board) -> np.ndarray:
        h, w = board.height, board.width
        C = self._num_channels
        obs = np.zeros((h, w, C), dtype=np.float32)
        # wall channels 0..3 from cache
        if self._cached_wall_obs is not None:
            obs[:, :, 0:4] = self._cached_wall_obs
        else:
            # Fallback if cache not built (should not happen)
            for r in range(h):
                for c in range(w):
                    obs[r, c, 0] = 1.0 if board.has_wall_up(r, c) else 0.0
                    obs[r, c, 1] = 1.0 if board.has_wall_down(r, c) else 0.0
                    obs[r, c, 2] = 1.0 if board.has_wall_left(r, c) else 0.0
                    obs[r, c, 3] = 1.0 if board.has_wall_right(r, c) else 0.0
        # goal channel 4
        gr, gc = board.goal_position
        obs[gr, gc, 4] = 1.0
        # target mask channel 5
        tr = board.target_robot
        tr_r, tr_c = board.robot_positions[tr]
        obs[tr_r, tr_c, 5] = 1.0
        # robot channels start at 6
        base = 6
        for rid, (r, c) in board.robot_positions.items():
            obs[r, c, base + rid] = 1.0
        if self.channels_first:
            obs = np.transpose(obs, (2, 0, 1))
        return obs

    def _board_to_symbolic_obs(self, board: Board) -> np.ndarray:
        gr, gc = board.goal_position
        target_one_hot = np.zeros((self.num_robots,), dtype=np.float32)
        target_one_hot[board.target_robot] = 1.0
        robots_vec: List[float] = []
        for rid in range(self.num_robots):
            r, c = board.robot_positions[rid]
            robots_vec.extend([float(r), float(c)])
        vec = np.concatenate([
            np.array([float(gr), float(gc)], dtype=np.float32),
            target_one_hot.astype(np.float32),
            np.array(robots_vec, dtype=np.float32),
        ])
        return vec

    def _generate_random_board(self) -> Board:
        h, w = self.height, self.width
        # Start with open grid, then add random interior edge walls, and border walls
        h_walls = np.zeros((h + 1, w), dtype=bool)
        v_walls = np.zeros((h, w + 1), dtype=bool)
        # Borders
        h_walls[0, :] = True
        h_walls[h, :] = True
        v_walls[:, 0] = True
        v_walls[:, w] = True
        # Random interior edges
        max_edges = max(1, (h * w) // 6)
        num_edges = int(self.np_random.integers(0, max_edges))
        for _ in range(num_edges):
            if self.np_random.integers(0, 2) == 0:
                rr = int(self.np_random.integers(1, h))
                cc = int(self.np_random.integers(0, w))
                h_walls[rr, cc] = True
            else:
                rr = int(self.np_random.integers(0, h))
                cc = int(self.np_random.integers(1, w))
                v_walls[rr, cc] = True
        # Place goal and robots in free cells
        free_cells: List[Tuple[int, int]] = [(r, c) for r in range(h) for c in range(w)]
        self.np_random.shuffle(free_cells)
        goal = free_cells.pop()
        robot_positions: Dict[int, Tuple[int, int]] = {}
        for rid in range(self.num_robots):
            robot_positions[rid] = free_cells.pop()
        target_robot = int(self.np_random.integers(0, self.num_robots))
        return Board(height=h, width=w, h_walls=h_walls, v_walls=v_walls, robot_positions=robot_positions, goal_position=goal, target_robot=target_robot)

    # Public channel names for image observations
    @property
    def channel_names(self) -> List[str]:
        """Human-readable names for image observation channels."""
        names = ["wall_up", "wall_down", "wall_left", "wall_right", "goal", "target_robot_mask"]
        names.extend([f"robot_{i}" for i in range(self.num_robots)])
        return names

    def _build_cached_walls(self, board: Board) -> None:
        """Precompute static wall indicator channels (H,W,4)."""
        h, w = board.height, board.width
        wall = np.zeros((h, w, 4), dtype=np.float32)
        for r in range(h):
            for c in range(w):
                wall[r, c, 0] = 1.0 if board.has_wall_up(r, c) else 0.0
                wall[r, c, 1] = 1.0 if board.has_wall_down(r, c) else 0.0
                wall[r, c, 2] = 1.0 if board.has_wall_left(r, c) else 0.0
                wall[r, c, 3] = 1.0 if board.has_wall_right(r, c) else 0.0
        self._cached_wall_obs = wall


# Optional helper for registration with gymnasium
def register_env(env_id: str = "RicochetRobots-v0") -> None:
    """Register this environment with gymnasium so it can be created via gym.make(env_id)."""
    try:
        import gymnasium as gym  # type: ignore
        from gymnasium.envs.registration import register  # type: ignore
        # Avoid double registration
        if env_id in gym.registry:  # type: ignore[attr-defined]
            return
        register(
            id=env_id,
            entry_point="env.ricochet_env:RicochetRobotsEnv",
        )
    except Exception:
        # Silently ignore if gymnasium not available
        pass

```

```python
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple, List, Literal

import numpy as np

from .ricochet_core import Board, apply_action, reached_goal

# Provide a runtime gymnasium binding if available, otherwise a minimal fallback
try:  # pragma: no cover
    import importlib
    _gym = importlib.import_module("gymnasium")  # type: ignore
    _spaces = importlib.import_module("gymnasium.spaces")  # type: ignore
    _seeding = importlib.import_module("gymnasium.utils.seeding")  # type: ignore
    GymEnvBase = _gym.Env  # type: ignore
    spaces = _spaces  # type: ignore
except (ModuleNotFoundError, ImportError):  # pragma: no cover
    class GymEnvBase(object):
        pass
    class _SpacesDummy:  # minimal placeholders to satisfy type usage
        class Box:  # type: ignore
            def __init__(self, low=None, high=None, shape=None, dtype=None):
                self.low = low
                self.high = high
                self.shape = shape
                self.dtype = dtype
        class Discrete:  # type: ignore
            def __init__(self, n: int):
                self.n = n
    spaces = _SpacesDummy()  # type: ignore


@dataclass
class FixedLayout:
    height: int
    width: int
    # Edge walls
    h_walls: np.ndarray  # (H+1, W) bool
    v_walls: np.ndarray  # (H, W+1) bool
    robot_positions: Dict[int, Tuple[int, int]]
    goal_position: Tuple[int, int]
    target_robot: int


ObsMode = Literal["image", "symbolic"]


class RicochetRobotsEnv(GymEnvBase):
    metadata = {"render_modes": ["ascii"], "render_fps": 4}

    def __init__(
        self,
        height: int = 8,
        width: int = 8,
        num_robots: int = 2,
        include_noop: bool = True,
        step_penalty: float = -0.01,
        goal_reward: float = 1.0,
        noop_penalty: Optional[float] = None,
        max_steps: int = 100,
        fixed_layout: Optional[FixedLayout] = None,
        seed: Optional[int] = None,
        ensure_solvable: bool = False,
        solver_max_depth: int = 30,
        solver_max_nodes: int = 20000,
        obs_mode: ObsMode = "image",
        channels_first: bool = False,
        render_mode: Optional[str] = None,
    ) -> None:
        super().__init__()
        self.height = height
        self.width = width
        self.num_robots = num_robots
        self.include_noop = include_noop
        self.step_penalty = step_penalty
        self.goal_reward = goal_reward
        self.noop_penalty = step_penalty if noop_penalty is None else noop_penalty
        self.max_steps = max_steps
        self.fixed_layout = fixed_layout
        self.ensure_solvable = ensure_solvable
        self.solver_max_depth = solver_max_depth
        self.solver_max_nodes = solver_max_nodes
        self.obs_mode: ObsMode = obs_mode
        self.channels_first = channels_first
        # Render API
        self.render_mode = render_mode
        if self.render_mode is not None and self.render_mode not in self.metadata["render_modes"]:
            raise ValueError(f"Unsupported render_mode {self.render_mode}. Supported: {self.metadata['render_modes']}")

        # Seeding: adopt Gymnasium convention with self.np_random
        self.np_random: np.random.Generator
        self._episode_seed: Optional[int] = None
        try:  # gymnasium present
            # _seeding.np_random returns (rng, seed)
            self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
            self._episode_seed = int(used_seed) if used_seed is not None else None
        except NameError:
            self.np_random = np.random.default_rng(seed)
            self._episode_seed = int(seed) if seed is not None else None
        self._board: Optional[Board] = None
        self._num_steps = 0
        self._cached_wall_obs: Optional[np.ndarray] = None  # (H,W,4) float32 for wall channels

        # Observation spaces
        if self.obs_mode == "image":
            # channels: up_wall, down_wall, left_wall, right_wall, goal, target_mask, robots...
            self._base_wall_channels = 4
            self._base_misc_channels = 2  # goal, target
            self._num_channels = self._base_wall_channels + self._base_misc_channels + self.num_robots
            if self.channels_first:
                obs_shape = (self._num_channels, self.height, self.width)
            else:
                obs_shape = (self.height, self.width, self._num_channels)
            self.observation_space = spaces.Box(
                low=0.0,
                high=1.0,
                shape=obs_shape,
                dtype=np.float32,
            )
        elif self.obs_mode == "symbolic":
            # [goal_r, goal_c] in [0..H-1], [0..W-1]; one-hot target in [0,1]; robots positions in bounds
            vec_len = 2 + self.num_robots + (self.num_robots * 2)
            low = np.full((vec_len,), 0.0, dtype=np.float32)
            high = np.full((vec_len,), 1.0, dtype=np.float32)
            # goal bounds
            low[0] = 0.0
            high[0] = float(self.height - 1)
            low[1] = 0.0
            high[1] = float(self.width - 1)
            # target one-hot already [0,1]
            # robots positions
            base = 2 + self.num_robots
            for i in range(self.num_robots):
                low[base + 2 * i] = 0.0
                high[base + 2 * i] = float(self.height - 1)
                low[base + 2 * i + 1] = 0.0
                high[base + 2 * i + 1] = float(self.width - 1)
            self.observation_space = spaces.Box(low=low, high=high, shape=(vec_len,), dtype=np.float32)
        else:
            raise ValueError(f"Unknown obs_mode: {self.obs_mode}")

        # Action space: num_robots * 4 directions (+ 1 for noop)
        self._noop_action = self.num_robots * 4 if include_noop else None
        self.action_space = spaces.Discrete(self.num_robots * 4 + (1 if include_noop else 0))

    # Gymnasium API
    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):
        """Reset the environment and start a new episode.

        Returns (obs, info) per Gymnasium API. info contains keys: 'target_robot',
        'level_solvable' (optional), 'optimal_length' (if ensured), 'solver_limits' (if ensured),
        and 'episode_seed' with the seed used for this episode.
        """
        # Standard seeding protocol
        if seed is not None:
            try:
                self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
                self._episode_seed = int(used_seed) if used_seed is not None else None
            except NameError:
                self.np_random = np.random.default_rng(seed)
                self._episode_seed = int(seed)
        _ = options  # silence unused
        self._num_steps = 0

        if self.fixed_layout is not None:
            self._board = Board(
                height=self.fixed_layout.height,
                width=self.fixed_layout.width,
                h_walls=self.fixed_layout.h_walls.copy(),
                v_walls=self.fixed_layout.v_walls.copy(),
                robot_positions=dict(self.fixed_layout.robot_positions),
                goal_position=self.fixed_layout.goal_position,
                target_robot=self.fixed_layout.target_robot,
            )
            # cache static walls for this layout
            self._build_cached_walls(self._board)
            obs = self._make_obs(self._board)
            info = {"level_solvable": None, "target_robot": self._board.target_robot, "episode_seed": self._episode_seed}
            return obs, info

        # Otherwise, generate random board, optionally ensure solvable via solver
        attempts = 0
        while True:
            attempts += 1
            board = self._generate_random_board()
            if not self.ensure_solvable:
                self._board = board
                break
            try:
                from .solver import solve_bfs  # type: ignore
                solution = solve_bfs(board, max_depth=self.solver_max_depth, max_nodes=self.solver_max_nodes)
                if solution is not None:
                    self._board = board
                    optimal_length = len(solution)
                    break
            except ImportError as exc:
                raise RuntimeError("ensure_solvable=True but solver unavailable (ImportError)") from exc
            if attempts >= 50:
                raise RuntimeError("Failed to generate solvable board within attempt limit")

        # cache static walls for this layout
        assert self._board is not None
        self._build_cached_walls(self._board)
        obs = self._make_obs(self._board)
        # Note: solver None during attempts may be due to cutoffs (depth/nodes), not true unsolvability.
        info = {"level_solvable": True if self.ensure_solvable else None, "target_robot": self._board.target_robot, "episode_seed": self._episode_seed}
        if self.ensure_solvable:
            info["optimal_length"] = optimal_length
            info["solver_limits"] = {"max_depth": self.solver_max_depth, "max_nodes": self.solver_max_nodes}
        return obs, info

    def step(self, action: int):
        """Apply an action and return (obs, reward, terminated, truncated, info).

        info always includes 'steps', 'target_robot', and 'is_success' (bool). When truncated due to
        max steps, info includes 'TimeLimit.truncated'=True.
        """
        assert self._board is not None, "Call reset() first"
        self._num_steps += 1

        terminated = False
        truncated = False
        info: Dict[str, object] = {}

        reward = self.step_penalty
        # Validate action range early
        if not (0 <= action < self.action_space.n):
            raise ValueError(f"Invalid action {action}")

        if self.include_noop and action == self._noop_action:
            reward = self.noop_penalty
        else:
            robot_id, direction = self._decode_action(action)
            self._board = apply_action(self._board, robot_id, direction)

        if reached_goal(self._board):
            reward += self.goal_reward
            terminated = True
            info["success"] = True
            info["is_success"] = True

        if not terminated and self._num_steps >= self.max_steps:
            truncated = True
            info["TimeLimit.truncated"] = True

        obs = self._make_obs(self._board)
        info["steps"] = self._num_steps
        info["target_robot"] = self._board.target_robot
        if "is_success" not in info:
            info["is_success"] = False
        return obs, reward, terminated, truncated, info

    def render(self):
        """Render according to render_mode.

        - render_mode=="ascii": returns a string frame.
        - render_mode is None or unsupported: returns None.
        """
        if self.render_mode != "ascii":
            return None
        if self._board is None:
            return ""
        from .ricochet_core import render_ascii  # local import to avoid circulars in lints
        return render_ascii(self._board)

    def close(self) -> None:
        """Close environment resources (no-op)."""
        return None

    def seed(self, seed: Optional[int] = None):  # legacy convenience
        """Legacy seeding helper returning [seed]. Prefer reset(seed=...)."""
        if seed is None:
            return [self._episode_seed]
        try:
            self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
            self._episode_seed = int(used_seed) if used_seed is not None else int(seed)
        except NameError:
            self.np_random = np.random.default_rng(seed)
            self._episode_seed = int(seed)
        return [self._episode_seed]

    # Helpers
    def _decode_action(self, action: int) -> Tuple[int, int]:
        if not (0 <= action < self.action_space.n):
            raise ValueError(f"Invalid action {action}")
        if self.include_noop and action == self._noop_action:
            raise ValueError("_decode_action called on noop action")
        robot_id = action // 4
        direction = action % 4
        if robot_id >= self.num_robots:
            raise ValueError(f"Invalid robot_id {robot_id} for action {action}")
        return robot_id, direction

    def _make_obs(self, board: Board) -> np.ndarray:
        if self.obs_mode == "image":
            return self._board_to_image_obs(board)
        return self._board_to_symbolic_obs(board)

    def _board_to_image_obs(self, board: Board) -> np.ndarray:
        h, w = board.height, board.width
        C = self._num_channels
        obs = np.zeros((h, w, C), dtype=np.float32)
        # wall channels 0..3 from cache
        if self._cached_wall_obs is not None:
            obs[:, :, 0:4] = self._cached_wall_obs
        else:
            # Fallback if cache not built (should not happen)
            for r in range(h):
                for c in range(w):
                    obs[r, c, 0] = 1.0 if board.has_wall_up(r, c) else 0.0
                    obs[r, c, 1] = 1.0 if board.has_wall_down(r, c) else 0.0
                    obs[r, c, 2] = 1.0 if board.has_wall_left(r, c) else 0.0
                    obs[r, c, 3] = 1.0 if board.has_wall_right(r, c) else 0.0
        # goal channel 4
        gr, gc = board.goal_position
        obs[gr, gc, 4] = 1.0
        # target mask channel 5
        tr = board.target_robot
        tr_r, tr_c = board.robot_positions[tr]
        obs[tr_r, tr_c, 5] = 1.0
        # robot channels start at 6
        base = 6
        for rid, (r, c) in board.robot_positions.items():
            obs[r, c, base + rid] = 1.0
        if self.channels_first:
            obs = np.transpose(obs, (2, 0, 1))
        return obs

    def _board_to_symbolic_obs(self, board: Board) -> np.ndarray:
        gr, gc = board.goal_position
        target_one_hot = np.zeros((self.num_robots,), dtype=np.float32)
        target_one_hot[board.target_robot] = 1.0
        robots_vec: List[float] = []
        for rid in range(self.num_robots):
            r, c = board.robot_positions[rid]
            robots_vec.extend([float(r), float(c)])
        vec = np.concatenate([
            np.array([float(gr), float(gc)], dtype=np.float32),
            target_one_hot.astype(np.float32),
            np.array(robots_vec, dtype=np.float32),
        ])
        return vec

    def _generate_random_board(self) -> Board:
        h, w = self.height, self.width
        # Start with open grid, then add random interior edge walls, and border walls
        h_walls = np.zeros((h + 1, w), dtype=bool)
        v_walls = np.zeros((h, w + 1), dtype=bool)
        # Borders
        h_walls[0, :] = True
        h_walls[h, :] = True
        v_walls[:, 0] = True
        v_walls[:, w] = True
        # Random interior edges
        max_edges = max(1, (h * w) // 6)
        num_edges = int(self.np_random.integers(0, max_edges))
        for _ in range(num_edges):
            if self.np_random.integers(0, 2) == 0:
                rr = int(self.np_random.integers(1, h))
                cc = int(self.np_random.integers(0, w))
                h_walls[rr, cc] = True
            else:
                rr = int(self.np_random.integers(0, h))
                cc = int(self.np_random.integers(1, w))
                v_walls[rr, cc] = True
        # Place goal and robots in free cells
        free_cells: List[Tuple[int, int]] = [(r, c) for r in range(h) for c in range(w)]
        self.np_random.shuffle(free_cells)
        goal = free_cells.pop()
        robot_positions: Dict[int, Tuple[int, int]] = {}
        for rid in range(self.num_robots):
            robot_positions[rid] = free_cells.pop()
        target_robot = int(self.np_random.integers(0, self.num_robots))
        return Board(height=h, width=w, h_walls=h_walls, v_walls=v_walls, robot_positions=robot_positions, goal_position=goal, target_robot=target_robot)

    # Public channel names for image observations
    @property
    def channel_names(self) -> List[str]:
        """Human-readable names for image observation channels."""
        names = ["wall_up", "wall_down", "wall_left", "wall_right", "goal", "target_robot_mask"]
        names.extend([f"robot_{i}" for i in range(self.num_robots)])
        return names

    def _build_cached_walls(self, board: Board) -> None:
        """Precompute static wall indicator channels (H,W,4)."""
        h, w = board.height, board.width
        wall = np.zeros((h, w, 4), dtype=np.float32)
        for r in range(h):
            for c in range(w):
                wall[r, c, 0] = 1.0 if board.has_wall_up(r, c) else 0.0
                wall[r, c, 1] = 1.0 if board.has_wall_down(r, c) else 0.0
                wall[r, c, 2] = 1.0 if board.has_wall_left(r, c) else 0.0
                wall[r, c, 3] = 1.0 if board.has_wall_right(r, c) else 0.0
        self._cached_wall_obs = wall


# Optional helper for registration with gymnasium
def register_env(env_id: str = "RicochetRobots-v0") -> None:
    """Register this environment with gymnasium so it can be created via gym.make(env_id)."""
    try:
        import gymnasium as gym  # type: ignore
        from gymnasium.envs.registration import register  # type: ignore
        # Avoid double registration
        if env_id in gym.registry:  # type: ignore[attr-defined]
            return
        register(
            id=env_id,
            entry_point="env.ricochet_env:RicochetRobotsEnv",
        )
    except (ModuleNotFoundError, ImportError):
        # Silently ignore if gymnasium not available
        pass

```

- I read the research plan and the feedback, then implemented the API and behavior changes directly in the environment.

- I'll now summarize the edits and impact, and this should fully address the Step 1.3 feedback points you highlighted.

What I changed:
- Gymnasium seeding protocol
  - Added `self.np_random` using Gymnasiums `np_random`; episode seed exposed via `info["episode_seed"]`.
  - `reset(seed=...)` updates `np_random` correctly; provided legacy `seed()` helper.

- Render API compliance
  - Added `render_mode` parameter with validation against `metadata["render_modes"]`.
  - `render()` returns a string only when `render_mode="ascii"`, otherwise returns `None`.

- Close and seed helpers
  - Implemented `close()` (no-op) and a legacy `seed()` that returns `[seed]`.

- Observation space tightening
  - Symbolic mode now uses finite bounds reflecting board dimensions and one-hot ranges.

- Performance optimization
  - Cached static wall channels at reset via `_build_cached_walls`; image obs reuses them each step.

- Step validation and info consistency
  - Early action range validation in `step()`.
  - Always include `info["is_success"]`; add `info["TimeLimit.truncated"]` when applicable.

- Registration helper and docs
  - Added `register_env()` to allow `gym.make("RicochetRobots-v0", ...)`.
  - Updated `README.md` with `render_mode`, seeding usage, and registration snippet.

- Docstrings and channel mapping
  - Added succinct docstrings to `reset`, `step`, `render`, and a `channel_names` property for image channels.

Files touched:
- `env/ricochet_env.py`  render/seeding API, symbolic bounds, caching, info consistency, registration helper, docstrings.
- `README.md`  examples updated to use `render_mode="ascii"`, `reset(seed=...)`, registration instructions.

This addresses the bold/high-priority points: render API shape, Gymnasium seeding protocol, close/seed methods, optional registration, info consistency (is_success and TimeLimit), symbolic space bounds, performance cache, and channel semantics.

- All todos are checked off.

---

**User**

Great work, the code looks much better. Here is the next round of feedback for your updated files:



---

**Cursor**

I'll scan the tests to ensure changes like removing the "success" key won't break expectations, then implement the requested polish: fix registration duplicate guard, add clearer render error on unsupported modes, clear cached walls at reset start, optionally raise InvalidAction when Gymnasium is present, enhance docstrings, and minor README clarifications.

I'll implement the polish items: adjust the registration helper to swallow duplicate registration errors, improve render() error behavior on unsupported modes, clear cached walls at the start of reset, raise Gymnasium's InvalidAction when available, and update README notes. Then I'll run a quick lint check.

```python
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple, List, Literal

import numpy as np

from .ricochet_core import Board, apply_action, reached_goal

# Provide a runtime gymnasium binding if available, otherwise a minimal fallback
try:  # pragma: no cover
    import importlib
    _gym = importlib.import_module("gymnasium")  # type: ignore
    _spaces = importlib.import_module("gymnasium.spaces")  # type: ignore
    _seeding = importlib.import_module("gymnasium.utils.seeding")  # type: ignore
    _error = importlib.import_module("gymnasium.error")  # type: ignore
    GymEnvBase = _gym.Env  # type: ignore
    spaces = _spaces  # type: ignore
    GymInvalidAction = getattr(_error, "InvalidAction", None)  # type: ignore
except (ModuleNotFoundError, ImportError):  # pragma: no cover
    class GymEnvBase(object):
        pass
    class _SpacesDummy:  # minimal placeholders to satisfy type usage
        class Box:  # type: ignore
            def __init__(self, low=None, high=None, shape=None, dtype=None):
                self.low = low
                self.high = high
                self.shape = shape
                self.dtype = dtype
        class Discrete:  # type: ignore
            def __init__(self, n: int):
                self.n = n
    spaces = _SpacesDummy()  # type: ignore
    GymInvalidAction = None  # type: ignore


@dataclass
class FixedLayout:
    height: int
    width: int
    # Edge walls
    h_walls: np.ndarray  # (H+1, W) bool
    v_walls: np.ndarray  # (H, W+1) bool
    robot_positions: Dict[int, Tuple[int, int]]
    goal_position: Tuple[int, int]
    target_robot: int


ObsMode = Literal["image", "symbolic"]


class RicochetRobotsEnv(GymEnvBase):
    metadata = {"render_modes": ["ascii"], "render_fps": 4}

    def __init__(
        self,
        height: int = 8,
        width: int = 8,
        num_robots: int = 2,
        include_noop: bool = True,
        step_penalty: float = -0.01,
        goal_reward: float = 1.0,
        noop_penalty: Optional[float] = None,
        max_steps: int = 100,
        fixed_layout: Optional[FixedLayout] = None,
        seed: Optional[int] = None,
        ensure_solvable: bool = False,
        solver_max_depth: int = 30,
        solver_max_nodes: int = 20000,
        obs_mode: ObsMode = "image",
        channels_first: bool = False,
        render_mode: Optional[str] = None,
    ) -> None:
        super().__init__()
        self.height = height
        self.width = width
        self.num_robots = num_robots
        self.include_noop = include_noop
        self.step_penalty = step_penalty
        self.goal_reward = goal_reward
        self.noop_penalty = step_penalty if noop_penalty is None else noop_penalty
        self.max_steps = max_steps
        self.fixed_layout = fixed_layout
        self.ensure_solvable = ensure_solvable
        self.solver_max_depth = solver_max_depth
        self.solver_max_nodes = solver_max_nodes
        self.obs_mode: ObsMode = obs_mode
        self.channels_first = channels_first
        # Render API
        self.render_mode = render_mode
        if self.render_mode is not None and self.render_mode not in self.metadata["render_modes"]:
            raise ValueError(f"Unsupported render_mode {self.render_mode}. Supported: {self.metadata['render_modes']}")

        # Seeding: adopt Gymnasium convention with self.np_random
        self.np_random: np.random.Generator
        self._episode_seed: Optional[int] = None
        try:  # gymnasium present
            # _seeding.np_random returns (rng, seed)
            self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
            self._episode_seed = int(used_seed) if used_seed is not None else None
        except NameError:
            self.np_random = np.random.default_rng(seed)
            self._episode_seed = int(seed) if seed is not None else None
        self._board: Optional[Board] = None
        self._num_steps = 0
        self._cached_wall_obs: Optional[np.ndarray] = None  # (H,W,4) float32 for wall channels

        # Observation spaces
        if self.obs_mode == "image":
            # channels: up_wall, down_wall, left_wall, right_wall, goal, target_mask, robots...
            self._base_wall_channels = 4
            self._base_misc_channels = 2  # goal, target
            self._num_channels = self._base_wall_channels + self._base_misc_channels + self.num_robots
            if self.channels_first:
                obs_shape = (self._num_channels, self.height, self.width)
            else:
                obs_shape = (self.height, self.width, self._num_channels)
            self.observation_space = spaces.Box(
                low=0.0,
                high=1.0,
                shape=obs_shape,
                dtype=np.float32,
            )
        elif self.obs_mode == "symbolic":
            # [goal_r, goal_c] in [0..H-1], [0..W-1]; one-hot target in [0,1]; robots positions in bounds
            vec_len = 2 + self.num_robots + (self.num_robots * 2)
            low = np.full((vec_len,), 0.0, dtype=np.float32)
            high = np.full((vec_len,), 1.0, dtype=np.float32)
            # goal bounds
            low[0] = 0.0
            high[0] = float(self.height - 1)
            low[1] = 0.0
            high[1] = float(self.width - 1)
            # target one-hot already [0,1]
            # robots positions
            base = 2 + self.num_robots
            for i in range(self.num_robots):
                low[base + 2 * i] = 0.0
                high[base + 2 * i] = float(self.height - 1)
                low[base + 2 * i + 1] = 0.0
                high[base + 2 * i + 1] = float(self.width - 1)
            self.observation_space = spaces.Box(low=low, high=high, shape=(vec_len,), dtype=np.float32)
        else:
            raise ValueError(f"Unknown obs_mode: {self.obs_mode}")

        # Action space: num_robots * 4 directions (+ 1 for noop)
        self._noop_action = self.num_robots * 4 if include_noop else None
        self.action_space = spaces.Discrete(self.num_robots * 4 + (1 if include_noop else 0))

    # Gymnasium API
    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):
        """Reset the environment and start a new episode.

        Returns (obs, info) per Gymnasium API. info contains keys: 'target_robot',
        'level_solvable' (optional), 'optimal_length' (if ensured), 'solver_limits' (if ensured),
        and 'episode_seed' with the seed used for this episode.
        """
        # Standard seeding protocol
        if seed is not None:
            try:
                self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
                self._episode_seed = int(used_seed) if used_seed is not None else None
            except NameError:
                self.np_random = np.random.default_rng(seed)
                self._episode_seed = int(seed)
        _ = options  # silence unused
        self._num_steps = 0
        # clear cached walls in case layout changes
        self._cached_wall_obs = None

        if self.fixed_layout is not None:
            self._board = Board(
                height=self.fixed_layout.height,
                width=self.fixed_layout.width,
                h_walls=self.fixed_layout.h_walls.copy(),
                v_walls=self.fixed_layout.v_walls.copy(),
                robot_positions=dict(self.fixed_layout.robot_positions),
                goal_position=self.fixed_layout.goal_position,
                target_robot=self.fixed_layout.target_robot,
            )
            # cache static walls for this layout
            self._build_cached_walls(self._board)
            obs = self._make_obs(self._board)
            info = {"level_solvable": None, "target_robot": self._board.target_robot, "episode_seed": self._episode_seed}
            return obs, info

        # Otherwise, generate random board, optionally ensure solvable via solver
        attempts = 0
        while True:
            attempts += 1
            board = self._generate_random_board()
            if not self.ensure_solvable:
                self._board = board
                break
            try:
                from .solver import solve_bfs  # type: ignore
                solution = solve_bfs(board, max_depth=self.solver_max_depth, max_nodes=self.solver_max_nodes)
                if solution is not None:
                    self._board = board
                    optimal_length = len(solution)
                    break
            except ImportError as exc:
                raise RuntimeError("ensure_solvable=True but solver unavailable (ImportError)") from exc
            if attempts >= 50:
                raise RuntimeError("Failed to generate solvable board within attempt limit")

        # cache static walls for this layout
        assert self._board is not None
        self._build_cached_walls(self._board)
        obs = self._make_obs(self._board)
        # Note: solver None during attempts may be due to cutoffs (depth/nodes), not true unsolvability.
        info = {"level_solvable": True if self.ensure_solvable else None, "target_robot": self._board.target_robot, "episode_seed": self._episode_seed}
        if self.ensure_solvable:
            info["optimal_length"] = optimal_length
            info["solver_limits"] = {"max_depth": self.solver_max_depth, "max_nodes": self.solver_max_nodes}
        return obs, info

    def step(self, action: int):
        """Apply an action and return (obs, reward, terminated, truncated, info).

        info always includes 'steps', 'target_robot', and 'is_success' (bool). When truncated due to
        max steps, info includes 'TimeLimit.truncated'=True.
        """
        assert self._board is not None, "Call reset() first"
        self._num_steps += 1

        terminated = False
        truncated = False
        info: Dict[str, object] = {}

        reward = self.step_penalty
        # Validate action range early
        if not (0 <= action < self.action_space.n):
            if GymInvalidAction is not None:
                raise GymInvalidAction(f"Invalid action {action}")  # type: ignore[misc]
            raise ValueError(f"Invalid action {action}")

        if self.include_noop and action == self._noop_action:
            reward = self.noop_penalty
        else:
            robot_id, direction = self._decode_action(action)
            self._board = apply_action(self._board, robot_id, direction)

        if reached_goal(self._board):
            reward += self.goal_reward
            terminated = True
            info["success"] = True
            info["is_success"] = True

        if not terminated and self._num_steps >= self.max_steps:
            truncated = True
            info["TimeLimit.truncated"] = True

        obs = self._make_obs(self._board)
        info["steps"] = self._num_steps
        info["target_robot"] = self._board.target_robot
        if "is_success" not in info:
            info["is_success"] = False
        return obs, reward, terminated, truncated, info

    def render(self):
        """Render according to render_mode.

        - render_mode=="ascii": returns a string frame.
        - render_mode is None or unsupported: returns None.
        """
        if self.render_mode is None:
            return None
        if self.render_mode != "ascii":
            raise ValueError(f"Unsupported render_mode {self.render_mode}. Supported: {self.metadata['render_modes']}")
        if self._board is None:
            return ""
        from .ricochet_core import render_ascii  # local import to avoid circulars in lints
        return render_ascii(self._board)

    def close(self) -> None:
        """Close environment resources (no-op)."""
        return None

    def seed(self, seed: Optional[int] = None):  # legacy convenience
        """Legacy seeding helper returning [seed]. Prefer reset(seed=...)."""
        if seed is None:
            return [self._episode_seed]
        try:
            self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
            self._episode_seed = int(used_seed) if used_seed is not None else int(seed)
        except NameError:
            self.np_random = np.random.default_rng(seed)
            self._episode_seed = int(seed)
        return [self._episode_seed]

    # Helpers
    def _decode_action(self, action: int) -> Tuple[int, int]:
        if not (0 <= action < self.action_space.n):
            raise ValueError(f"Invalid action {action}")
        if self.include_noop and action == self._noop_action:
            raise ValueError("_decode_action called on noop action")
        robot_id = action // 4
        direction = action % 4
        if robot_id >= self.num_robots:
            raise ValueError(f"Invalid robot_id {robot_id} for action {action}")
        return robot_id, direction

    def _make_obs(self, board: Board) -> np.ndarray:
        if self.obs_mode == "image":
            return self._board_to_image_obs(board)
        return self._board_to_symbolic_obs(board)

    def _board_to_image_obs(self, board: Board) -> np.ndarray:
        h, w = board.height, board.width
        C = self._num_channels
        obs = np.zeros((h, w, C), dtype=np.float32)
        # wall channels 0..3 from cache
        if self._cached_wall_obs is not None:
            obs[:, :, 0:4] = self._cached_wall_obs
        else:
            # Fallback if cache not built (should not happen)
            for r in range(h):
                for c in range(w):
                    obs[r, c, 0] = 1.0 if board.has_wall_up(r, c) else 0.0
                    obs[r, c, 1] = 1.0 if board.has_wall_down(r, c) else 0.0
                    obs[r, c, 2] = 1.0 if board.has_wall_left(r, c) else 0.0
                    obs[r, c, 3] = 1.0 if board.has_wall_right(r, c) else 0.0
        # goal channel 4
        gr, gc = board.goal_position
        obs[gr, gc, 4] = 1.0
        # target mask channel 5
        tr = board.target_robot
        tr_r, tr_c = board.robot_positions[tr]
        obs[tr_r, tr_c, 5] = 1.0
        # robot channels start at 6
        base = 6
        for rid, (r, c) in board.robot_positions.items():
            obs[r, c, base + rid] = 1.0
        if self.channels_first:
            obs = np.transpose(obs, (2, 0, 1))
        return obs

    def _board_to_symbolic_obs(self, board: Board) -> np.ndarray:
        gr, gc = board.goal_position
        target_one_hot = np.zeros((self.num_robots,), dtype=np.float32)
        target_one_hot[board.target_robot] = 1.0
        robots_vec: List[float] = []
        for rid in range(self.num_robots):
            r, c = board.robot_positions[rid]
            robots_vec.extend([float(r), float(c)])
        vec = np.concatenate([
            np.array([float(gr), float(gc)], dtype=np.float32),
            target_one_hot.astype(np.float32),
            np.array(robots_vec, dtype=np.float32),
        ])
        return vec

    def _generate_random_board(self) -> Board:
        h, w = self.height, self.width
        # Start with open grid, then add random interior edge walls, and border walls
        h_walls = np.zeros((h + 1, w), dtype=bool)
        v_walls = np.zeros((h, w + 1), dtype=bool)
        # Borders
        h_walls[0, :] = True
        h_walls[h, :] = True
        v_walls[:, 0] = True
        v_walls[:, w] = True
        # Random interior edges
        max_edges = max(1, (h * w) // 6)
        num_edges = int(self.np_random.integers(0, max_edges))
        for _ in range(num_edges):
            if self.np_random.integers(0, 2) == 0:
                rr = int(self.np_random.integers(1, h))
                cc = int(self.np_random.integers(0, w))
                h_walls[rr, cc] = True
            else:
                rr = int(self.np_random.integers(0, h))
                cc = int(self.np_random.integers(1, w))
                v_walls[rr, cc] = True
        # Place goal and robots in free cells
        free_cells: List[Tuple[int, int]] = [(r, c) for r in range(h) for c in range(w)]
        self.np_random.shuffle(free_cells)
        goal = free_cells.pop()
        robot_positions: Dict[int, Tuple[int, int]] = {}
        for rid in range(self.num_robots):
            robot_positions[rid] = free_cells.pop()
        target_robot = int(self.np_random.integers(0, self.num_robots))
        return Board(height=h, width=w, h_walls=h_walls, v_walls=v_walls, robot_positions=robot_positions, goal_position=goal, target_robot=target_robot)

    # Public channel names for image observations
    @property
    def channel_names(self) -> List[str]:
        """Human-readable names for image observation channels."""
        names = ["wall_up", "wall_down", "wall_left", "wall_right", "goal", "target_robot_mask"]
        names.extend([f"robot_{i}" for i in range(self.num_robots)])
        return names

    def _build_cached_walls(self, board: Board) -> None:
        """Precompute static wall indicator channels (H,W,4)."""
        h, w = board.height, board.width
        wall = np.zeros((h, w, 4), dtype=np.float32)
        for r in range(h):
            for c in range(w):
                wall[r, c, 0] = 1.0 if board.has_wall_up(r, c) else 0.0
                wall[r, c, 1] = 1.0 if board.has_wall_down(r, c) else 0.0
                wall[r, c, 2] = 1.0 if board.has_wall_left(r, c) else 0.0
                wall[r, c, 3] = 1.0 if board.has_wall_right(r, c) else 0.0
        self._cached_wall_obs = wall


# Optional helper for registration with gymnasium
def register_env(env_id: str = "RicochetRobots-v0") -> None:
    """Register this environment with gymnasium so it can be created via gym.make(env_id)."""
    try:
        import gymnasium as gym  # type: ignore
        from gymnasium.envs.registration import register  # type: ignore
        from gymnasium.error import Error as GymError  # type: ignore
        try:
            register(
            id=env_id,
            entry_point="env.ricochet_env:RicochetRobotsEnv",
            )
        except GymError as e:  # pragma: no cover - depends on gym version behavior
            # Swallow duplicate registration errors; re-raise others
            if "already registered" in str(e).lower():
                return
            raise
    except (ModuleNotFoundError, ImportError):
        # Silently ignore if gymnasium not available
        pass

```

```markdown
# Ricochet Robots RL Environment (Step 1)

This repository contains a custom Gymnasium-compatible environment for the Ricochet Robots puzzle, a BFS solver for validation/curriculum, and unit tests.

## Setup

Install dependencies:

```bash
pip install -r requirements.txt
```

## Run Tests

```bash
pytest -q
```

## Usage Example

```python
from env.ricochet_env import RicochetRobotsEnv

env = RicochetRobotsEnv(height=8, width=8, num_robots=2, render_mode="ascii")
obs, info = env.reset(seed=123)
action = 0  # robot 0 up
obs, reward, terminated, truncated, info = env.step(action)
print(env.render())
```

### Gymnasium Registration (optional)

To create the env via gym.make:

```python
import gymnasium as gym
from env.ricochet_env import register_env

register_env("RicochetRobots-v0")
env = gym.make("RicochetRobots-v0", height=8, width=8, num_robots=2, render_mode="ascii")
```

### Notes on API compliance

- Seeding follows Gymnasium: use `reset(seed=...)`. The used seed is provided in `info["episode_seed"]`.
- Rendering uses `render_mode`. With `render_mode="ascii"`, `render()` returns a string. Other modes are not implemented and will raise a clear error.
- The `info` dict includes `is_success` each step, and `TimeLimit.truncated` when the episode hits `max_steps`.
- The environment already enforces a time limit via `max_steps`; avoid wrapping with `TimeLimit` unless you disable the internal cap.

```

- Ive addressed the new feedback directly in the code and docs.

Changes made:
- Registration helper
  - Removed non-portable registry check. Now calls `register(...)` and swallows already registered by catching Gymnasiums error and checking the message.

- Render ergonomics
  - `render()` now raises a clear error if `render_mode` is set to an unsupported value; returns None only when `render_mode` is None.
  - README clarifies that only `"ascii"` is implemented and others will error.

- Seeding/documentation polish
  - `reset()` now clears `_cached_wall_obs` at the start to avoid any stale state across resets.
  - README notes time limit is enforced internally to avoid double TimeLimit wrapping.

- Action error type
  - If Gymnasium is available, invalid actions raise `gymnasium.error.InvalidAction`; otherwise a `ValueError`.

- Doc/UX touch-ups
  - `channel_names` docstring is present; success flag usage is consistent (`is_success` always present). Tests still reference `success`, so I kept it for compatibility.

Files updated:
- `env/ricochet_env.py`: registration guard, render error behavior, cache clearing in `reset`, InvalidAction raising when available.
- `README.md`: clarified render behavior and time limit note.

- All tasks from this round are complete.

---

**User**

Good work! Latest feedback attached, please go ahead and implement it.

---

**Cursor**

```python
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple, List, Literal

import numpy as np

from .ricochet_core import Board, apply_action, reached_goal

# Provide a runtime gymnasium binding if available, otherwise a minimal fallback
try:  # pragma: no cover
    import importlib
    _gym = importlib.import_module("gymnasium")  # type: ignore
    _spaces = importlib.import_module("gymnasium.spaces")  # type: ignore
    _seeding = importlib.import_module("gymnasium.utils.seeding")  # type: ignore
    _error = importlib.import_module("gymnasium.error")  # type: ignore
    GymEnvBase = _gym.Env  # type: ignore
    spaces = _spaces  # type: ignore
    GymInvalidAction = getattr(_error, "InvalidAction", None)  # type: ignore
except (ModuleNotFoundError, ImportError):  # pragma: no cover
    class GymEnvBase(object):
        pass
    class _SpacesDummy:  # minimal placeholders to satisfy type usage
        class Box:  # type: ignore
            def __init__(self, low=None, high=None, shape=None, dtype=None):
                self.low = low
                self.high = high
                self.shape = shape
                self.dtype = dtype
        class Discrete:  # type: ignore
            def __init__(self, n: int):
                self.n = n
    spaces = _SpacesDummy()  # type: ignore
    GymInvalidAction = None  # type: ignore


@dataclass
class FixedLayout:
    height: int
    width: int
    # Edge walls
    h_walls: np.ndarray  # (H+1, W) bool
    v_walls: np.ndarray  # (H, W+1) bool
    robot_positions: Dict[int, Tuple[int, int]]
    goal_position: Tuple[int, int]
    target_robot: int


ObsMode = Literal["image", "symbolic"]


class RicochetRobotsEnv(GymEnvBase):
    """Ricochet Robots Gymnasium-compatible environment.

    Determinism and seeding:
    - Deterministic given the seed provided to __init__ or reset(seed=...).
    - Randomness flows through self.np_random (Gymnasium seeding utils); the episode's resolved
      seed is exposed via info["episode_seed"].
    - When ensure_solvable=True, the environment may retry board generation; retries do not add
      extra non-determinism beyond RNG draws. The included solver is deterministic.

    Observations:
    - Image mode: float32 in [0,1]. Channels are named by channel_names; note that the target robot
      is represented both by a dedicated mask (index 5) and its robot channel (duplication by design).
    - Symbolic mode: float32 with absolute grid indices (not normalized). Downstream code may wish to
      normalize to [0,1]. The Box low/high reflect board bounds.

    Rendering:
    - Only render_mode="ascii" is implemented and returns a string frame.
    - Other modes are not implemented and will raise a clear error.
    """
    metadata = {"render_modes": ["ascii"], "render_fps": 4}

    def __init__(
        self,
        height: int = 8,
        width: int = 8,
        num_robots: int = 2,
        include_noop: bool = True,
        step_penalty: float = -0.01,
        goal_reward: float = 1.0,
        noop_penalty: Optional[float] = None,
        max_steps: int = 100,
        fixed_layout: Optional[FixedLayout] = None,
        seed: Optional[int] = None,
        ensure_solvable: bool = False,
        solver_max_depth: int = 30,
        solver_max_nodes: int = 20000,
        obs_mode: ObsMode = "image",
        channels_first: bool = False,
        render_mode: Optional[str] = None,
        ensure_attempt_limit: int = 50,
    ) -> None:
        super().__init__()
        self.height = height
        self.width = width
        self.num_robots = num_robots
        self.include_noop = include_noop
        self.step_penalty = step_penalty
        self.goal_reward = goal_reward
        self.noop_penalty = step_penalty if noop_penalty is None else noop_penalty
        self.max_steps = max_steps
        self.fixed_layout = fixed_layout
        self.ensure_solvable = ensure_solvable
        self.solver_max_depth = solver_max_depth
        self.solver_max_nodes = solver_max_nodes
        self.obs_mode: ObsMode = obs_mode
        self.channels_first = channels_first
        # Render API
        self.render_mode = render_mode
        if self.render_mode is not None and self.render_mode not in self.metadata["render_modes"]:
            raise ValueError(f"Unsupported render_mode {self.render_mode}. Supported: {self.metadata['render_modes']}")

        # Seeding: adopt Gymnasium convention with self.np_random
        self.np_random: np.random.Generator
        self._episode_seed: Optional[int] = None
        try:  # gymnasium present
            # _seeding.np_random returns (rng, seed)
            self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
            self._episode_seed = int(used_seed) if used_seed is not None else None
        except NameError:
            self.np_random = np.random.default_rng(seed)
            self._episode_seed = int(seed) if seed is not None else None
        self._board: Optional[Board] = None
        self._num_steps = 0
        self._cached_wall_obs: Optional[np.ndarray] = None  # (H,W,4) float32 for wall channels
        self._ensure_attempt_limit = int(ensure_attempt_limit)

        # Observation spaces
        if self.obs_mode == "image":
            # channels: up_wall, down_wall, left_wall, right_wall, goal, target_mask, robots...
            self._base_wall_channels = 4
            self._base_misc_channels = 2  # goal, target
            self._num_channels = self._base_wall_channels + self._base_misc_channels + self.num_robots
            if self.channels_first:
                obs_shape = (self._num_channels, self.height, self.width)
            else:
                obs_shape = (self.height, self.width, self._num_channels)
            self.observation_space = spaces.Box(
                low=0.0,
                high=1.0,
                shape=obs_shape,
                dtype=np.float32,
            )
        elif self.obs_mode == "symbolic":
            # [goal_r, goal_c] in [0..H-1], [0..W-1]; one-hot target in [0,1]; robots positions in bounds
            vec_len = 2 + self.num_robots + (self.num_robots * 2)
            low = np.full((vec_len,), 0.0, dtype=np.float32)
            high = np.full((vec_len,), 1.0, dtype=np.float32)
            # goal bounds
            low[0] = 0.0
            high[0] = float(self.height - 1)
            low[1] = 0.0
            high[1] = float(self.width - 1)
            # target one-hot already [0,1]
            # robots positions
            base = 2 + self.num_robots
            for i in range(self.num_robots):
                low[base + 2 * i] = 0.0
                high[base + 2 * i] = float(self.height - 1)
                low[base + 2 * i + 1] = 0.0
                high[base + 2 * i + 1] = float(self.width - 1)
            self.observation_space = spaces.Box(low=low, high=high, shape=(vec_len,), dtype=np.float32)
        else:
            raise ValueError(f"Unknown obs_mode: {self.obs_mode}")

        # Action space: num_robots * 4 directions (+ 1 for noop)
        self._noop_action = self.num_robots * 4 if include_noop else None
        self.action_space = spaces.Discrete(self.num_robots * 4 + (1 if include_noop else 0))

    # Gymnasium API
    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):
        """Reset the environment and start a new episode.

        Returns (obs, info) per Gymnasium API. info contains keys: 'target_robot',
        'level_solvable' (optional), 'optimal_length' (if ensured), 'solver_limits' (if ensured),
        and 'episode_seed' with the seed used for this episode.
        """
        # Standard seeding protocol
        if seed is not None:
            try:
                self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
                self._episode_seed = int(used_seed) if used_seed is not None else None
            except NameError:
                self.np_random = np.random.default_rng(seed)
                self._episode_seed = int(seed)
        _ = options  # silence unused
        self._num_steps = 0
        # clear cached walls in case layout changes
        self._cached_wall_obs = None

        if self.fixed_layout is not None:
            self._board = Board(
                height=self.fixed_layout.height,
                width=self.fixed_layout.width,
                h_walls=self.fixed_layout.h_walls.copy(),
                v_walls=self.fixed_layout.v_walls.copy(),
                robot_positions=dict(self.fixed_layout.robot_positions),
                goal_position=self.fixed_layout.goal_position,
                target_robot=self.fixed_layout.target_robot,
            )
            # cache static walls for this layout
            self._build_cached_walls(self._board)
            obs = self._make_obs(self._board)
            info = {"level_solvable": None, "target_robot": self._board.target_robot, "episode_seed": self._episode_seed}
            return obs, info

        # Otherwise, generate random board, optionally ensure solvable via solver
        attempts = 0
        while True:
            attempts += 1
            board = self._generate_random_board()
            if not self.ensure_solvable:
                self._board = board
                break
            try:
                from .solver import solve_bfs  # type: ignore
                solution = solve_bfs(board, max_depth=self.solver_max_depth, max_nodes=self.solver_max_nodes)
                if solution is not None:
                    self._board = board
                    optimal_length = len(solution)
                    break
            except ImportError as exc:
                raise RuntimeError("ensure_solvable=True but solver unavailable (ImportError)") from exc
            if attempts >= self._ensure_attempt_limit:
                raise RuntimeError("Failed to generate solvable board within attempt limit")

        # cache static walls for this layout
        assert self._board is not None
        self._build_cached_walls(self._board)
        obs = self._make_obs(self._board)
        # Note: solver None during attempts may be due to cutoffs (depth/nodes), not true unsolvability.
        info = {"level_solvable": True if self.ensure_solvable else None, "target_robot": self._board.target_robot, "episode_seed": self._episode_seed}
        if self.ensure_solvable:
            info["optimal_length"] = optimal_length
            info["solver_limits"] = {"max_depth": self.solver_max_depth, "max_nodes": self.solver_max_nodes}
        return obs, info

    def step(self, action: int):
        """Apply an action and return (obs, reward, terminated, truncated, info).

        info always includes 'steps', 'target_robot', and 'is_success' (bool). When truncated due to
        max steps, info includes 'TimeLimit.truncated'=True.
        """
        assert self._board is not None, "Call reset() first"
        self._num_steps += 1

        terminated = False
        truncated = False
        info: Dict[str, object] = {}

        reward = self.step_penalty
        # Validate action range early
        if not (0 <= action < self.action_space.n):
            if GymInvalidAction is not None:
                raise GymInvalidAction(f"Invalid action {action}")  # type: ignore[misc]
            raise ValueError(f"Invalid action {action}")

        if self.include_noop and action == self._noop_action:
            reward = self.noop_penalty
        else:
            robot_id, direction = self._decode_action(action)
            self._board = apply_action(self._board, robot_id, direction)

        if reached_goal(self._board):
            reward += self.goal_reward
            terminated = True
            info["is_success"] = True

        if not terminated and self._num_steps >= self.max_steps:
            truncated = True
            info["TimeLimit.truncated"] = True

        obs = self._make_obs(self._board)
        info["steps"] = self._num_steps
        info["target_robot"] = self._board.target_robot
        if "is_success" not in info:
            info["is_success"] = False
        return obs, reward, terminated, truncated, info

    def render(self):
        """Render according to render_mode.

        - render_mode=="ascii": returns a string frame.
        - render_mode is None or unsupported: returns None.
        """
        if self.render_mode is None:
            return None
        if self.render_mode != "ascii":
            raise ValueError(f"Unsupported render_mode {self.render_mode}. Supported: {self.metadata['render_modes']}")
        if self._board is None:
            return ""
        from .ricochet_core import render_ascii  # local import to avoid circulars in lints
        return render_ascii(self._board)

    def close(self) -> None:
        """Close environment resources (no-op)."""
        return None

    def seed(self, seed: Optional[int] = None):  # legacy convenience
        """Legacy seeding helper returning [seed]. Prefer reset(seed=...)."""
        if seed is None:
            return [self._episode_seed]
        try:
            self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
            self._episode_seed = int(used_seed) if used_seed is not None else int(seed)
        except NameError:
            self.np_random = np.random.default_rng(seed)
            self._episode_seed = int(seed)
        return [self._episode_seed]

    # Helpers
    def _decode_action(self, action: int) -> Tuple[int, int]:
        if not (0 <= action < self.action_space.n):
            raise ValueError(f"Invalid action {action}")
        if self.include_noop and action == self._noop_action:
            raise ValueError("_decode_action called on noop action")
        robot_id = action // 4
        direction = action % 4
        if robot_id >= self.num_robots:
            raise ValueError(f"Invalid robot_id {robot_id} for action {action}")
        return robot_id, direction

    def _make_obs(self, board: Board) -> np.ndarray:
        if self.obs_mode == "image":
            return self._board_to_image_obs(board)
        return self._board_to_symbolic_obs(board)

    def _board_to_image_obs(self, board: Board) -> np.ndarray:
        h, w = board.height, board.width
        C = self._num_channels
        obs = np.zeros((h, w, C), dtype=np.float32)
        # wall channels 0..3 from cache
        if self._cached_wall_obs is not None:
            obs[:, :, 0:4] = self._cached_wall_obs
        else:
            # Fallback if cache not built (should not happen)
            for r in range(h):
                for c in range(w):
                    obs[r, c, 0] = 1.0 if board.has_wall_up(r, c) else 0.0
                    obs[r, c, 1] = 1.0 if board.has_wall_down(r, c) else 0.0
                    obs[r, c, 2] = 1.0 if board.has_wall_left(r, c) else 0.0
                    obs[r, c, 3] = 1.0 if board.has_wall_right(r, c) else 0.0
        # goal channel 4
        gr, gc = board.goal_position
        obs[gr, gc, 4] = 1.0
        # target mask channel 5
        tr = board.target_robot
        tr_r, tr_c = board.robot_positions[tr]
        obs[tr_r, tr_c, 5] = 1.0
        # robot channels start at 6
        base = 6
        for rid, (r, c) in board.robot_positions.items():
            obs[r, c, base + rid] = 1.0
        if self.channels_first:
            obs = np.transpose(obs, (2, 0, 1))
        return obs

    def _board_to_symbolic_obs(self, board: Board) -> np.ndarray:
        gr, gc = board.goal_position
        target_one_hot = np.zeros((self.num_robots,), dtype=np.float32)
        target_one_hot[board.target_robot] = 1.0
        robots_vec: List[float] = []
        for rid in range(self.num_robots):
            r, c = board.robot_positions[rid]
            robots_vec.extend([float(r), float(c)])
        vec = np.concatenate([
            np.array([float(gr), float(gc)], dtype=np.float32),
            target_one_hot.astype(np.float32),
            np.array(robots_vec, dtype=np.float32),
        ])
        return vec

    def _generate_random_board(self) -> Board:
        h, w = self.height, self.width
        # Start with open grid, then add random interior edge walls, and border walls
        h_walls = np.zeros((h + 1, w), dtype=bool)
        v_walls = np.zeros((h, w + 1), dtype=bool)
        # Borders
        h_walls[0, :] = True
        h_walls[h, :] = True
        v_walls[:, 0] = True
        v_walls[:, w] = True
        # Random interior edges
        max_edges = max(1, (h * w) // 6)
        num_edges = int(self.np_random.integers(0, max_edges))
        for _ in range(num_edges):
            if self.np_random.integers(0, 2) == 0:
                rr = int(self.np_random.integers(1, h))
                cc = int(self.np_random.integers(0, w))
                h_walls[rr, cc] = True
            else:
                rr = int(self.np_random.integers(0, h))
                cc = int(self.np_random.integers(1, w))
                v_walls[rr, cc] = True
        # Place goal and robots in free cells
        free_cells: List[Tuple[int, int]] = [(r, c) for r in range(h) for c in range(w)]
        self.np_random.shuffle(free_cells)
        goal = free_cells.pop()
        robot_positions: Dict[int, Tuple[int, int]] = {}
        for rid in range(self.num_robots):
            robot_positions[rid] = free_cells.pop()
        target_robot = int(self.np_random.integers(0, self.num_robots))
        return Board(height=h, width=w, h_walls=h_walls, v_walls=v_walls, robot_positions=robot_positions, goal_position=goal, target_robot=target_robot)

    # Public channel names for image observations
    @property
    def channel_names(self) -> List[str]:
        """Human-readable names for image observation channels."""
        names = ["wall_up", "wall_down", "wall_left", "wall_right", "goal", "target_robot_mask"]
        names.extend([f"robot_{i}" for i in range(self.num_robots)])
        return names

    def _build_cached_walls(self, board: Board) -> None:
        """Precompute static wall indicator channels (H,W,4)."""
        h, w = board.height, board.width
        wall = np.zeros((h, w, 4), dtype=np.float32)
        for r in range(h):
            for c in range(w):
                wall[r, c, 0] = 1.0 if board.has_wall_up(r, c) else 0.0
                wall[r, c, 1] = 1.0 if board.has_wall_down(r, c) else 0.0
                wall[r, c, 2] = 1.0 if board.has_wall_left(r, c) else 0.0
                wall[r, c, 3] = 1.0 if board.has_wall_right(r, c) else 0.0
        self._cached_wall_obs = wall


# Optional helper for registration with gymnasium
def register_env(env_id: str = "RicochetRobots-v0", *, max_episode_steps: Optional[int] = None) -> None:
    """Register this environment with gymnasium so it can be created via gym.make(env_id)."""
    try:
        import gymnasium as gym  # type: ignore
        from gymnasium.envs.registration import register  # type: ignore
        from gymnasium.error import Error as GymError  # type: ignore
        try:
            kwargs = {}
            if max_episode_steps is not None:
                kwargs["max_episode_steps"] = int(max_episode_steps)
            register(
                id=env_id,
                entry_point="env.ricochet_env:RicochetRobotsEnv",
                **kwargs,
            )
        except GymError as e:  # pragma: no cover - depends on gym version behavior
            # Swallow duplicate registration errors; re-raise others
            if "already registered" in str(e).lower():
                return
            raise
    except (ModuleNotFoundError, ImportError):
        # Silently ignore if gymnasium not available
        pass

```

```python
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple, List, Literal

import numpy as np

from .ricochet_core import Board, apply_action, reached_goal

# Provide a runtime gymnasium binding if available, otherwise a minimal fallback
try:  # pragma: no cover
    import importlib
    _gym = importlib.import_module("gymnasium")  # type: ignore
    _spaces = importlib.import_module("gymnasium.spaces")  # type: ignore
    _seeding = importlib.import_module("gymnasium.utils.seeding")  # type: ignore
    _error = importlib.import_module("gymnasium.error")  # type: ignore
    GymEnvBase = _gym.Env  # type: ignore
    spaces = _spaces  # type: ignore
    GymInvalidAction = getattr(_error, "InvalidAction", None)  # type: ignore
except (ModuleNotFoundError, ImportError):  # pragma: no cover
    class GymEnvBase(object):
        pass
    class _SpacesDummy:  # minimal placeholders to satisfy type usage
        class Box:  # type: ignore
            def __init__(self, low=None, high=None, shape=None, dtype=None):
                self.low = low
                self.high = high
                self.shape = shape
                self.dtype = dtype
        class Discrete:  # type: ignore
            def __init__(self, n: int):
                self.n = n
    spaces = _SpacesDummy()  # type: ignore
    GymInvalidAction = None  # type: ignore


@dataclass
class FixedLayout:
    height: int
    width: int
    # Edge walls
    h_walls: np.ndarray  # (H+1, W) bool
    v_walls: np.ndarray  # (H, W+1) bool
    robot_positions: Dict[int, Tuple[int, int]]
    goal_position: Tuple[int, int]
    target_robot: int


ObsMode = Literal["image", "symbolic"]


class RicochetRobotsEnv(GymEnvBase):
    """Ricochet Robots Gymnasium-compatible environment.

    Determinism and seeding:
    - Deterministic given the seed provided to __init__ or reset(seed=...).
    - Randomness flows through self.np_random (Gymnasium seeding utils); the episode's resolved
      seed is exposed via info["episode_seed"].
    - When ensure_solvable=True, the environment may retry board generation; retries do not add
      extra non-determinism beyond RNG draws. The included solver is deterministic.

    Observations:
    - Image mode: float32 in [0,1]. Channels are named by channel_names; note that the target robot
      is represented both by a dedicated mask (index 5) and its robot channel (duplication by design).
    - Symbolic mode: float32 with absolute grid indices (not normalized). Downstream code may wish to
      normalize to [0,1]. The Box low/high reflect board bounds.

    Rendering:
    - Only render_mode="ascii" is implemented and returns a string frame.
    - Other modes are not implemented and will raise a clear error.
    """
    metadata = {"render_modes": ["ascii"], "render_fps": 4}

    def __init__(
        self,
        height: int = 8,
        width: int = 8,
        num_robots: int = 2,
        include_noop: bool = True,
        step_penalty: float = -0.01,
        goal_reward: float = 1.0,
        noop_penalty: Optional[float] = None,
        max_steps: int = 100,
        fixed_layout: Optional[FixedLayout] = None,
        seed: Optional[int] = None,
        ensure_solvable: bool = False,
        solver_max_depth: int = 30,
        solver_max_nodes: int = 20000,
        obs_mode: ObsMode = "image",
        channels_first: bool = False,
        render_mode: Optional[str] = None,
        ensure_attempt_limit: int = 50,
    ) -> None:
        super().__init__()
        self.height = height
        self.width = width
        self.num_robots = num_robots
        self.include_noop = include_noop
        self.step_penalty = step_penalty
        self.goal_reward = goal_reward
        self.noop_penalty = step_penalty if noop_penalty is None else noop_penalty
        self.max_steps = max_steps
        self.fixed_layout = fixed_layout
        self.ensure_solvable = ensure_solvable
        self.solver_max_depth = solver_max_depth
        self.solver_max_nodes = solver_max_nodes
        self.obs_mode: ObsMode = obs_mode
        self.channels_first = channels_first
        # Render API
        self.render_mode = render_mode
        if self.render_mode is not None and self.render_mode not in self.metadata["render_modes"]:
            raise ValueError(f"Unsupported render_mode {self.render_mode}. Supported: {self.metadata['render_modes']}")

        # Seeding: adopt Gymnasium convention with self.np_random
        self.np_random: np.random.Generator
        self._episode_seed: Optional[int] = None
        try:  # gymnasium present
            # _seeding.np_random returns (rng, seed)
            self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
            self._episode_seed = int(used_seed) if used_seed is not None else None
        except NameError:
            self.np_random = np.random.default_rng(seed)
            self._episode_seed = int(seed) if seed is not None else None
        self._board: Optional[Board] = None
        self._num_steps = 0
        self._cached_wall_obs: Optional[np.ndarray] = None  # (H,W,4) float32 for wall channels
        self._ensure_attempt_limit = int(ensure_attempt_limit)

        # Observation spaces
        if self.obs_mode == "image":
            # channels: up_wall, down_wall, left_wall, right_wall, goal, target_mask, robots...
            self._base_wall_channels = 4
            self._base_misc_channels = 2  # goal, target
            self._num_channels = self._base_wall_channels + self._base_misc_channels + self.num_robots
            if self.channels_first:
                obs_shape = (self._num_channels, self.height, self.width)
            else:
                obs_shape = (self.height, self.width, self._num_channels)
            self.observation_space = spaces.Box(
                low=0.0,
                high=1.0,
                shape=obs_shape,
                dtype=np.float32,
            )
        elif self.obs_mode == "symbolic":
            # [goal_r, goal_c] in [0..H-1], [0..W-1]; one-hot target in [0,1]; robots positions in bounds
            vec_len = 2 + self.num_robots + (self.num_robots * 2)
            low = np.full((vec_len,), 0.0, dtype=np.float32)
            high = np.full((vec_len,), 1.0, dtype=np.float32)
            # goal bounds
            low[0] = 0.0
            high[0] = float(self.height - 1)
            low[1] = 0.0
            high[1] = float(self.width - 1)
            # target one-hot already [0,1]
            # robots positions
            base = 2 + self.num_robots
            for i in range(self.num_robots):
                low[base + 2 * i] = 0.0
                high[base + 2 * i] = float(self.height - 1)
                low[base + 2 * i + 1] = 0.0
                high[base + 2 * i + 1] = float(self.width - 1)
            self.observation_space = spaces.Box(low=low, high=high, shape=(vec_len,), dtype=np.float32)
        else:
            raise ValueError(f"Unknown obs_mode: {self.obs_mode}")

        # Action space: num_robots * 4 directions (+ 1 for noop)
        self._noop_action = self.num_robots * 4 if include_noop else None
        self.action_space = spaces.Discrete(self.num_robots * 4 + (1 if include_noop else 0))

    # Gymnasium API
    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):
        """Reset the environment and start a new episode.

        Returns (obs, info) per Gymnasium API. info contains keys: 'target_robot',
        'level_solvable' (optional), 'optimal_length' (if ensured), 'solver_limits' (if ensured),
        and 'episode_seed' with the seed used for this episode.
        """
        # Standard seeding protocol
        if seed is not None:
            try:
                self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
                self._episode_seed = int(used_seed) if used_seed is not None else None
            except NameError:
                self.np_random = np.random.default_rng(seed)
                self._episode_seed = int(seed)
        _ = options  # silence unused
        self._num_steps = 0
        # clear cached walls in case layout changes
        self._cached_wall_obs = None

        if self.fixed_layout is not None:
            self._board = Board(
                height=self.fixed_layout.height,
                width=self.fixed_layout.width,
                h_walls=self.fixed_layout.h_walls.copy(),
                v_walls=self.fixed_layout.v_walls.copy(),
                robot_positions=dict(self.fixed_layout.robot_positions),
                goal_position=self.fixed_layout.goal_position,
                target_robot=self.fixed_layout.target_robot,
            )
            # cache static walls for this layout
            self._build_cached_walls(self._board)
            obs = self._make_obs(self._board)
            info = {"level_solvable": None, "target_robot": self._board.target_robot, "episode_seed": self._episode_seed}
            return obs, info

        # Otherwise, generate random board, optionally ensure solvable via solver
        attempts = 0
        while True:
            attempts += 1
            board = self._generate_random_board()
            if not self.ensure_solvable:
                self._board = board
                break
            try:
                from .solver import solve_bfs  # type: ignore
                solution = solve_bfs(board, max_depth=self.solver_max_depth, max_nodes=self.solver_max_nodes)
                if solution is not None:
                    self._board = board
                    optimal_length = len(solution)
                    break
            except ImportError as exc:
                raise RuntimeError("ensure_solvable=True but solver unavailable (ImportError)") from exc
            if attempts >= self._ensure_attempt_limit:
                raise RuntimeError("Failed to generate solvable board within attempt limit")

        # cache static walls for this layout
        assert self._board is not None
        self._build_cached_walls(self._board)
        obs = self._make_obs(self._board)
        # Note: solver None during attempts may be due to cutoffs (depth/nodes), not true unsolvability.
        info = {"level_solvable": True if self.ensure_solvable else None, "target_robot": self._board.target_robot, "episode_seed": self._episode_seed}
        if self.ensure_solvable:
            info["optimal_length"] = optimal_length
            info["solver_limits"] = {"max_depth": self.solver_max_depth, "max_nodes": self.solver_max_nodes}
        return obs, info

    def step(self, action: int):
        """Apply an action and return (obs, reward, terminated, truncated, info).

        info always includes 'steps', 'target_robot', and 'is_success' (bool). When truncated due to
        max steps, info includes 'TimeLimit.truncated'=True.
        """
        assert self._board is not None, "Call reset() first"
        self._num_steps += 1

        terminated = False
        truncated = False
        info: Dict[str, object] = {}

        reward = self.step_penalty
        # Validate action range early
        if not (0 <= action < self.action_space.n):
            if GymInvalidAction is not None:
                raise GymInvalidAction(f"Invalid action {action}")  # type: ignore[misc]
            raise ValueError(f"Invalid action {action}")

        if self.include_noop and action == self._noop_action:
            reward = self.noop_penalty
        else:
            robot_id, direction = self._decode_action(action)
            self._board = apply_action(self._board, robot_id, direction)

        if reached_goal(self._board):
            reward += self.goal_reward
            terminated = True
            info["is_success"] = True

        if not terminated and self._num_steps >= self.max_steps:
            truncated = True
            info["TimeLimit.truncated"] = True

        obs = self._make_obs(self._board)
        info["steps"] = self._num_steps
        info["target_robot"] = self._board.target_robot
        if "is_success" not in info:
            info["is_success"] = False
        return obs, reward, terminated, truncated, info

    def render(self):
        """Render according to render_mode.

        - render_mode=="ascii": returns a string frame.
        - render_mode is None or unsupported: returns None.
        """
        if self.render_mode is None:
            return None
        if self.render_mode != "ascii":
            raise ValueError(f"Unsupported render_mode {self.render_mode}. Supported: {self.metadata['render_modes']}")
        if self._board is None:
            return ""
        from .ricochet_core import render_ascii  # local import to avoid circulars in lints
        return render_ascii(self._board)

    def close(self) -> None:
        """Close environment resources (no-op)."""
        return None

    def seed(self, seed: Optional[int] = None):  # legacy convenience
        """Legacy seeding helper returning [seed]. Prefer reset(seed=...)."""
        if seed is None:
            return [self._episode_seed]
        try:
            self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
            self._episode_seed = int(used_seed) if used_seed is not None else int(seed)
        except NameError:
            self.np_random = np.random.default_rng(seed)
            self._episode_seed = int(seed)
        return [self._episode_seed]

    # Helpers
    def _decode_action(self, action: int) -> Tuple[int, int]:
        if not (0 <= action < self.action_space.n):
            raise ValueError(f"Invalid action {action}")
        if self.include_noop and action == self._noop_action:
            raise ValueError("_decode_action called on noop action")
        robot_id = action // 4
        direction = action % 4
        if robot_id >= self.num_robots:
            raise ValueError(f"Invalid robot_id {robot_id} for action {action}")
        return robot_id, direction

    def _make_obs(self, board: Board) -> np.ndarray:
        if self.obs_mode == "image":
            return self._board_to_image_obs(board)
        return self._board_to_symbolic_obs(board)

    def _board_to_image_obs(self, board: Board) -> np.ndarray:
        h, w = board.height, board.width
        C = self._num_channels
        obs = np.zeros((h, w, C), dtype=np.float32)
        # wall channels 0..3 from cache
        if self._cached_wall_obs is not None:
            obs[:, :, 0:4] = self._cached_wall_obs
        else:
            # Fallback if cache not built (should not happen)
            for r in range(h):
                for c in range(w):
                    obs[r, c, 0] = 1.0 if board.has_wall_up(r, c) else 0.0
                    obs[r, c, 1] = 1.0 if board.has_wall_down(r, c) else 0.0
                    obs[r, c, 2] = 1.0 if board.has_wall_left(r, c) else 0.0
                    obs[r, c, 3] = 1.0 if board.has_wall_right(r, c) else 0.0
        # goal channel 4
        gr, gc = board.goal_position
        obs[gr, gc, 4] = 1.0
        # target mask channel 5
        tr = board.target_robot
        tr_r, tr_c = board.robot_positions[tr]
        obs[tr_r, tr_c, 5] = 1.0
        # robot channels start at 6
        base = 6
        for rid, (r, c) in board.robot_positions.items():
            obs[r, c, base + rid] = 1.0
        if self.channels_first:
            obs = np.transpose(obs, (2, 0, 1))
        return obs

    def _board_to_symbolic_obs(self, board: Board) -> np.ndarray:
        gr, gc = board.goal_position
        target_one_hot = np.zeros((self.num_robots,), dtype=np.float32)
        target_one_hot[board.target_robot] = 1.0
        robots_vec: List[float] = []
        for rid in range(self.num_robots):
            r, c = board.robot_positions[rid]
            robots_vec.extend([float(r), float(c)])
        vec = np.concatenate([
            np.array([float(gr), float(gc)], dtype=np.float32),
            target_one_hot.astype(np.float32),
            np.array(robots_vec, dtype=np.float32),
        ])
        return vec

    def _generate_random_board(self) -> Board:
        h, w = self.height, self.width
        # Start with open grid, then add random interior edge walls, and border walls
        h_walls = np.zeros((h + 1, w), dtype=bool)
        v_walls = np.zeros((h, w + 1), dtype=bool)
        # Borders
        h_walls[0, :] = True
        h_walls[h, :] = True
        v_walls[:, 0] = True
        v_walls[:, w] = True
        # Random interior edges
        max_edges = max(1, (h * w) // 6)
        num_edges = int(self.np_random.integers(0, max_edges))
        for _ in range(num_edges):
            if self.np_random.integers(0, 2) == 0:
                rr = int(self.np_random.integers(1, h))
                cc = int(self.np_random.integers(0, w))
                h_walls[rr, cc] = True
            else:
                rr = int(self.np_random.integers(0, h))
                cc = int(self.np_random.integers(1, w))
                v_walls[rr, cc] = True
        # Place goal and robots in free cells
        free_cells: List[Tuple[int, int]] = [(r, c) for r in range(h) for c in range(w)]
        self.np_random.shuffle(free_cells)
        goal = free_cells.pop()
        robot_positions: Dict[int, Tuple[int, int]] = {}
        for rid in range(self.num_robots):
            robot_positions[rid] = free_cells.pop()
        target_robot = int(self.np_random.integers(0, self.num_robots))
        return Board(height=h, width=w, h_walls=h_walls, v_walls=v_walls, robot_positions=robot_positions, goal_position=goal, target_robot=target_robot)

    # Public channel names for image observations
    @property
    def channel_names(self) -> List[str]:
        """Human-readable names for image observation channels."""
        names = ["wall_up", "wall_down", "wall_left", "wall_right", "goal", "target_robot_mask"]
        names.extend([f"robot_{i}" for i in range(self.num_robots)])
        return names

    def _build_cached_walls(self, board: Board) -> None:
        """Precompute static wall indicator channels (H,W,4)."""
        h, w = board.height, board.width
        wall = np.zeros((h, w, 4), dtype=np.float32)
        for r in range(h):
            for c in range(w):
                wall[r, c, 0] = 1.0 if board.has_wall_up(r, c) else 0.0
                wall[r, c, 1] = 1.0 if board.has_wall_down(r, c) else 0.0
                wall[r, c, 2] = 1.0 if board.has_wall_left(r, c) else 0.0
                wall[r, c, 3] = 1.0 if board.has_wall_right(r, c) else 0.0
        self._cached_wall_obs = wall


# Optional helper for registration with gymnasium
def register_env(env_id: str = "RicochetRobots-v0", *, max_episode_steps: Optional[int] = None) -> None:
    """Register this environment with gymnasium so it can be created via gym.make(env_id)."""
    try:
        from gymnasium.envs.registration import register  # type: ignore
        from gymnasium.error import Error as GymError  # type: ignore
        try:
            kwargs = {}
            if max_episode_steps is not None:
                kwargs["max_episode_steps"] = int(max_episode_steps)
            register(
                id=env_id,
                entry_point="env.ricochet_env:RicochetRobotsEnv",
                **kwargs,
            )
        except GymError as e:  # pragma: no cover - depends on gym version behavior
            # Swallow duplicate registration errors; re-raise others
            if "already registered" in str(e).lower():
                return
            raise
    except (ModuleNotFoundError, ImportError):
        # Silently ignore if gymnasium not available
        pass

```

```python
import numpy as np

from env.ricochet_env import RicochetRobotsEnv, FixedLayout
from env.ricochet_core import UP, LEFT, RIGHT


def make_simple_layout():
    H, W = 5, 5
    # Edge walls init with borders
    h_walls = np.zeros((H + 1, W), dtype=bool)
    v_walls = np.zeros((H, W + 1), dtype=bool)
    h_walls[0, :] = True
    h_walls[H, :] = True
    v_walls[:, 0] = True
    v_walls[:, W] = True
    # Add a horizontal wall above (1,2): between rows 0-1 at col 2
    h_walls[1, 2] = True
    # Add a vertical wall to the right of (0,2): between cols 2-3 at row 0
    v_walls[0, 3] = True
    robots = {0: (3, 2)}
    goal = (0, 2)
    target_robot = 0
    return FixedLayout(height=H, width=W, h_walls=h_walls, v_walls=v_walls, robot_positions=robots, goal_position=goal, target_robot=target_robot)


def test_slide_and_stop():
    layout = make_simple_layout()
    env = RicochetRobotsEnv(fixed_layout=layout, include_noop=False, step_penalty=0.0)
    _, _ = env.reset()
    action_up = 0 * 4 + UP
    _, _, _, _, _ = env.step(action_up)
    _, _, _, _, _ = env.step(action_up)
    action_right = 0 * 4 + RIGHT
    _, _, _, _, _ = env.step(action_right)
    action_left = 0 * 4 + LEFT
    _, _, terminated, _, _ = env.step(action_left)
    assert not terminated


def test_goal_termination_and_reward():
    layout = make_simple_layout()
    env = RicochetRobotsEnv(fixed_layout=layout, include_noop=False, step_penalty=-0.01, goal_reward=1.0)
    _, _ = env.reset()
    # Move up to (2,2) if possible; with h_wall at (1,2), robot at (3,2) moves to (2,2)
    _, r1, term, _, _ = env.step(0 * 4 + UP)
    # Move left to reach column 0
    _, r2, term, _, _ = env.step(0 * 4 + LEFT)
    # Move up to row 0
    _, r3, term, _, _ = env.step(0 * 4 + UP)
    # Move right; v_wall at (0,3) should cause stopping on (0,2) goal
    _, r4, term, _, info = env.step(0 * 4 + RIGHT)
    assert term
    assert info.get("is_success", False)
    total_reward = r1 + r2 + r3 + r4
    assert total_reward > 0.9


def test_multi_robot_blocking_and_truncation():
    H, W = 5, 5
    h_walls = np.zeros((H + 1, W), dtype=bool)
    v_walls = np.zeros((H, W + 1), dtype=bool)
    h_walls[0, :] = True
    h_walls[H, :] = True
    v_walls[:, 0] = True
    v_walls[:, W] = True
    robots = {0: (4, 2), 1: (2, 2)}
    goal = (0, 0)
    layout = FixedLayout(height=H, width=W, h_walls=h_walls, v_walls=v_walls, robot_positions=robots, goal_position=goal, target_robot=0)
    env = RicochetRobotsEnv(fixed_layout=layout, include_noop=False, step_penalty=0.0, max_steps=3)
    _, _ = env.reset()
    # Move robot 0 up; should stop at (3,2) because robot 1 occupies (2,2)
    _, _, _, _, _ = env.step(0 * 4 + UP)
    # Move robot 1 left, then right; episode should truncate due to max_steps
    _, _, _, _, _ = env.step(1 * 4 + LEFT)
    _, _, term, trunc, _ = env.step(1 * 4 + RIGHT)
    assert not term
    assert trunc

```

```markdown
# Ricochet Robots RL Environment (Step 1)

This repository contains a custom Gymnasium-compatible environment for the Ricochet Robots puzzle, a BFS solver for validation/curriculum, and unit tests.

## Setup

Install dependencies:

```bash
pip install -r requirements.txt
```

## Run Tests

```bash
pytest -q
```

## Usage Example

```python
from env.ricochet_env import RicochetRobotsEnv

env = RicochetRobotsEnv(height=8, width=8, num_robots=2, render_mode="ascii")
obs, info = env.reset(seed=123)
action = 0  # robot 0 up
obs, reward, terminated, truncated, info = env.step(action)
print(env.render())
```

### Gymnasium Registration (optional)

To create the env via gym.make:

```python
import gymnasium as gym
from env.ricochet_env import register_env

register_env("RicochetRobots-v0", max_episode_steps=100)
env = gym.make("RicochetRobots-v0", height=8, width=8, num_robots=2, render_mode="ascii")
```

### Notes on API compliance

- Seeding follows Gymnasium: use `reset(seed=...)`. The used seed is provided in `info["episode_seed"]`.
- Rendering uses `render_mode`. With `render_mode="ascii"`, `render()` returns a string. Other modes are not implemented and will raise a clear error.
- The `info` dict includes `is_success` each step, and `TimeLimit.truncated` when the episode hits `max_steps`.
- The environment already enforces a time limit via `max_steps`; avoid wrapping with `TimeLimit` unless you disable the internal cap.

### Import path

Ensure the project root is on `PYTHONPATH` (e.g., run from repo root or `pip install -e .`) so the entry point `env.ricochet_env:RicochetRobotsEnv` is importable when registering.

### Observation scaling

- Image observations are float32 in [0,1].
- Symbolic observations use absolute grid indices (float32); downstream code may normalize to [0,1].

```

- Implemented all requested polish and consistency fixes across the env and docs.

Key updates:
- Success key
  - Removed duplicate `success`; now only `info["is_success"]` is used and always present (True/False).
  - Updated `tests/test_env.py` to assert `is_success`.

- Registration helper
  - `register_env(env_id, max_episode_steps=...)` now supports `max_episode_steps` in Gyms registry and gracefully ignores already registered.
  - Clarified import path requirement in README.

- Determinism and seeding docs
  - Added a class docstring detailing determinism guarantees, seeding behavior, and retry semantics when `ensure_solvable=True`.

- Action validation
  - Invalid actions raise `gymnasium.error.InvalidAction` when available, with `ValueError` fallback otherwise.

- Reset/cache
  - Clear `_cached_wall_obs` at the start of `reset()` to prevent any stale cache.

- Documentation improvements
  - README: clarified `render_mode` behavior (only ascii), time-limit note, `PYTHONPATH` requirement, observation scaling (image in [0,1], symbolic absolute indices).
  - Class docstring documents channel duplication (target mask and robot channel).

All tasks for this round are complete:
- Unified success key
- Registration with max_episode_steps
- Determinism/seeding docstring
- Exposed ensure_attempt_limit parameter
- README clarifications

---

**User**

Hi, I've attached the latest feedback - please read and act upon it - thanks!


---

**Cursor**

```python
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple, List, Literal

import numpy as np

from .ricochet_core import Board, apply_action, reached_goal

# Provide a runtime gymnasium binding if available, otherwise a minimal fallback
try:  # pragma: no cover
    import importlib
    _gym = importlib.import_module("gymnasium")  # type: ignore
    _spaces = importlib.import_module("gymnasium.spaces")  # type: ignore
    _seeding = importlib.import_module("gymnasium.utils.seeding")  # type: ignore
    _error = importlib.import_module("gymnasium.error")  # type: ignore
    GymEnvBase = _gym.Env  # type: ignore
    spaces = _spaces  # type: ignore
    GymInvalidAction = getattr(_error, "InvalidAction", None)  # type: ignore
except (ModuleNotFoundError, ImportError):  # pragma: no cover
    class GymEnvBase(object):
        pass
    class _SpacesDummy:  # minimal placeholders to satisfy type usage
        class Box:  # type: ignore
            def __init__(self, low=None, high=None, shape=None, dtype=None):
                self.low = low
                self.high = high
                self.shape = shape
                self.dtype = dtype
        class Discrete:  # type: ignore
            def __init__(self, n: int):
                self.n = n
    spaces = _SpacesDummy()  # type: ignore
    GymInvalidAction = None  # type: ignore


@dataclass
class FixedLayout:
    height: int
    width: int
    # Edge walls
    h_walls: np.ndarray  # (H+1, W) bool
    v_walls: np.ndarray  # (H, W+1) bool
    robot_positions: Dict[int, Tuple[int, int]]
    goal_position: Tuple[int, int]
    target_robot: int


ObsMode = Literal["image", "symbolic"]


class RicochetRobotsEnv(GymEnvBase):
    """Ricochet Robots Gymnasium-compatible environment.

    Determinism and seeding:
    - Deterministic given the seed provided to __init__ or reset(seed=...).
    - Randomness flows through self.np_random (Gymnasium seeding utils); the episode's resolved
      seed is exposed via info["episode_seed"].
    - When ensure_solvable=True, the environment may retry board generation; retries do not add
      extra non-determinism beyond RNG draws. The included solver is deterministic.

    Observations:
    - Image mode: float32 in [0,1]. Channels are named by channel_names; note that the target robot
      is represented both by a dedicated mask (index 5) and its robot channel (duplication by design).
    - Symbolic mode: float32 with absolute grid indices (not normalized). Downstream code may wish to
      normalize to [0,1]. The Box low/high reflect board bounds.

    Rendering:
    - Only render_mode="ascii" is implemented and returns a string frame.
    - Other modes are not implemented and will raise a clear error.
    """
    metadata = {"render_modes": ["ascii"], "render_fps": 4}

    def __init__(
        self,
        height: int = 8,
        width: int = 8,
        num_robots: int = 2,
        include_noop: bool = True,
        step_penalty: float = -0.01,
        goal_reward: float = 1.0,
        noop_penalty: Optional[float] = None,
        max_steps: int = 100,
        fixed_layout: Optional[FixedLayout] = None,
        seed: Optional[int] = None,
        ensure_solvable: bool = False,
        solver_max_depth: int = 30,
        solver_max_nodes: int = 20000,
        obs_mode: ObsMode = "image",
        channels_first: bool = False,
        render_mode: Optional[str] = None,
        ensure_attempt_limit: int = 50,
    ) -> None:
        super().__init__()
        self.height = height
        self.width = width
        self.num_robots = num_robots
        self.include_noop = include_noop
        self.step_penalty = step_penalty
        self.goal_reward = goal_reward
        self.noop_penalty = step_penalty if noop_penalty is None else noop_penalty
        self.max_steps = max_steps
        self.fixed_layout = fixed_layout
        self.ensure_solvable = ensure_solvable
        self.solver_max_depth = solver_max_depth
        self.solver_max_nodes = solver_max_nodes
        self.obs_mode: ObsMode = obs_mode
        self.channels_first = channels_first
        # Render API
        self.render_mode = render_mode
        if self.render_mode is not None and self.render_mode not in self.metadata["render_modes"]:
            raise ValueError(f"Unsupported render_mode {self.render_mode}. Supported: {self.metadata['render_modes']}")

        # Seeding: adopt Gymnasium convention with self.np_random
        self.np_random: np.random.Generator
        self._episode_seed: Optional[int] = None
        try:  # gymnasium present
            # _seeding.np_random returns (rng, seed)
            self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
            self._episode_seed = int(used_seed) if used_seed is not None else None
        except NameError:
            self.np_random = np.random.default_rng(seed)
            self._episode_seed = int(seed) if seed is not None else None
        self._board: Optional[Board] = None
        self._num_steps = 0
        self._cached_wall_obs: Optional[np.ndarray] = None  # (H,W,4) float32 for wall channels
        self._ensure_attempt_limit = int(ensure_attempt_limit)

        # Observation spaces
        if self.obs_mode == "image":
            # channels: up_wall, down_wall, left_wall, right_wall, goal, target_mask, robots...
            self._base_wall_channels = 4
            self._base_misc_channels = 2  # goal, target
            self._num_channels = self._base_wall_channels + self._base_misc_channels + self.num_robots
            if self.channels_first:
                obs_shape = (self._num_channels, self.height, self.width)
            else:
                obs_shape = (self.height, self.width, self._num_channels)
            self.observation_space = spaces.Box(
                low=0.0,
                high=1.0,
                shape=obs_shape,
                dtype=np.float32,
            )
        elif self.obs_mode == "symbolic":
            # [goal_r, goal_c] in [0..H-1], [0..W-1]; one-hot target in [0,1]; robots positions in bounds
            vec_len = 2 + self.num_robots + (self.num_robots * 2)
            low = np.full((vec_len,), 0.0, dtype=np.float32)
            high = np.full((vec_len,), 1.0, dtype=np.float32)
            # goal bounds
            low[0] = 0.0
            high[0] = float(self.height - 1)
            low[1] = 0.0
            high[1] = float(self.width - 1)
            # target one-hot already [0,1]
            # robots positions
            base = 2 + self.num_robots
            for i in range(self.num_robots):
                low[base + 2 * i] = 0.0
                high[base + 2 * i] = float(self.height - 1)
                low[base + 2 * i + 1] = 0.0
                high[base + 2 * i + 1] = float(self.width - 1)
            self.observation_space = spaces.Box(low=low, high=high, shape=(vec_len,), dtype=np.float32)
        else:
            raise ValueError(f"Unknown obs_mode: {self.obs_mode}")

        # Action space: num_robots * 4 directions (+ 1 for noop)
        self._noop_action = self.num_robots * 4 if include_noop else None
        self.action_space = spaces.Discrete(self.num_robots * 4 + (1 if include_noop else 0))

    # Gymnasium API
    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):
        """Reset the environment and start a new episode.

        Returns (obs, info) per Gymnasium API. info contains keys: 'target_robot',
        'level_solvable' (optional), 'optimal_length' (if ensured), 'solver_limits' (if ensured),
        and 'episode_seed' with the seed used for this episode.
        """
        # Standard seeding protocol
        if seed is not None:
            try:
                self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
                self._episode_seed = int(used_seed) if used_seed is not None else None
            except NameError:
                self.np_random = np.random.default_rng(seed)
                self._episode_seed = int(seed)
        _ = options  # silence unused
        self._num_steps = 0
        # clear cached walls in case layout changes
        self._cached_wall_obs = None

        if self.fixed_layout is not None:
            self._board = Board(
                height=self.fixed_layout.height,
                width=self.fixed_layout.width,
                h_walls=self.fixed_layout.h_walls.copy(),
                v_walls=self.fixed_layout.v_walls.copy(),
                robot_positions=dict(self.fixed_layout.robot_positions),
                goal_position=self.fixed_layout.goal_position,
                target_robot=self.fixed_layout.target_robot,
            )
            # cache static walls for this layout
            self._build_cached_walls(self._board)
            obs = self._make_obs(self._board)
            info = {
                "level_solvable": False,
                "ensure_solvable_enabled": False,
                "target_robot": self._board.target_robot,
                "episode_seed": self._episode_seed,
            }
            if self.obs_mode == "image":
                info["channel_names"] = self.channel_names
            return obs, info

        # Otherwise, generate random board, optionally ensure solvable via solver
        attempts = 0
        while True:
            attempts += 1
            board = self._generate_random_board()
            if not self.ensure_solvable:
                self._board = board
                break
            try:
                from .solver import solve_bfs  # type: ignore
                solution = solve_bfs(board, max_depth=self.solver_max_depth, max_nodes=self.solver_max_nodes)
                if solution is not None:
                    self._board = board
                    optimal_length = len(solution)
                    break
            except ImportError as exc:
                raise RuntimeError("ensure_solvable=True but solver unavailable (ImportError)") from exc
            if attempts >= self._ensure_attempt_limit:
                raise RuntimeError("Failed to generate solvable board within attempt limit")

        # cache static walls for this layout
        assert self._board is not None
        self._build_cached_walls(self._board)
        obs = self._make_obs(self._board)
        # Note: solver None during attempts may be due to cutoffs (depth/nodes), not true unsolvability.
        info = {
            "level_solvable": bool(self.ensure_solvable),
            "ensure_solvable_enabled": bool(self.ensure_solvable),
            "target_robot": self._board.target_robot,
            "episode_seed": self._episode_seed,
        }
        if self.obs_mode == "image":
            info["channel_names"] = self.channel_names
        if self.ensure_solvable:
            info["optimal_length"] = optimal_length
            info["solver_limits"] = {"max_depth": self.solver_max_depth, "max_nodes": self.solver_max_nodes}
        return obs, info

    def step(self, action: int):
        """Apply an action and return (obs, reward, terminated, truncated, info).

        info always includes 'steps', 'target_robot', and 'is_success' (bool). When truncated due to
        max steps, info includes 'TimeLimit.truncated'=True.
        """
        assert self._board is not None, "Call reset() first"
        self._num_steps += 1

        terminated = False
        truncated = False
        info: Dict[str, object] = {}

        reward = self.step_penalty
        # Validate action range early
        if not (0 <= action < self.action_space.n):
            if GymInvalidAction is not None:
                raise GymInvalidAction(f"Invalid action {action}")  # type: ignore[misc]
            raise ValueError(f"Invalid action {action}")

        if self.include_noop and action == self._noop_action:
            reward = self.noop_penalty
        else:
            robot_id, direction = self._decode_action(action)
            self._board = apply_action(self._board, robot_id, direction)

        if reached_goal(self._board):
            reward += self.goal_reward
            terminated = True
            info["is_success"] = True

        if not terminated and self._num_steps >= self.max_steps:
            truncated = True
            info["TimeLimit.truncated"] = True

        obs = self._make_obs(self._board)
        info["steps"] = self._num_steps
        info["target_robot"] = self._board.target_robot
        if "is_success" not in info:
            info["is_success"] = False
        return obs, reward, terminated, truncated, info

    def render(self):
        """Render according to render_mode.

        - render_mode=="ascii": returns a string frame.
        - render_mode is None or unsupported: returns None.
        """
        if self.render_mode is None:
            return None
        if self.render_mode != "ascii":
            raise ValueError(f"Unsupported render_mode {self.render_mode}. Supported: {self.metadata['render_modes']}")
        if self._board is None:
            return ""
        from .ricochet_core import render_ascii  # local import to avoid circulars in lints
        return render_ascii(self._board)

    def close(self) -> None:
        """Close environment resources (no-op)."""
        return None

    def seed(self, seed: Optional[int] = None):  # legacy convenience
        """Legacy seeding helper returning [seed]. Prefer reset(seed=...)."""
        if seed is None:
            return [self._episode_seed]
        try:
            self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
            self._episode_seed = int(used_seed) if used_seed is not None else int(seed)
        except NameError:
            self.np_random = np.random.default_rng(seed)
            self._episode_seed = int(seed)
        return [self._episode_seed]

    # Helpers
    def _decode_action(self, action: int) -> Tuple[int, int]:
        if not (0 <= action < self.action_space.n):
            raise ValueError(f"Invalid action {action}")
        if self.include_noop and action == self._noop_action:
            raise ValueError("_decode_action called on noop action")
        robot_id = action // 4
        direction = action % 4
        if robot_id >= self.num_robots:
            raise ValueError(f"Invalid robot_id {robot_id} for action {action}")
        return robot_id, direction

    def _make_obs(self, board: Board) -> np.ndarray:
        if self.obs_mode == "image":
            return self._board_to_image_obs(board)
        return self._board_to_symbolic_obs(board)

    def _board_to_image_obs(self, board: Board) -> np.ndarray:
        h, w = board.height, board.width
        C = self._num_channels
        obs = np.zeros((h, w, C), dtype=np.float32)
        # wall channels 0..3 from cache
        if self._cached_wall_obs is not None:
            obs[:, :, 0:4] = self._cached_wall_obs
        else:
            # Fallback if cache not built (should not happen)
            for r in range(h):
                for c in range(w):
                    obs[r, c, 0] = 1.0 if board.has_wall_up(r, c) else 0.0
                    obs[r, c, 1] = 1.0 if board.has_wall_down(r, c) else 0.0
                    obs[r, c, 2] = 1.0 if board.has_wall_left(r, c) else 0.0
                    obs[r, c, 3] = 1.0 if board.has_wall_right(r, c) else 0.0
        # goal channel 4
        gr, gc = board.goal_position
        obs[gr, gc, 4] = 1.0
        # target mask channel 5
        tr = board.target_robot
        tr_r, tr_c = board.robot_positions[tr]
        obs[tr_r, tr_c, 5] = 1.0
        # robot channels start at 6
        base = 6
        for rid, (r, c) in board.robot_positions.items():
            obs[r, c, base + rid] = 1.0
        if self.channels_first:
            obs = np.transpose(obs, (2, 0, 1))
        return obs

    def _board_to_symbolic_obs(self, board: Board) -> np.ndarray:
        gr, gc = board.goal_position
        target_one_hot = np.zeros((self.num_robots,), dtype=np.float32)
        target_one_hot[board.target_robot] = 1.0
        robots_vec: List[float] = []
        for rid in range(self.num_robots):
            r, c = board.robot_positions[rid]
            robots_vec.extend([float(r), float(c)])
        vec = np.concatenate([
            np.array([float(gr), float(gc)], dtype=np.float32),
            target_one_hot.astype(np.float32),
            np.array(robots_vec, dtype=np.float32),
        ])
        return vec

    def _generate_random_board(self) -> Board:
        h, w = self.height, self.width
        # Start with open grid, then add random interior edge walls, and border walls
        h_walls = np.zeros((h + 1, w), dtype=bool)
        v_walls = np.zeros((h, w + 1), dtype=bool)
        # Borders
        h_walls[0, :] = True
        h_walls[h, :] = True
        v_walls[:, 0] = True
        v_walls[:, w] = True
        # Random interior edges
        max_edges = max(1, (h * w) // 6)
        num_edges = int(self.np_random.integers(0, max_edges))
        for _ in range(num_edges):
            if self.np_random.integers(0, 2) == 0:
                rr = int(self.np_random.integers(1, h))
                cc = int(self.np_random.integers(0, w))
                h_walls[rr, cc] = True
            else:
                rr = int(self.np_random.integers(0, h))
                cc = int(self.np_random.integers(1, w))
                v_walls[rr, cc] = True
        # Place goal and robots in free cells
        free_cells: List[Tuple[int, int]] = [(r, c) for r in range(h) for c in range(w)]
        self.np_random.shuffle(free_cells)
        goal = free_cells.pop()
        robot_positions: Dict[int, Tuple[int, int]] = {}
        for rid in range(self.num_robots):
            robot_positions[rid] = free_cells.pop()
        target_robot = int(self.np_random.integers(0, self.num_robots))
        return Board(height=h, width=w, h_walls=h_walls, v_walls=v_walls, robot_positions=robot_positions, goal_position=goal, target_robot=target_robot)

    # Public channel names for image observations
    @property
    def channel_names(self) -> List[str]:
        """Human-readable names for image observation channels."""
        names = ["wall_up", "wall_down", "wall_left", "wall_right", "goal", "target_robot_mask"]
        names.extend([f"robot_{i}" for i in range(self.num_robots)])
        return names

    def _build_cached_walls(self, board: Board) -> None:
        """Precompute static wall indicator channels (H,W,4)."""
        h, w = board.height, board.width
        wall = np.zeros((h, w, 4), dtype=np.float32)
        for r in range(h):
            for c in range(w):
                wall[r, c, 0] = 1.0 if board.has_wall_up(r, c) else 0.0
                wall[r, c, 1] = 1.0 if board.has_wall_down(r, c) else 0.0
                wall[r, c, 2] = 1.0 if board.has_wall_left(r, c) else 0.0
                wall[r, c, 3] = 1.0 if board.has_wall_right(r, c) else 0.0
        self._cached_wall_obs = wall


# Optional helper for registration with gymnasium
def register_env(env_id: str = "RicochetRobots-v0", *, max_episode_steps: Optional[int] = None) -> None:
    """Register this environment with gymnasium so it can be created via gym.make(env_id)."""
    try:
        from gymnasium.envs.registration import register  # type: ignore
        from gymnasium.error import Error as GymError  # type: ignore
        try:
            kwargs = {}
            if max_episode_steps is not None:
                kwargs["max_episode_steps"] = int(max_episode_steps)
            register(
                id=env_id,
                entry_point="env.ricochet_env:RicochetRobotsEnv",
                **kwargs,
            )
        except GymError as e:  # pragma: no cover - depends on gym version behavior
            # Swallow duplicate registration errors; re-raise others
            if "already registered" in str(e).lower():
                return
            raise
    except (ModuleNotFoundError, ImportError):
        # Silently ignore if gymnasium not available
        pass

```

```markdown
# Ricochet Robots RL Environment (Step 1)

This repository contains a custom Gymnasium-compatible environment for the Ricochet Robots puzzle, a BFS solver for validation/curriculum, and unit tests.

## Setup

Install dependencies:

```bash
pip install -r requirements.txt
```

## Run Tests

```bash
pytest -q
```

## Usage Example

```python
from env.ricochet_env import RicochetRobotsEnv

env = RicochetRobotsEnv(height=8, width=8, num_robots=2, render_mode="ascii")
obs, info = env.reset(seed=123)
action = 0  # robot 0 up
obs, reward, terminated, truncated, info = env.step(action)
print(env.render())
```

### Gymnasium Registration (optional)

To create the env via gym.make:

```python
import gymnasium as gym
from env.ricochet_env import register_env

register_env("RicochetRobots-v0", max_episode_steps=100)
env = gym.make("RicochetRobots-v0", height=8, width=8, num_robots=2, render_mode="ascii")
```

### Notes on API compliance

- Seeding follows Gymnasium: use `reset(seed=...)`. The used seed is provided in `info["episode_seed"]`.
- Rendering uses `render_mode`. With `render_mode="ascii"`, `render()` returns a string. Other modes are not implemented and will raise a clear error.
- The `info` dict includes `is_success` each step, and `TimeLimit.truncated` when the episode hits `max_steps`.
- The environment already enforces a time limit via `max_steps`; avoid wrapping with `TimeLimit` unless you disable the internal cap.

Additional info keys on reset:
- `level_solvable` (bool): True if solvability was enforced this episode; False otherwise.
- `ensure_solvable_enabled` (bool): whether solvability enforcement was enabled.
- `channel_names` (image mode): the list of observation channel names for logging.
- Invalid actions raise `gymnasium.error.InvalidAction` when Gymnasium is installed, or `ValueError` otherwise.

### Import path

Ensure the project root is on `PYTHONPATH` (e.g., run from repo root or `pip install -e .`) so the entry point `env.ricochet_env:RicochetRobotsEnv` is importable when registering.

### Observation scaling

- Image observations are float32 in [0,1].
- Symbolic observations use absolute grid indices (float32); downstream code may normalize to [0,1].

```

```python
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple, List, Literal

import numpy as np

from .ricochet_core import Board, apply_action, reached_goal

# Provide a runtime gymnasium binding if available, otherwise a minimal fallback
try:  # pragma: no cover
    import importlib
    _gym = importlib.import_module("gymnasium")  # type: ignore
    _spaces = importlib.import_module("gymnasium.spaces")  # type: ignore
    _seeding = importlib.import_module("gymnasium.utils.seeding")  # type: ignore
    _error = importlib.import_module("gymnasium.error")  # type: ignore
    GymEnvBase = _gym.Env  # type: ignore
    spaces = _spaces  # type: ignore
    GymInvalidAction = getattr(_error, "InvalidAction", None)  # type: ignore
except (ModuleNotFoundError, ImportError):  # pragma: no cover
    class GymEnvBase(object):
        pass
    class _SpacesDummy:  # minimal placeholders to satisfy type usage
        class Box:  # type: ignore
            def __init__(self, low=None, high=None, shape=None, dtype=None):
                self.low = low
                self.high = high
                self.shape = shape
                self.dtype = dtype
        class Discrete:  # type: ignore
            def __init__(self, n: int):
                self.n = n
    spaces = _SpacesDummy()  # type: ignore
    GymInvalidAction = None  # type: ignore


@dataclass
class FixedLayout:
    height: int
    width: int
    # Edge walls
    h_walls: np.ndarray  # (H+1, W) bool
    v_walls: np.ndarray  # (H, W+1) bool
    robot_positions: Dict[int, Tuple[int, int]]
    goal_position: Tuple[int, int]
    target_robot: int


ObsMode = Literal["image", "symbolic"]


class RicochetRobotsEnv(GymEnvBase):
    """Ricochet Robots Gymnasium-compatible environment.

    Determinism and seeding:
    - Deterministic given the seed provided to __init__ or reset(seed=...).
    - Randomness flows through self.np_random (Gymnasium seeding utils); the episode's resolved
      seed is exposed via info["episode_seed"].
    - When ensure_solvable=True, the environment may retry board generation; retries do not add
      extra non-determinism beyond RNG draws. The included solver is deterministic.

    Observations:
    - Image mode: float32 in [0,1]. Channels are named by channel_names; note that the target robot
      is represented both by a dedicated mask (index 5) and its robot channel (duplication by design).
    - Symbolic mode: float32 with absolute grid indices (not normalized). Downstream code may wish to
      normalize to [0,1]. The Box low/high reflect board bounds.

    Rendering:
    - Only render_mode="ascii" is implemented and returns a string frame.
    - Other modes are not implemented and will raise a clear error.
    """
    metadata = {"render_modes": ["ascii"], "render_fps": 4}

    def __init__(
        self,
        height: int = 8,
        width: int = 8,
        num_robots: int = 2,
        include_noop: bool = True,
        step_penalty: float = -0.01,
        goal_reward: float = 1.0,
        noop_penalty: Optional[float] = None,
        max_steps: int = 100,
        fixed_layout: Optional[FixedLayout] = None,
        seed: Optional[int] = None,
        ensure_solvable: bool = False,
        solver_max_depth: int = 30,
        solver_max_nodes: int = 20000,
        obs_mode: ObsMode = "image",
        channels_first: bool = False,
        render_mode: Optional[str] = None,
        ensure_attempt_limit: int = 50,
    ) -> None:
        super().__init__()
        self.height = height
        self.width = width
        self.num_robots = num_robots
        self.include_noop = include_noop
        self.step_penalty = step_penalty
        self.goal_reward = goal_reward
        self.noop_penalty = step_penalty if noop_penalty is None else noop_penalty
        self.max_steps = max_steps
        self.fixed_layout = fixed_layout
        self.ensure_solvable = ensure_solvable
        self.solver_max_depth = solver_max_depth
        self.solver_max_nodes = solver_max_nodes
        self.obs_mode: ObsMode = obs_mode
        self.channels_first = channels_first
        # Render API
        self.render_mode = render_mode
        if self.render_mode is not None and self.render_mode not in self.metadata["render_modes"]:
            raise ValueError(f"Unsupported render_mode {self.render_mode}. Supported: {self.metadata['render_modes']}")

        # Seeding: adopt Gymnasium convention with self.np_random
        self.np_random: np.random.Generator
        self._episode_seed: Optional[int] = None
        try:  # gymnasium present
            # _seeding.np_random returns (rng, seed)
            self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
            self._episode_seed = int(used_seed) if used_seed is not None else None
        except NameError:
            self.np_random = np.random.default_rng(seed)
            self._episode_seed = int(seed) if seed is not None else None
        self._board: Optional[Board] = None
        self._num_steps = 0
        self._cached_wall_obs: Optional[np.ndarray] = None  # (H,W,4) float32 for wall channels
        self._ensure_attempt_limit = int(ensure_attempt_limit)

        # Observation spaces
        if self.obs_mode == "image":
            # channels: up_wall, down_wall, left_wall, right_wall, goal, target_mask, robots...
            self._base_wall_channels = 4
            self._base_misc_channels = 2  # goal, target
            self._num_channels = self._base_wall_channels + self._base_misc_channels + self.num_robots
            if self.channels_first:
                obs_shape = (self._num_channels, self.height, self.width)
            else:
                obs_shape = (self.height, self.width, self._num_channels)
            self.observation_space = spaces.Box(
                low=0.0,
                high=1.0,
                shape=obs_shape,
                dtype=np.float32,
            )
        elif self.obs_mode == "symbolic":
            # [goal_r, goal_c] in [0..H-1], [0..W-1]; one-hot target in [0,1]; robots positions in bounds
            vec_len = 2 + self.num_robots + (self.num_robots * 2)
            low = np.full((vec_len,), 0.0, dtype=np.float32)
            high = np.full((vec_len,), 1.0, dtype=np.float32)
            # goal bounds
            low[0] = 0.0
            high[0] = float(self.height - 1)
            low[1] = 0.0
            high[1] = float(self.width - 1)
            # target one-hot already [0,1]
            # robots positions
            base = 2 + self.num_robots
            for i in range(self.num_robots):
                low[base + 2 * i] = 0.0
                high[base + 2 * i] = float(self.height - 1)
                low[base + 2 * i + 1] = 0.0
                high[base + 2 * i + 1] = float(self.width - 1)
            self.observation_space = spaces.Box(low=low, high=high, shape=(vec_len,), dtype=np.float32)
        else:
            raise ValueError(f"Unknown obs_mode: {self.obs_mode}")

        # Action space: num_robots * 4 directions (+ 1 for noop)
        self._noop_action = self.num_robots * 4 if include_noop else None
        self.action_space = spaces.Discrete(self.num_robots * 4 + (1 if include_noop else 0))

    # Gymnasium API
    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):
        """Reset the environment and start a new episode.

        Returns (obs, info) per Gymnasium API. info contains keys: 'target_robot',
        'level_solvable' (optional), 'optimal_length' (if ensured), 'solver_limits' (if ensured),
        and 'episode_seed' with the seed used for this episode.
        """
        # Standard seeding protocol
        if seed is not None:
            try:
                self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
                self._episode_seed = int(used_seed) if used_seed is not None else None
            except NameError:
                self.np_random = np.random.default_rng(seed)
                self._episode_seed = int(seed)
        _ = options  # silence unused
        self._num_steps = 0
        # clear cached walls in case layout changes
        self._cached_wall_obs = None

        if self.fixed_layout is not None:
            self._board = Board(
                height=self.fixed_layout.height,
                width=self.fixed_layout.width,
                h_walls=self.fixed_layout.h_walls.copy(),
                v_walls=self.fixed_layout.v_walls.copy(),
                robot_positions=dict(self.fixed_layout.robot_positions),
                goal_position=self.fixed_layout.goal_position,
                target_robot=self.fixed_layout.target_robot,
            )
            # cache static walls for this layout
            self._build_cached_walls(self._board)
            obs = self._make_obs(self._board)
            info = {
                "level_solvable": False,
                "ensure_solvable_enabled": False,
                "target_robot": self._board.target_robot,
                "episode_seed": self._episode_seed,
            }
            if self.obs_mode == "image":
                info["channel_names"] = self.channel_names
            return obs, info

        # Otherwise, generate random board, optionally ensure solvable via solver
        attempts = 0
        while True:
            attempts += 1
            board = self._generate_random_board()
            if not self.ensure_solvable:
                self._board = board
                break
            try:
                from .solver import solve_bfs  # type: ignore
                solution = solve_bfs(board, max_depth=self.solver_max_depth, max_nodes=self.solver_max_nodes)
                if solution is not None:
                    self._board = board
                    optimal_length = len(solution)
                    break
            except ImportError as exc:
                raise RuntimeError("ensure_solvable=True but solver unavailable (ImportError)") from exc
            if attempts >= self._ensure_attempt_limit:
                raise RuntimeError("Failed to generate solvable board within attempt limit")

        # cache static walls for this layout
        assert self._board is not None
        self._build_cached_walls(self._board)
        obs = self._make_obs(self._board)
        # Note: solver None during attempts may be due to cutoffs (depth/nodes), not true unsolvability.
        info = {
            "level_solvable": bool(self.ensure_solvable),
            "ensure_solvable_enabled": bool(self.ensure_solvable),
            "target_robot": self._board.target_robot,
            "episode_seed": self._episode_seed,
        }
        if self.obs_mode == "image":
            info["channel_names"] = self.channel_names
        if self.ensure_solvable:
            info["optimal_length"] = optimal_length
            info["solver_limits"] = {"max_depth": self.solver_max_depth, "max_nodes": self.solver_max_nodes}
        return obs, info

    def step(self, action: int):
        """Apply an action and return (obs, reward, terminated, truncated, info).

        info always includes 'steps', 'target_robot', and 'is_success' (bool). When truncated due to
        max steps, info includes 'TimeLimit.truncated'=True.
        """
        assert self._board is not None, "Call reset() first"
        self._num_steps += 1

        terminated = False
        truncated = False
        info: Dict[str, object] = {}

        reward = self.step_penalty
        # Validate action range early
        if not (0 <= action < self.action_space.n):
            if GymInvalidAction is not None:
                raise GymInvalidAction(f"Invalid action {action}")  # type: ignore[misc]
            raise ValueError(f"Invalid action {action}")

        if self.include_noop and action == self._noop_action:
            reward = self.noop_penalty
        else:
            robot_id, direction = self._decode_action(action)
            self._board = apply_action(self._board, robot_id, direction)

        if reached_goal(self._board):
            reward += self.goal_reward
            terminated = True
            info["is_success"] = True

        if not terminated and self._num_steps >= self.max_steps:
            truncated = True
            info["TimeLimit.truncated"] = True

        obs = self._make_obs(self._board)
        info["steps"] = self._num_steps
        info["target_robot"] = self._board.target_robot
        if "is_success" not in info:
            info["is_success"] = False
        return obs, reward, terminated, truncated, info

    def render(self):
        """Render according to render_mode.

        - render_mode=="ascii": returns a string frame.
        - render_mode is None or unsupported: returns None.
        """
        if self.render_mode is None:
            return None
        if self.render_mode != "ascii":
            raise ValueError(f"Unsupported render_mode {self.render_mode}. Supported: {self.metadata['render_modes']}")
        if self._board is None:
            return ""
        from .ricochet_core import render_ascii  # local import to avoid circulars in lints
        return render_ascii(self._board)

    def close(self) -> None:
        """Close environment resources (no-op)."""
        return None

    def seed(self, seed: Optional[int] = None):  # legacy convenience
        """Legacy seeding helper returning [seed]. Prefer reset(seed=...)."""
        if seed is None:
            return [self._episode_seed]
        try:
            self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
            self._episode_seed = int(used_seed) if used_seed is not None else int(seed)
        except NameError:
            self.np_random = np.random.default_rng(seed)
            self._episode_seed = int(seed)
        return [self._episode_seed]

    # Helpers
    def _decode_action(self, action: int) -> Tuple[int, int]:
        if not (0 <= action < self.action_space.n):
            raise ValueError(f"Invalid action {action}")
        if self.include_noop and action == self._noop_action:
            raise ValueError("_decode_action called on noop action")
        robot_id = action // 4
        direction = action % 4
        if robot_id >= self.num_robots:
            raise ValueError(f"Invalid robot_id {robot_id} for action {action}")
        return robot_id, direction

    def _make_obs(self, board: Board) -> np.ndarray:
        if self.obs_mode == "image":
            return self._board_to_image_obs(board)
        return self._board_to_symbolic_obs(board)

    def _board_to_image_obs(self, board: Board) -> np.ndarray:
        h, w = board.height, board.width
        C = self._num_channels
        obs = np.zeros((h, w, C), dtype=np.float32)
        # wall channels 0..3 from cache
        if self._cached_wall_obs is not None:
            obs[:, :, 0:4] = self._cached_wall_obs
        else:
            # Fallback if cache not built (should not happen)
            for r in range(h):
                for c in range(w):
                    obs[r, c, 0] = 1.0 if board.has_wall_up(r, c) else 0.0
                    obs[r, c, 1] = 1.0 if board.has_wall_down(r, c) else 0.0
                    obs[r, c, 2] = 1.0 if board.has_wall_left(r, c) else 0.0
                    obs[r, c, 3] = 1.0 if board.has_wall_right(r, c) else 0.0
        # goal channel 4
        gr, gc = board.goal_position
        obs[gr, gc, 4] = 1.0
        # target mask channel 5
        tr = board.target_robot
        tr_r, tr_c = board.robot_positions[tr]
        obs[tr_r, tr_c, 5] = 1.0
        # robot channels start at 6
        base = 6
        for rid, (r, c) in board.robot_positions.items():
            obs[r, c, base + rid] = 1.0
        if self.channels_first:
            obs = np.transpose(obs, (2, 0, 1))
        return obs

    def _board_to_symbolic_obs(self, board: Board) -> np.ndarray:
        gr, gc = board.goal_position
        target_one_hot = np.zeros((self.num_robots,), dtype=np.float32)
        target_one_hot[board.target_robot] = 1.0
        robots_vec: List[float] = []
        for rid in range(self.num_robots):
            r, c = board.robot_positions[rid]
            robots_vec.extend([float(r), float(c)])
        vec = np.concatenate([
            np.array([float(gr), float(gc)], dtype=np.float32),
            target_one_hot.astype(np.float32),
            np.array(robots_vec, dtype=np.float32),
        ])
        return vec

    def _generate_random_board(self) -> Board:
        h, w = self.height, self.width
        # Start with open grid, then add random interior edge walls, and border walls
        h_walls = np.zeros((h + 1, w), dtype=bool)
        v_walls = np.zeros((h, w + 1), dtype=bool)
        # Borders
        h_walls[0, :] = True
        h_walls[h, :] = True
        v_walls[:, 0] = True
        v_walls[:, w] = True
        # Random interior edges
        max_edges = max(1, (h * w) // 6)
        num_edges = int(self.np_random.integers(0, max_edges))
        for _ in range(num_edges):
            if self.np_random.integers(0, 2) == 0:
                rr = int(self.np_random.integers(1, h))
                cc = int(self.np_random.integers(0, w))
                h_walls[rr, cc] = True
            else:
                rr = int(self.np_random.integers(0, h))
                cc = int(self.np_random.integers(1, w))
                v_walls[rr, cc] = True
        # Place goal and robots in free cells
        free_cells: List[Tuple[int, int]] = [(r, c) for r in range(h) for c in range(w)]
        self.np_random.shuffle(free_cells)
        goal = free_cells.pop()
        robot_positions: Dict[int, Tuple[int, int]] = {}
        for rid in range(self.num_robots):
            robot_positions[rid] = free_cells.pop()
        target_robot = int(self.np_random.integers(0, self.num_robots))
        return Board(height=h, width=w, h_walls=h_walls, v_walls=v_walls, robot_positions=robot_positions, goal_position=goal, target_robot=target_robot)

    # Public channel names for image observations
    @property
    def channel_names(self) -> List[str]:
        """Human-readable names for image observation channels."""
        names = ["wall_up", "wall_down", "wall_left", "wall_right", "goal", "target_robot_mask"]
        names.extend([f"robot_{i}" for i in range(self.num_robots)])
        return names

    def _build_cached_walls(self, board: Board) -> None:
        """Precompute static wall indicator channels (H,W,4)."""
        h, w = board.height, board.width
        wall = np.zeros((h, w, 4), dtype=np.float32)
        for r in range(h):
            for c in range(w):
                wall[r, c, 0] = 1.0 if board.has_wall_up(r, c) else 0.0
                wall[r, c, 1] = 1.0 if board.has_wall_down(r, c) else 0.0
                wall[r, c, 2] = 1.0 if board.has_wall_left(r, c) else 0.0
                wall[r, c, 3] = 1.0 if board.has_wall_right(r, c) else 0.0
        self._cached_wall_obs = wall


# Optional helper for registration with gymnasium
def register_env(env_id: str = "RicochetRobots-v0", *, max_episode_steps: Optional[int] = None) -> None:
    """Register this environment with gymnasium so it can be created via gym.make(env_id).

    Note: This env already enforces a time limit via its max_steps argument. If you also set
    max_episode_steps here and wrap with Gym's TimeLimit implicitly via gym.make, you may see
    duplicate truncation behavior. Prefer one source of time limits.
    """
    try:
        from gymnasium.envs.registration import register  # type: ignore
        from gymnasium.error import Error as GymError  # type: ignore
        try:
            kwargs = {}
            if max_episode_steps is not None:
                kwargs["max_episode_steps"] = int(max_episode_steps)
            register(
                id=env_id,
                entry_point="env.ricochet_env:RicochetRobotsEnv",
                **kwargs,
            )
        except GymError as e:  # pragma: no cover - depends on gym version behavior
            # Swallow duplicate registration errors; re-raise others
            if "already registered" in str(e).lower():
                return
            raise
    except (ModuleNotFoundError, ImportError):
        # Silently ignore if gymnasium not available
        pass

```

- Ill implement the remaining items now: make `level_solvable` strictly boolean with a companion flag, add channel names into reset info for image mode, and update registration/docstrings to note the InvalidAction fallback and TimeLimit caveat. Ill lint after.

- Done. All requested updates are in.

What changed:
- level_solvable semantics
  - `info["level_solvable"]` is now always boolean.
  - Added `info["ensure_solvable_enabled"]` to indicate enforcement.
  - Applied in both fixed-layout and random-generation reset paths.

- Reset info additions
  - When `obs_mode=="image"`, `info["channel_names"]` is included on reset for easy logging/verification.

- Registration/docstring and README
  - `register_env` docstring now warns about duplicate time limits if using Gyms `TimeLimit` as well as internal `max_steps`.
  - README Notes on API compliance expanded: `level_solvable`, `ensure_solvable_enabled`, `channel_names`, and explicit mention that invalid actions raise `gymnasium.error.InvalidAction` or `ValueError` fallback when Gymnasium is absent.

- Tests
  - Updated `tests/test_env.py` to assert `is_success` (post unification). All lints pass.

All tasks for this round are complete.

