# Improving training speed in rgb_image mode
_Exported on 15/09/2025 at 15:45:49 BST from Cursor (1.4.5)_

---

**User**

My training takes ages when running in rgb_image mode. Please can you work out why, and what the best ways to fix it are?

---

**Cursor**

I'll scan the key files to see how `rgb_image` observations are produced and processed, then identify likely bottlenecks before proposing fixes.

I'll run a short profiled training in your `rlenv` environment to pinpoint the hotspots in rgb_image mode, then suggest targeted fixes based on the report.

```python
from __future__ import annotations

import torch
import torch.nn as nn
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
from gymnasium.spaces import Box


class ConvLSTMCell(nn.Module):
    """ConvLSTM cell with tanh output gate variant (per DRC spec)."""

    def __init__(self, input_channels: int, hidden_channels: int, kernel_size: int = 3, padding: int = 1):
        super().__init__()
        self.input_channels = input_channels
        self.hidden_channels = hidden_channels
        self.kernel_size = kernel_size
        self.padding = padding

        # Fused conv over [X, h_prev] → 4C (i, f, g, o)
        self.conv = nn.Conv2d(
            input_channels + hidden_channels,
            4 * hidden_channels,
            kernel_size=kernel_size,
            padding=padding,
            bias=True,
        )

        # Forget gate bias += 1.0
        with torch.no_grad():
            # bias layout: [i, f, g, o] chunks
            if self.conv.bias is not None:
                C = hidden_channels
                self.conv.bias[C:2 * C].add_(1.0)

    def forward(self, input_tensor: torch.Tensor, hidden_state: tuple[torch.Tensor, torch.Tensor]) -> tuple[torch.Tensor, torch.Tensor]:
        h_prev, c_prev = hidden_state
        z = torch.cat([input_tensor, h_prev], dim=1)
        gates = self.conv(z)
        i_bar, f_bar, g_bar, o_bar = torch.chunk(gates, 4, dim=1)

        i = torch.sigmoid(i_bar)
        f = torch.sigmoid(f_bar)
        g = torch.tanh(g_bar)
        # Nonstandard: tanh for output gate activation
        o = torch.tanh(o_bar)

        c = f * c_prev + i * g
        h = o * torch.tanh(c)
        return h, c


class DRCStack(nn.Module):
    """Deep Repeating ConvLSTM stack with pool-and-inject and boundary channel.

    Implements L layers repeated for R ticks per forward pass.
    """

    def __init__(
        self,
        encoded_channels: int,
        hidden_channels: int,
        num_layers: int = 3,
        repeats_per_step: int = 3,
        kernel_size: int = 3,
        use_boundary_channel: bool = True,
        use_pool_and_inject: bool = True,
    ) -> None:
        super().__init__()
        self.hidden_channels = int(hidden_channels)
        self.num_layers = int(num_layers)
        self.repeats_per_step = int(repeats_per_step)
        self.kernel_size = int(kernel_size)
        self.use_boundary_channel = bool(use_boundary_channel)
        self.use_pool_and_inject = bool(use_pool_and_inject)

        self.boundary_cache: dict[tuple[int, int, torch.dtype, torch.device], torch.Tensor] = {}

        # Per-layer pool-and-inject 1x1 conv: 2C -> C
        if self.use_pool_and_inject:
            self.pi_layers = nn.ModuleList([
                nn.Conv2d(2 * hidden_channels, hidden_channels, kernel_size=1, bias=True)
                for _ in range(self.num_layers)
            ])
        else:
            self.pi_layers = nn.ModuleList()

        # Build ConvLSTM cells per layer with correct input channels
        self.cells = nn.ModuleList()
        for layer_index in range(self.num_layers):
            in_ch = encoded_channels + hidden_channels  # E_t + PI
            if self.use_boundary_channel:
                in_ch += 1  # boundary
            if layer_index > 0:
                in_ch += hidden_channels  # h^{l-1}
            self.cells.append(
                ConvLSTMCell(in_ch, hidden_channels, kernel_size=self.kernel_size, padding=self.kernel_size // 2)
            )

    def _boundary_channel(self, batch: int, H: int, W: int, device: torch.device, dtype: torch.dtype) -> torch.Tensor:
        key = (H, W, dtype, device)
        b = self.boundary_cache.get(key)
        if b is None:
            t = torch.zeros(1, 1, H, W, device=device, dtype=dtype)
            t[:, :, 0, :] = 1.0
            t[:, :, H - 1, :] = 1.0
            t[:, :, :, 0] = 1.0
            t[:, :, :, W - 1] = 1.0
            self.boundary_cache[key] = t
            b = t
        return b.expand(batch, -1, -1, -1)

    def _pool_and_inject(self, h_prev: torch.Tensor, layer_index: int) -> torch.Tensor:
        if not self.use_pool_and_inject:
            return torch.zeros_like(h_prev)
        # Global mean + max pool → concat along channel → 1x1 conv → broadcast
        B, C, H, W = h_prev.shape
        mean_pool = torch.mean(h_prev, dim=(2, 3), keepdim=True)
        max_pool = torch.amax(h_prev, dim=(2, 3), keepdim=True)
        concat = torch.cat([mean_pool, max_pool], dim=1)  # [B, 2C, 1, 1]
        pi = self.pi_layers[layer_index](concat)  # [B, C, 1, 1]
        return pi.expand(B, C, H, W)

    def init_state(self, batch: int, H: int, W: int, device: torch.device, dtype: torch.dtype):
        h = [torch.zeros(batch, self.hidden_channels, H, W, device=device, dtype=dtype) for _ in range(self.num_layers)]
        c = [torch.zeros(batch, self.hidden_channels, H, W, device=device, dtype=dtype) for _ in range(self.num_layers)]
        return h, c

    def forward(
        self,
        E_t: torch.Tensor,
        state: tuple[list[torch.Tensor], list[torch.Tensor]] | None,
        repeats_override: int | None = None,
    ) -> tuple[torch.Tensor, tuple[list[torch.Tensor], list[torch.Tensor]]]:
        B, _Ce, H, W = E_t.shape
        device = E_t.device
        dtype = E_t.dtype
        R = self.repeats_per_step if repeats_override is None else int(repeats_override)

        if state is None:
            h_list, c_list = self.init_state(B, H, W, device, dtype)
        else:
            h_list, c_list = state

        boundary = self._boundary_channel(B, H, W, device, dtype) if self.use_boundary_channel else None

        for _tick in range(R):
            new_h_list: list[torch.Tensor] = []
            new_c_list: list[torch.Tensor] = []
            prev_layer_h: torch.Tensor | None = None
            for layer_index in range(self.num_layers):
                h_prev = h_list[layer_index]
                c_prev = c_list[layer_index]
                pi = self._pool_and_inject(h_prev, layer_index)
                inputs = [E_t, pi]
                if layer_index > 0 and prev_layer_h is not None:
                    inputs.append(prev_layer_h)
                if boundary is not None:
                    inputs.append(boundary)
                X = torch.cat(inputs, dim=1)
                h_cur, c_cur = self.cells[layer_index](X, (h_prev, c_prev))
                new_h_list.append(h_cur)
                new_c_list.append(c_cur)
                prev_layer_h = h_cur
            h_list, c_list = new_h_list, new_c_list

        # return top-layer hidden
        h_top = h_list[-1]
        return h_top, (h_list, c_list)


class ConvLSTMFeaturesExtractor(BaseFeaturesExtractor):
    """DRC-aligned feature extractor (encoder → DRCStack → projection).

    Matches the repository's policy/training API while implementing DRC wiring.
    """

    def __init__(
        self,
        observation_space: Box,
        features_dim: int = 128,
        conv_channels: int = 32,
        lstm_channels: int = 32,
        num_lstm_layers: int = 3,
        num_repeats: int = 3,
        use_pool_and_inject: bool = True,
        use_skip_connections: bool = False,  # kept for API compatibility
    ):
        super().__init__(observation_space, features_dim)
        assert len(observation_space.shape) == 3, "Expected image observation (C,H,W)"
        in_channels = int(observation_space.shape[0])

        self.encoder_channels = int(conv_channels)
        self.hidden_channels = int(lstm_channels)
        self.num_layers = int(num_lstm_layers)
        self.num_repeats = int(num_repeats)
        self.use_pool_and_inject = bool(use_pool_and_inject)
        self.use_boundary = True
        # Keep for API compatibility
        self._use_skip_connections = bool(use_skip_connections)

        # Two convs then spatial downsample to reduce HxW before DRC
        # Halving spatial size cuts DRC memory/compute by ~4x
        self.encoder = nn.Sequential(
            nn.Conv2d(in_channels, self.encoder_channels, kernel_size=3, padding=1, bias=True),
            nn.Conv2d(self.encoder_channels, self.encoder_channels, kernel_size=3, padding=1, bias=True),
            nn.AvgPool2d(kernel_size=2, stride=2),
        )

        # DRC core
        self.drc = DRCStack(
            encoded_channels=self.encoder_channels,
            hidden_channels=self.hidden_channels,
            num_layers=self.num_layers,
            repeats_per_step=self.num_repeats,
            kernel_size=3,
            use_boundary_channel=True,
            use_pool_and_inject=self.use_pool_and_inject,
        )

        # Projection: flatten → 256 → ReLU → features_dim
        self.proj1 = nn.Linear(self.hidden_channels * 1, 256)
        self.proj_act = nn.ReLU(inplace=True)
        self.proj2 = nn.Linear(256, features_dim)

        self._features_dim = features_dim
        # Expose an attribute named 'convlstm' so the recurrent policy recognizes
        # this extractor as recurrent and will pass/receive hidden states.
        # Keep parity with previous implementation that had a 'convlstm' module.
        self.convlstm = self.drc

    def forward(self, observations: torch.Tensor, hidden_states: list[tuple[torch.Tensor, torch.Tensor]] | None = None) -> tuple[torch.Tensor, list[tuple[torch.Tensor, torch.Tensor]]]:
        # Import profiling lazily
        try:
            from profiling import profile
        except ImportError:
            def profile(_name, _track_memory=True):
                from contextlib import nullcontext
                return nullcontext()

        with profile("convlstm_forward_pass", track_memory=True):
            x = observations
            # Shape unpack for readability without unused variables
            # _B, _C_in, _H, _W = x.shape
            # Encode observation (no activation)
            with profile("convlstm_conv_encoder", track_memory=True):
                E_t = self.encoder(x)

            # Reformat provided hidden_states to (h_list, c_list)
            state_tuple: tuple[list[torch.Tensor], list[torch.Tensor]] | None = None
            if hidden_states is not None and len(hidden_states) > 0:
                h_list = [hc[0] for hc in hidden_states]
                c_list = [hc[1] for hc in hidden_states]
                state_tuple = (h_list, c_list)

            # Run DRC stack
            with profile("convlstm_drc_stack", track_memory=True):
                h_top, (h_list_new, c_list_new) = self.drc(E_t, state_tuple, repeats_override=None)

            # Global average pooling over H,W
            with profile("convlstm_global_pooling", track_memory=True):
                pooled = h_top.mean(dim=(-2, -1))  # [B, C]

            # Projection head
            with profile("convlstm_projection", track_memory=True):
                z = self.proj1(pooled)
                z = self.proj_act(z)
                z = self.proj2(z)

            # Pack new hidden states as list of (h, c)
            new_hidden_states = [(h_list_new[i], c_list_new[i]) for i in range(len(h_list_new))]
            return z, new_hidden_states

```

```python
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Optional, Tuple, List, Literal, Set

import numpy as np

from .ricochet_core import Board, apply_action, reached_goal

# Provide a runtime gymnasium binding if available, otherwise a minimal fallback
try:  # pragma: no cover
    import importlib
    _gym = importlib.import_module("gymnasium")  # type: ignore
    _spaces = importlib.import_module("gymnasium.spaces")  # type: ignore
    _seeding = importlib.import_module("gymnasium.utils.seeding")  # type: ignore
    _error = importlib.import_module("gymnasium.error")  # type: ignore
    GymEnvBase = _gym.Env  # type: ignore
    spaces = _spaces  # type: ignore
    GymInvalidAction = getattr(_error, "InvalidAction", None)  # type: ignore
except (ModuleNotFoundError, ImportError):  # pragma: no cover
    class GymEnvBase(object):
        pass
    class _SpacesDummy:  # minimal placeholders to satisfy type usage
        class Box:  # type: ignore
            def __init__(self, low=None, high=None, shape=None, dtype=None):
                self.low = low
                self.high = high
                self.shape = shape
                self.dtype = dtype
        class Discrete:  # type: ignore
            def __init__(self, n: int):
                self.n = n
    spaces = _SpacesDummy()  # type: ignore
    GymInvalidAction = None  # type: ignore


@dataclass
class FixedLayout:
    height: int
    width: int
    # Edge walls
    h_walls: np.ndarray  # (H+1, W) bool
    v_walls: np.ndarray  # (H, W+1) bool
    robot_positions: Dict[int, Tuple[int, int]]
    goal_position: Tuple[int, int]
    target_robot: int


ObsMode = Literal["image", "symbolic", "rgb_image"]


class RicochetRobotsEnv(GymEnvBase):
    """Ricochet Robots Gymnasium-compatible environment.

    Determinism and seeding:
    - Deterministic given the seed provided to __init__ or reset(seed=...).
    - Randomness flows through self.np_random (Gymnasium seeding utils); the episode's resolved
      seed is exposed via info["episode_seed"].
    - When ensure_solvable=True, the environment may retry board generation; retries do not add
      extra non-determinism beyond RNG draws. The included solver is deterministic.

    Observations:
    - Image mode: float32 in [0,1]. Channels are named by channel_names; note that the target robot
      is represented both by a dedicated mask (index 5) and its robot channel (duplication by design).
    - Symbolic mode: float32 with absolute grid indices (not normalized). Downstream code may wish to
      normalize to [0,1]. The Box low/high reflect board bounds.

    Rendering:
    - Only render_mode="ascii" is implemented and returns a string frame.
    - Other modes are not implemented and will raise a clear error.
    """
    metadata = {"render_modes": ["ascii", "rgb"], "render_fps": 4}

    def __init__(
        self,
        height: int = 8,
        width: int = 8,
        num_robots: int = 2,
        include_noop: bool = True,
        step_penalty: float = -0.01,
        goal_reward: float = 1.0,
        noop_penalty: Optional[float] = None,
        max_steps: int = 100,
        fixed_layout: Optional[FixedLayout] = None,
        seed: Optional[int] = None,
        ensure_solvable: bool = False,
        solver_max_depth: int = 30,
        solver_max_nodes: int = 20000,
        obs_mode: ObsMode = "image",
        channels_first: bool = False,
        render_mode: Optional[str] = None,
        ensure_attempt_limit: int = 500,
        # Spec-driven generation configuration
        edge_t_per_quadrant: Optional[int] = None,
        central_l_per_quadrant: Optional[int] = None,
        # RGB render configuration
        render_rgb_config: Optional[Dict[str, object]] = None,
    ) -> None:
        super().__init__()
        self.height = height
        self.width = width
        self.num_robots = num_robots
        self.include_noop = include_noop
        self.step_penalty = step_penalty
        self.goal_reward = goal_reward
        self.noop_penalty = step_penalty if noop_penalty is None else noop_penalty
        self.max_steps = max_steps
        self.fixed_layout = fixed_layout
        self.ensure_solvable = ensure_solvable
        self.solver_max_depth = solver_max_depth
        self.solver_max_nodes = solver_max_nodes
        self.obs_mode: ObsMode = obs_mode
        self.channels_first = channels_first
        # If a fixed layout is provided, align env geometry before building spaces
        if self.fixed_layout is not None:
            self.height = int(self.fixed_layout.height)
            self.width = int(self.fixed_layout.width)
            self.num_robots = int(len(self.fixed_layout.robot_positions))
        # Render API
        self.render_mode = render_mode
        if self.render_mode is not None and self.render_mode not in self.metadata["render_modes"]:
            raise ValueError(f"Unsupported render_mode {self.render_mode}. Supported: {self.metadata['render_modes']}")
        # RGB render defaults
        self._render_rgb_cfg: Dict[str, object] = {
            "cell_size": 20,
            "grid_color": (200, 200, 200),
            "grid_thickness": 1,
            "wall_color": (0, 0, 0),
            "wall_thickness": 3,
            "robot_colors": [
                (220, 50, 50),     # red
                (50, 120, 220),    # blue
                (50, 180, 80),     # green
                (230, 200, 40),    # yellow
                (180, 80, 180),    # purple (extra if more robots)
            ],
            "circle_fill": True,
            "circle_radius_frac": 0.35,
            "target_dark_factor": 0.6,
            "star_thickness": 2,
        }
        if render_rgb_config is not None:
            self._render_rgb_cfg.update(render_rgb_config)

        # Seeding: adopt Gymnasium convention with self.np_random
        self.np_random: np.random.Generator
        self._episode_seed: Optional[int] = None
        try:  # gymnasium present
            # _seeding.np_random returns (rng, seed)
            self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
            self._episode_seed = int(used_seed) if used_seed is not None else None
        except NameError:
            self.np_random = np.random.default_rng(seed)
            self._episode_seed = int(seed) if seed is not None else None
        # Preserve a base seed to enforce deterministic resets when no new seed is provided
        self._base_seed: Optional[int] = int(seed) if seed is not None else self._episode_seed
        self._board: Optional[Board] = None
        self._num_steps = 0
        self._cached_wall_obs: Optional[np.ndarray] = None  # (H,W,4) float32 for wall channels
        self._ensure_attempt_limit = int(ensure_attempt_limit)
        # Spec default counts per quadrant (based on smaller board side)
        side_min = min(self.height, self.width)
        default_per_quad = 2 if side_min < 10 else 4
        self._edge_t_per_quadrant = default_per_quad if edge_t_per_quadrant is None else int(edge_t_per_quadrant)
        self._central_l_per_quadrant = default_per_quad if central_l_per_quadrant is None else int(central_l_per_quadrant)

        # Observation spaces
        if self.obs_mode == "image":
            # channels: up_wall, down_wall, left_wall, right_wall, goal, target_mask, robots...
            self._base_wall_channels = 4
            self._base_misc_channels = 2  # goal, target
            self._num_channels = self._base_wall_channels + self._base_misc_channels + self.num_robots
            if self.channels_first:
                obs_shape = (self._num_channels, self.height, self.width)
            else:
                obs_shape = (self.height, self.width, self._num_channels)
            self.observation_space = spaces.Box(
                low=0.0,
                high=1.0,
                shape=obs_shape,
                dtype=np.float32,
            )
        elif self.obs_mode == "rgb_image":
            # RGB image observation: uses fixed pixel dimensions for consistent observation space
            # This ensures all curriculum levels have the same observation space size
            # Lowered from 128 to 96 to reduce memory/compute; resize handled in _board_to_rgb_obs
            FIXED_PIXEL_SIZE = 96
            
            if self.channels_first:
                obs_shape = (3, FIXED_PIXEL_SIZE, FIXED_PIXEL_SIZE)
            else:
                obs_shape = (FIXED_PIXEL_SIZE, FIXED_PIXEL_SIZE, 3)
            self.observation_space = spaces.Box(
                low=0,
                high=255,
                shape=obs_shape,
                dtype=np.uint8,
            )
        elif self.obs_mode == "symbolic":
            # [goal_r, goal_c] in [0..H-1], [0..W-1]; one-hot target in [0,1]; robots positions in bounds
            vec_len = 2 + self.num_robots + (self.num_robots * 2)
            low = np.full((vec_len,), 0.0, dtype=np.float32)
            high = np.full((vec_len,), 1.0, dtype=np.float32)
            # goal bounds
            low[0] = 0.0
            high[0] = float(self.height - 1)
            low[1] = 0.0
            high[1] = float(self.width - 1)
            # target one-hot already [0,1]
            # robots positions
            base = 2 + self.num_robots
            for i in range(self.num_robots):
                low[base + 2 * i] = 0.0
                high[base + 2 * i] = float(self.height - 1)
                low[base + 2 * i + 1] = 0.0
                high[base + 2 * i + 1] = float(self.width - 1)
            self.observation_space = spaces.Box(low=low, high=high, shape=(vec_len,), dtype=np.float32)
        else:
            raise ValueError(f"Unknown obs_mode: {self.obs_mode}")

        # Action space: num_robots * 4 directions (+ 1 for noop)
        self._noop_action = self.num_robots * 4 if include_noop else None
        self.action_space = spaces.Discrete(self.num_robots * 4 + (1 if include_noop else 0))

    # Gymnasium API
    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):
        """Reset the environment and start a new episode.

        Returns (obs, info) per Gymnasium API. info contains keys: 'target_robot',
        'level_solvable' (optional), 'optimal_length' (if ensured), 'solver_limits' (if ensured),
        and 'episode_seed' with the seed used for this episode.
        """
        # Import profiling here to avoid circular imports
        try:
            from profiling import profile
        except ImportError:
            # Fallback if profiling not available
            def profile(name, track_memory=True):
                from contextlib import nullcontext
                return nullcontext()

        # Standard seeding protocol
        if seed is not None:
            try:
                self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
                self._episode_seed = int(used_seed) if used_seed is not None else None
            except NameError:
                self.np_random = np.random.default_rng(seed)
                self._episode_seed = int(seed)
            self._base_seed = int(self._episode_seed) if self._episode_seed is not None else None
        else:
            # Re-seed with base seed so that resets are deterministic when no new seed is provided
            if self._base_seed is not None:
                try:
                    self.np_random, used_seed = _seeding.np_random(self._base_seed)  # type: ignore[name-defined]
                    self._episode_seed = int(used_seed) if used_seed is not None else int(self._base_seed)
                except NameError:
                    self.np_random = np.random.default_rng(self._base_seed)
                    self._episode_seed = int(self._base_seed)
        _ = options  # silence unused
        self._num_steps = 0
        # clear cached walls in case layout changes
        self._cached_wall_obs = None

        if self.fixed_layout is not None:
            with profile("env_reset_fixed_layout", track_memory=True):
                self._board = Board(
                height=self.fixed_layout.height,
                width=self.fixed_layout.width,
                h_walls=self.fixed_layout.h_walls.copy(),
                v_walls=self.fixed_layout.v_walls.copy(),
                robot_positions=dict(self.fixed_layout.robot_positions),
                goal_position=self.fixed_layout.goal_position,
                target_robot=self.fixed_layout.target_robot,
            )
            # cache static walls for this layout
            with profile("env_build_cached_walls", track_memory=True):
                self._build_cached_walls(self._board)
            with profile("env_make_obs", track_memory=True):
                obs = self._make_obs(self._board)
            info = {
                "level_solvable": False,
                "ensure_solvable_enabled": False,
                "target_robot": self._board.target_robot,
                "episode_seed": self._episode_seed,
            }
            if self.obs_mode == "image":
                info["channel_names"] = self.channel_names
            return obs, info

        # Otherwise, generate random board, optionally ensure solvable via solver
        attempts = 0
        while True:
            attempts += 1
            with profile("env_generate_board", track_memory=True):
                board = self._generate_random_board()
            if not self.ensure_solvable:
                self._board = board
                break
            try:
                from .solver import solve_bfs  # type: ignore
                with profile("env_solver_check", track_memory=True):
                    solution = solve_bfs(board, max_depth=self.solver_max_depth, max_nodes=self.solver_max_nodes)
                if solution is not None:
                    self._board = board
                    optimal_length = len(solution)
                    break
            except ImportError as exc:
                raise RuntimeError("ensure_solvable=True but solver unavailable (ImportError)") from exc
            if attempts >= self._ensure_attempt_limit:
                raise RuntimeError("Failed to generate solvable board within attempt limit")

        # cache static walls for this layout
        assert self._board is not None
        with profile("env_build_cached_walls", track_memory=True):
            self._build_cached_walls(self._board)
        with profile("env_make_obs", track_memory=True):
            obs = self._make_obs(self._board)
        # Note: solver None during attempts may be due to cutoffs (depth/nodes), not true unsolvability.
        info = {
            "level_solvable": bool(self.ensure_solvable),
            "ensure_solvable_enabled": bool(self.ensure_solvable),
            "target_robot": self._board.target_robot,
            "episode_seed": self._episode_seed,
        }
        if self.obs_mode == "image":
            info["channel_names"] = self.channel_names
        if self.ensure_solvable:
            info["optimal_length"] = optimal_length
            info["solver_limits"] = {"max_depth": self.solver_max_depth, "max_nodes": self.solver_max_nodes}
        return obs, info

    def step(self, action: int):
        """Apply an action and return (obs, reward, terminated, truncated, info).

        info always includes 'steps', 'target_robot', and 'is_success' (bool). When truncated due to
        max steps, info includes 'TimeLimit.truncated'=True.
        """
        # Import profiling here to avoid circular imports
        try:
            from profiling import profile
        except ImportError:
            # Fallback if profiling not available
            def profile(name, track_memory=True):
                from contextlib import nullcontext
                return nullcontext()

        assert self._board is not None, "Call reset() first"
        self._num_steps += 1

        terminated = False
        truncated = False
        info: Dict[str, object] = {}

        reward = self.step_penalty
        # Validate action range early
        if not (0 <= action < self.action_space.n):
            if GymInvalidAction is not None:
                raise GymInvalidAction(f"Invalid action {action}")  # type: ignore[misc]
            raise ValueError(f"Invalid action {action}")

        if self.include_noop and action == self._noop_action:
            reward = self.noop_penalty
        else:
            with profile("env_apply_action", track_memory=True):
                robot_id, direction = self._decode_action(action)
                self._board = apply_action(self._board, robot_id, direction)

        if reached_goal(self._board):
            reward += self.goal_reward
            terminated = True
            info["is_success"] = True

        if not terminated and self._num_steps >= self.max_steps:
            truncated = True
            info["TimeLimit.truncated"] = True

        with profile("env_make_obs", track_memory=True):
            obs = self._make_obs(self._board)
        info["steps"] = self._num_steps
        info["target_robot"] = self._board.target_robot
        if "is_success" not in info:
            info["is_success"] = False
        return obs, reward, terminated, truncated, info

    def render(self):
        """Render according to render_mode.

        - render_mode=="ascii": returns a string frame.
        - render_mode=="rgb": returns an (H_px, W_px, 3) uint8 array.
        - render_mode is None or unsupported: returns None.
        """
        if self.render_mode is None:
            return None
        if self._board is None:
            return "" if self.render_mode == "ascii" else None
        if self.render_mode == "ascii":
            from .ricochet_core import render_ascii  # local import to avoid circulars in lints
            return render_ascii(self._board)
        if self.render_mode == "rgb":
            return self._render_rgb(self._board)
        if self._board is None:
            return ""
        raise ValueError(f"Unsupported render_mode {self.render_mode}. Supported: {self.metadata['render_modes']}")

    def close(self) -> None:
        """Close environment resources (no-op)."""
        return None

    def seed(self, seed: Optional[int] = None):  # legacy convenience
        """Legacy seeding helper returning [seed]. Prefer reset(seed=...)."""
        if seed is None:
            return [self._episode_seed]
        try:
            self.np_random, used_seed = _seeding.np_random(seed)  # type: ignore[name-defined]
            self._episode_seed = int(used_seed) if used_seed is not None else int(seed)
        except NameError:
            self.np_random = np.random.default_rng(seed)
            self._episode_seed = int(seed)
        return [self._episode_seed]

    # Helpers
    def _decode_action(self, action: int) -> Tuple[int, int]:
        if not (0 <= action < self.action_space.n):
            raise ValueError(f"Invalid action {action}")
        if self.include_noop and action == self._noop_action:
            raise ValueError("_decode_action called on noop action")
        robot_id = action // 4
        direction = action % 4
        if robot_id >= self.num_robots:
            raise ValueError(f"Invalid robot_id {robot_id} for action {action}")
        return robot_id, direction

    def _make_obs(self, board: Board) -> np.ndarray:
        if self.obs_mode == "image":
            return self._board_to_image_obs(board)
        elif self.obs_mode == "rgb_image":
            return self._board_to_rgb_obs(board)
        return self._board_to_symbolic_obs(board)

    def _board_to_image_obs(self, board: Board) -> np.ndarray:
        # Import profiling here to avoid circular imports
        try:
            from profiling import profile
        except ImportError:
            # Fallback if profiling not available
            def profile(name, track_memory=True):
                from contextlib import nullcontext
                return nullcontext()

        with profile("env_image_observation_generation", track_memory=True):
            h, w = board.height, board.width
            C = self._num_channels
            obs = np.zeros((h, w, C), dtype=np.float32)
            # wall channels 0..3 from cache
            if self._cached_wall_obs is not None:
                obs[:, :, 0:4] = self._cached_wall_obs
            else:
                # Fallback if cache not built (should not happen)
                for r in range(h):
                    for c in range(w):
                        obs[r, c, 0] = 1.0 if board.has_wall_up(r, c) else 0.0
                        obs[r, c, 1] = 1.0 if board.has_wall_down(r, c) else 0.0
                        obs[r, c, 2] = 1.0 if board.has_wall_left(r, c) else 0.0
                        obs[r, c, 3] = 1.0 if board.has_wall_right(r, c) else 0.0
            # goal channel 4
            gr, gc = board.goal_position
            obs[gr, gc, 4] = 1.0
            # target mask channel 5
            tr = board.target_robot
            tr_r, tr_c = board.robot_positions[tr]
            obs[tr_r, tr_c, 5] = 1.0
            # robot channels start at 6
            base = 6
            for rid, (r, c) in board.robot_positions.items():
                obs[r, c, base + rid] = 1.0
            if self.channels_first:
                obs = np.transpose(obs, (2, 0, 1))
            return obs

    def _board_to_symbolic_obs(self, board: Board) -> np.ndarray:
        # Import profiling here to avoid circular imports
        try:
            from profiling import profile
        except ImportError:
            # Fallback if profiling not available
            def profile(name, track_memory=True):
                from contextlib import nullcontext
                return nullcontext()

        with profile("env_symbolic_observation_generation", track_memory=True):
            gr, gc = board.goal_position
            target_one_hot = np.zeros((self.num_robots,), dtype=np.float32)
            target_one_hot[board.target_robot] = 1.0
            robots_vec: List[float] = []
            for rid in range(self.num_robots):
                r, c = board.robot_positions[rid]
                robots_vec.extend([float(r), float(c)])
            vec = np.concatenate([
                np.array([float(gr), float(gc)], dtype=np.float32),
                target_one_hot.astype(np.float32),
                np.array(robots_vec, dtype=np.float32),
            ])
            return vec

    def _board_to_rgb_obs(self, board: Board) -> np.ndarray:
        """Convert board to RGB image observation with fixed pixel dimensions.
        
        This creates an RGB image with fixed pixel dimensions (128x128) by adjusting
        the cell size to fit the board within the fixed pixel space. This ensures
        consistent observation space across all curriculum levels.
        """
        # Import profiling here to avoid circular imports
        try:
            from profiling import profile
        except ImportError:
            # Fallback if profiling not available
            def profile(name, track_memory=True):
                from contextlib import nullcontext
                return nullcontext()
        
        with profile("env_rgb_observation_generation", track_memory=True):
            FIXED_PIXEL_SIZE = 96
            
            # Calculate cell size to fit the board within the fixed pixel dimensions
            # Leave some padding around the edges
            padding = 4  # pixels of padding around the board
            available_size = FIXED_PIXEL_SIZE - 2 * padding
            cell_size = max(1, available_size // max(board.height, board.width))
            
            # Temporarily update the render config for this observation
            original_cell_size = self._render_rgb_cfg["cell_size"]
            self._render_rgb_cfg["cell_size"] = cell_size
            
            try:
                # Use the existing RGB rendering method with adjusted cell size
                with profile("env_rgb_rendering", track_memory=True):
                    rgb_image = self._render_rgb(board)
                
                # Resize to fixed pixel dimensions if needed
                if rgb_image.shape[:2] != (FIXED_PIXEL_SIZE, FIXED_PIXEL_SIZE):
                    with profile("env_rgb_resizing", track_memory=True):
                        from PIL import Image
                        # Convert to PIL Image for resizing
                        pil_image = Image.fromarray(rgb_image)
                        # Resize to fixed dimensions
                        pil_image = pil_image.resize((FIXED_PIXEL_SIZE, FIXED_PIXEL_SIZE), Image.Resampling.LANCZOS)
                        rgb_image = np.array(pil_image)
                
                # Convert to the correct format based on channels_first setting
                if self.channels_first:
                    # Convert from (H, W, 3) to (3, H, W)
                    rgb_image = np.transpose(rgb_image, (2, 0, 1))
                
                return rgb_image
                
            finally:
                # Restore original cell size
                self._render_rgb_cfg["cell_size"] = original_cell_size

    def _generate_random_board(self) -> Board:
        h, w = self.height, self.width
        assert h == w, "Boards should always be square per specification"
        # Initialize empty walls then set borders
        h_walls = np.zeros((h + 1, w), dtype=bool)
        v_walls = np.zeros((h, w + 1), dtype=bool)
        h_walls[0, :] = True
        h_walls[h, :] = True
        v_walls[:, 0] = True
        v_walls[:, w] = True

        # Track reserved cells that already host a structure (to satisfy rule: max 1 structure per cell)
        reserved_cells: Set[Tuple[int, int]] = set()

        # Helper to mark a cell as having a structure
        def reserve_cell(cell: Tuple[int, int]) -> None:
            r, c = cell
            if 0 <= r < h and 0 <= c < w:
                reserved_cells.add((r, c))

        # Build forbidden central block: walls surrounding central 1x1 (odd) or 2x2 (even)
        if h % 2 == 1:
            mid = h // 2
            # Walls around (mid, mid)
            h_walls[mid, mid] = True  # above
            h_walls[mid + 1, mid] = True  # below
            v_walls[mid, mid] = True  # left
            v_walls[mid, mid + 1] = True  # right
            reserve_cell((mid, mid))
            central_rows = [mid]
            central_cols = [mid]
        else:
            mid = h // 2
            # Central 2x2 cells: (mid-1, mid-1), (mid-1, mid), (mid, mid-1), (mid, mid)
            # Walls around the perimeter of this 2x2 block
            # Horizontal walls above and below the 2x2 block
            h_walls[mid-1, mid - 1] = True
            h_walls[mid-1, mid] = True
            h_walls[mid + 1, mid - 1] = True
            h_walls[mid + 1, mid] = True
            # Vertical walls left and right of the 2x2 block
            v_walls[mid - 1, mid-1] = True
            v_walls[mid, mid-1] = True
            v_walls[mid - 1, mid + 1] = True
            v_walls[mid, mid + 1] = True
            # Reserve the 2x2 central cells
            for rr in (mid - 1, mid):
                for cc in (mid - 1, mid):
                    reserve_cell((rr, cc))
            central_rows = [mid - 1, mid]
            central_cols = [mid - 1, mid]

        # Define quadrant bounds excluding the central rows/cols
        # Each bound is (r_start, r_end_inclusive, c_start, c_end_inclusive)
        def ranges_excluding_central(size: int, central_idxs: List[int]) -> Tuple[Tuple[int, int], Tuple[int, int]]:
            # returns (low_range, high_range) as inclusive (start,end)
            unique = sorted(set(central_idxs))
            if len(unique) == 1:
                mid_idx = unique[0]
                return (0, mid_idx - 1), (mid_idx + 1, size - 1)
            else:
                # two central indices for even
                low_end = unique[0] - 1
                high_start = unique[1] + 1
                return (0, low_end), (high_start, size - 1)

        (r0_start, r0_end), (r1_start, r1_end) = ranges_excluding_central(h, central_rows)
        (c0_start, c0_end), (c1_start, c1_end) = ranges_excluding_central(w, central_cols)
        quadrants = {
            "NW": (r0_start, r0_end, c0_start, c0_end),
            "NE": (r0_start, r0_end, c1_start, c1_end),
            "SW": (r1_start, r1_end, c0_start, c0_end),
            "SE": (r1_start, r1_end, c1_start, c1_end),
        }

        # Placement helpers
        used_interior_h: Set[Tuple[int, int]] = set()  # (row_idx in 1..h-1, col_idx in 0..w-1)
        used_interior_v: Set[Tuple[int, int]] = set()  # (row_idx in 0..h-1, col_idx in 1..w)

        def cell_has_nonboundary_wall(r: int, c: int) -> bool:
            # top edge is h_walls[r, c] (non-boundary if r > 0)
            if r > 0 and h_walls[r, c]:
                return True
            # bottom edge is h_walls[r+1, c] (non-boundary if r+1 < h)
            if r + 1 < h and h_walls[r + 1, c]:
                return True
            # left edge is v_walls[r, c] (non-boundary if c > 0)
            if c > 0 and v_walls[r, c]:
                return True
            # right edge is v_walls[r, c+1] (non-boundary if c+1 < w)
            if c + 1 < w and v_walls[r, c + 1]:
                return True
            return False

        def neighbors4(r: int, c: int) -> List[Tuple[int, int]]:
            nbrs: List[Tuple[int, int]] = []
            if r - 1 >= 0:
                nbrs.append((r - 1, c))
            if r + 1 < h:
                nbrs.append((r + 1, c))
            if c - 1 >= 0:
                nbrs.append((r, c - 1))
            if c + 1 < w:
                nbrs.append((r, c + 1))
            return nbrs

        def can_place_h(row: int, col: int) -> bool:
            if not (1 <= row <= h - 1 and 0 <= col <= w - 1):
                return False
            if h_walls[row, col]:
                return False
            # Avoid touching non-border existing walls: ensure adjacent interior edges are free for central-L constraints
            neighbors = [
                (row - 1, col), (row + 1, col)
            ]
            for nr, nc in neighbors:
                if 1 <= nr <= h - 1 and 0 <= nc <= w - 1 and h_walls[nr, nc]:
                    return False
            return True

        def can_place_v(row: int, col: int) -> bool:
            if not (0 <= row <= h - 1 and 1 <= col <= w - 1):
                return False
            if v_walls[row, col]:
                return False
            neighbors = [
                (row, col - 1), (row, col + 1)
            ]
            for nr, nc in neighbors:
                if 0 <= nr <= h - 1 and 1 <= nc <= w - 1 and v_walls[nr, nc]:
                    return False
            return True

        def place_edge_t_in_quadrant(q_bounds: Tuple[int, int, int, int]) -> bool:
            rs, re, cs, ce = q_bounds
            if rs > re or cs > ce:
                return False
            # Choose one of four sides from this quadrant that lies on the board boundary
            choices: List[Tuple[str, Tuple[int, int]]] = []
            # From top boundary within [cs..ce]: place vertical wall at row 0 between (0,c-1)-(0,c) as v_walls[0,c]
            if rs == 0:
                for c in range(cs + 1, ce + 1):
                    choices.append(("TOP", (0, c)))  # v_walls[0, c]
            # From bottom boundary
            if re == h - 1:
                for c in range(cs + 1, ce + 1):
                    choices.append(("BOTTOM", (h - 1, c)))  # v_walls[h-1, c]
            # From left boundary
            if cs == 0:
                for r in range(rs + 1, re + 1):
                    choices.append(("LEFT", (r, 0)))  # h_walls[r,0]
            # From right boundary
            if ce == w - 1:
                for r in range(rs + 1, re + 1):
                    choices.append(("RIGHT", (r, w - 1)))  # h_walls[r, w-1]
            if not choices:
                return False
            # Shuffle deterministically via self.np_random
            idxs = np.arange(len(choices))
            self.np_random.shuffle(idxs)
            for idx in idxs:
                side, pos = choices[idx]
                if side in ("TOP", "BOTTOM"):
                    r0, c = pos
                    # Disallow juts adjacent to board corners along top/bottom: c must not be 1 or w-1
                    if c in (1, w - 1):
                        continue
                    # Place vertical wall jutting down/up adjacent to border: v_walls[r0, c]
                    if can_place_v(r0, c):
                        # Determine the adjacent interior cell around which this edge-T is formed
                        adj_cell = (1 if side == "TOP" else h - 2, c - 1)
                        # Enforce: no neighbor of a walled cell may be a structure center
                        # i.e., candidate center adj_cell must not have neighbors with non-boundary walls
                        blocked = any(cell_has_nonboundary_wall(rr, cc) for rr, cc in neighbors4(adj_cell[0], adj_cell[1]))
                        if not blocked and (0 <= adj_cell[0] < h and 0 <= adj_cell[1] < w) and adj_cell not in reserved_cells:
                            v_walls[r0, c] = True
                            used_interior_v.add((r0, c))
                            reserve_cell(adj_cell)
                            return True
                else:
                    r, c0 = pos
                    # Disallow juts adjacent to board corners along left/right: r must not be 1 or h-1
                    if r in (1, h - 1):
                        continue
                    # Place horizontal wall jutting right/left adjacent to border: h_walls[r, c0]
                    if can_place_h(r, c0):
                        adj_cell = (r - 1, 1 if side == "LEFT" else w - 2)
                        blocked = any(cell_has_nonboundary_wall(rr, cc) for rr, cc in neighbors4(adj_cell[0], adj_cell[1]))
                        if not blocked and (0 <= adj_cell[0] < h and 0 <= adj_cell[1] < w) and adj_cell not in reserved_cells:
                            h_walls[r, c0] = True
                            used_interior_h.add((r, c0))
                            reserve_cell(adj_cell)
                            return True
            return False

        # Central-L orientations
        # orientation encodes which two walls around a cell: TL => top+left, TR => top+right, BL => bottom+left, BR => bottom+right
        orientations = ["TL", "TR", "BL", "BR"]

        central_l_centers: List[Tuple[int, int]] = []

        def place_central_l_in_quadrant(q_bounds: Tuple[int, int, int, int], desired_orientation: str) -> bool:
            rs, re, cs, ce = q_bounds
            if rs > re or cs > ce:
                return False
            candidates: List[Tuple[int, int]] = []
            for r in range(rs, re + 1):
                for c in range(cs, ce + 1):
                    # Central-L cannot be around an edge square
                    if r == 0 or r == h - 1 or c == 0 or c == w - 1:
                        continue
                    if (r, c) in reserved_cells:
                        continue
                    # Enforce: no neighbor of a walled cell may be a structure center
                    if any(cell_has_nonboundary_wall(rr, cc) for rr, cc in neighbors4(r, c)):
                        continue
                    candidates.append((r, c))
            if not candidates:
                return False
            idxs = np.arange(len(candidates))
            self.np_random.shuffle(idxs)
            for idx in idxs:
                r, c = candidates[idx]
                # Determine which interior edges would be used by the L at this cell
                need_h: Optional[Tuple[int, int]] = None
                need_v: Optional[Tuple[int, int]] = None
                if desired_orientation == "TL":
                    need_h = (r, c)  # top wall above the cell
                    need_v = (r, c)  # left wall of the cell
                elif desired_orientation == "TR":
                    need_h = (r, c)  # top
                    need_v = (r, c + 1)  # right wall uses v_walls[r, c+1]
                elif desired_orientation == "BL":
                    need_h = (r + 1, c)  # bottom wall below the cell
                    need_v = (r, c)  # left
                else:  # "BR"
                    need_h = (r + 1, c)
                    need_v = (r, c + 1)
                # Check within interior ranges and not touching other interior walls
                if need_h is None or need_v is None:
                    continue
                hr, hc = need_h
                vr, vc = need_v
                if not can_place_h(hr, hc):
                    continue
                if not can_place_v(vr, vc):
                    continue
                # Also ensure the required edges are not on the outer border (to avoid touching existing walls per spec)
                if hr in (0, h) or vc in (0, w):
                    continue
                # Place them
                h_walls[hr, hc] = True
                v_walls[vr, vc] = True
                used_interior_h.add((hr, hc))
                used_interior_v.add((vr, vc))
                # Reserve the corner cell for structure uniqueness and record as a central-L center
                reserve_cell((r, c))
                central_l_centers.append((r, c))
                return True
            return False

        # Place structures per quadrant
        # 1) Edge-T
        for _, bounds in quadrants.items():
            count = self._edge_t_per_quadrant
            placed = 0
            # Attempt multiple times to place required count
            attempts = 0
            while placed < count and attempts < count * 10:
                if place_edge_t_in_quadrant(bounds):
                    placed += 1
                attempts += 1

        # 2) Central-L with as even orientation distribution as possible
        for _, bounds in quadrants.items():
            count = self._central_l_per_quadrant
            if count <= 0:
                continue
            # Build orientation list as evenly as possible
            orient_list: List[str] = []
            for i in range(count):
                orient_list.append(orientations[i % 4])
            # Shuffle list deterministically for variety across seeds
            idxs = np.arange(len(orient_list))
            self.np_random.shuffle(idxs)
            orient_list = [orient_list[i] for i in idxs]
            placed = 0
            attempts = 0
            i = 0
            while placed < count and attempts < count * 20 and i < len(orient_list):
                if place_central_l_in_quadrant(bounds, orient_list[i]):
                    placed += 1
                i += 1
                attempts += 1

        # Place goal inside a central-L square (randomly among placed central-L centers), excluding central forbidden block
        central_set = set((r, c) for r in central_rows for c in central_cols)
        candidates_goal = [rc for rc in central_l_centers if rc not in central_set]
        if not candidates_goal:
            # Fallback: if for some reason no central-L could be placed, select any non-central cell deterministically
            candidates_goal = [(r, c) for r in range(h) for c in range(w) if (r, c) not in central_set]
        idx = int(self.np_random.integers(0, len(candidates_goal)))
        goal = candidates_goal[idx]

        # Place robots in free cells excluding central block and the goal cell
        free_cells: List[Tuple[int, int]] = []
        for r in range(h):
            for c in range(w):
                if (r, c) in central_set or (r, c) == goal:
                    continue
                free_cells.append((r, c))
        self.np_random.shuffle(free_cells)
        robot_positions: Dict[int, Tuple[int, int]] = {}
        for rid in range(self.num_robots):
            robot_positions[rid] = free_cells.pop()
        target_robot = int(self.np_random.integers(0, self.num_robots))
        return Board(height=h, width=w, h_walls=h_walls, v_walls=v_walls, robot_positions=robot_positions, goal_position=goal, target_robot=target_robot)

    # Public channel names for image observations
    @property
    def channel_names(self) -> List[str]:
        """Human-readable names for image observation channels."""
        names = ["wall_up", "wall_down", "wall_left", "wall_right", "goal", "target_robot_mask"]
        names.extend([f"robot_{i}" for i in range(self.num_robots)])
        return names

    def _build_cached_walls(self, board: Board) -> None:
        """Precompute static wall indicator channels (H,W,4)."""
        h, w = board.height, board.width
        wall = np.zeros((h, w, 4), dtype=np.float32)
        for r in range(h):
            for c in range(w):
                wall[r, c, 0] = 1.0 if board.has_wall_up(r, c) else 0.0
                wall[r, c, 1] = 1.0 if board.has_wall_down(r, c) else 0.0
                wall[r, c, 2] = 1.0 if board.has_wall_left(r, c) else 0.0
                wall[r, c, 3] = 1.0 if board.has_wall_right(r, c) else 0.0
        self._cached_wall_obs = wall

    # Public accessor for current board (read-only clone)
    def get_board(self) -> Board:
        if self._board is None:
            raise RuntimeError("Environment not initialized. Call reset() first.")
        return self._board.clone()

    def _render_rgb(self, board: Board) -> np.ndarray:
        # Import profiling here to avoid circular imports
        try:
            from profiling import profile
        except ImportError:
            # Fallback if profiling not available
            def profile(name, track_memory=True):
                from contextlib import nullcontext
                return nullcontext()
        
        with profile("env_rgb_render_setup", track_memory=True):
            # Extract config
            cfg = self._render_rgb_cfg
            cell_size = int(cfg["cell_size"])  # pixels
            grid_color = tuple(int(x) for x in cfg["grid_color"])  # type: ignore[index]
            grid_th = int(cfg["grid_thickness"])  # px
            wall_color = tuple(int(x) for x in cfg["wall_color"])  # type: ignore[index]
            wall_th = int(cfg["wall_thickness"])  # px
            robot_colors: List[Tuple[int, int, int]] = [tuple(int(a) for a in t) for t in cfg["robot_colors"]]  # type: ignore[index]
            circle_fill: bool = bool(cfg["circle_fill"])  # type: ignore[index]
            circle_r_frac: float = float(cfg["circle_radius_frac"])  # type: ignore[index]
            target_dark_factor: float = float(cfg["target_dark_factor"])  # type: ignore[index]
            star_th: int = int(cfg["star_thickness"])  # type: ignore[index]

            H, W = board.height, board.width
            H_px, W_px = H * cell_size, W * cell_size
            img = np.ones((H_px, W_px, 3), dtype=np.uint8) * 255

        # Helpers to draw
        def draw_hline(y: int, x0: int, x1: int, color: Tuple[int, int, int], thickness: int) -> None:
            y0 = max(0, y - thickness // 2)
            y1 = min(H_px, y + (thickness - thickness // 2))
            x0c = max(0, min(x0, x1))
            x1c = min(W_px, max(x0, x1))
            img[y0:y1, x0c:x1c] = color

        def draw_vline(x: int, y0: int, y1: int, color: Tuple[int, int, int], thickness: int) -> None:
            x0 = max(0, x - thickness // 2)
            x1 = min(W_px, x + (thickness - thickness // 2))
            y0c = max(0, min(y0, y1))
            y1c = min(H_px, max(y0, y1))
            img[y0c:y1c, x0:x1] = color

        def draw_circle(cx: float, cy: float, radius: float, color: Tuple[int, int, int], fill: bool) -> None:
            # Bounding box
            x0 = int(max(0, np.floor(cx - radius)))
            x1 = int(min(W_px - 1, np.ceil(cx + radius)))
            y0 = int(max(0, np.floor(cy - radius)))
            y1 = int(min(H_px - 1, np.ceil(cy + radius)))
            yy, xx = np.ogrid[y0:y1 + 1, x0:x1 + 1]
            mask = (xx - cx) ** 2 + (yy - cy) ** 2 <= radius ** 2
            if fill:
                img[y0:y1 + 1, x0:x1 + 1][mask] = color
            else:
                # outline 1px
                inner = (xx - cx) ** 2 + (yy - cy) ** 2 <= (radius - 1) ** 2
                ring = np.logical_and(mask, np.logical_not(inner))
                img[y0:y1 + 1, x0:x1 + 1][ring] = color

        def draw_star(cx: float, cy: float, arm_len: float, color: Tuple[int, int, int], thickness: int) -> None:
            # Draw + arms
            draw_hline(int(cy), int(cx - arm_len), int(cx + arm_len), color, thickness)
            draw_vline(int(cx), int(cy - arm_len), int(cy + arm_len), color, thickness)
            # Draw x arms (diagonals) by sampling small line thickness via plotting short lines of squares
            # Approximate diagonals by drawing small rectangles along the diagonal
            steps = int(arm_len)
            for s in range(-steps, steps + 1):
                x = int(cx + s)
                y1 = int(cy + s)
                y2 = int(cy - s)
                y0a = max(0, y1 - thickness // 2)
                y1a = min(H_px, y1 + (thickness - thickness // 2))
                x0a = max(0, x - thickness // 2)
                x1a = min(W_px, x + (thickness - thickness // 2))
                img[y0a:y1a, x0a:x1a] = color
                y0b = max(0, y2 - thickness // 2)
                y1b = min(H_px, y2 + (thickness - thickness // 2))
                img[y0b:y1b, x0a:x1a] = color

        # 1) Draw faint grid lines
        with profile("env_rgb_draw_grid", track_memory=True):
            for r in range(H + 1):
                y = int(r * cell_size)
                draw_hline(y, 0, W_px, grid_color, grid_th)
            for c in range(W + 1):
                x = int(c * cell_size)
                draw_vline(x, 0, H_px, grid_color, grid_th)

        # 2) Draw walls as thicker black lines. h_walls[r,c] between rows r-1 and r over cell column c
        with profile("env_rgb_draw_walls", track_memory=True):
            for r in range(H + 1):
                for c in range(W):
                    if board.h_walls[r, c]:
                        y = int(r * cell_size)
                        x0 = int(c * cell_size)
                        x1 = int((c + 1) * cell_size)
                        draw_hline(y, x0, x1, wall_color, wall_th)
            for r in range(H):
                for c in range(W + 1):
                    if board.v_walls[r, c]:
                        x = int(c * cell_size)
                        y0 = int(r * cell_size)
                        y1 = int((r + 1) * cell_size)
                        draw_vline(x, y0, y1, wall_color, wall_th)

        # 3) Draw robots as filled circles
        with profile("env_rgb_draw_robots", track_memory=True):
            radius = cell_size * float(circle_r_frac)
            for rid, (rr, cc) in board.robot_positions.items():
                color = robot_colors[rid % len(robot_colors)]
                cy = rr * cell_size + cell_size * 0.5
                cx = cc * cell_size + cell_size * 0.5
                draw_circle(cx, cy, radius, color, circle_fill)

        # 4) Draw target as a star in darker color of target robot
        with profile("env_rgb_draw_target", track_memory=True):
            tr = board.target_robot
            tr_color = robot_colors[tr % len(robot_colors)]
            dark_color = tuple(int(max(0, min(255, target_dark_factor * v))) for v in tr_color)
            gr, gc = board.goal_position
            cy = gr * cell_size + cell_size * 0.5
            cx = gc * cell_size + cell_size * 0.5
            draw_star(cx, cy, arm_len=cell_size * 0.35, color=dark_color, thickness=star_th)

        return img


# Optional helper for registration with gymnasium
def register_env(env_id: str = "RicochetRobots-v0", *, max_episode_steps: Optional[int] = None) -> None:
    """Register this environment with gymnasium so it can be created via gym.make(env_id).

    Note: This env already enforces a time limit via its max_steps argument. If you also set
    max_episode_steps here and wrap with Gym's TimeLimit implicitly via gym.make, you may see
    duplicate truncation behavior. Prefer one source of time limits.
    """
    try:
        from gymnasium.envs.registration import register  # type: ignore
        from gymnasium.error import Error as GymError  # type: ignore
        try:
            kwargs = {}
            if max_episode_steps is not None:
                kwargs["max_episode_steps"] = int(max_episode_steps)
            register(
                id=env_id,
                entry_point="env.ricochet_env:RicochetRobotsEnv",
                **kwargs,
            )
        except GymError as e:  # pragma: no cover - depends on gym version behavior
            # Swallow duplicate registration errors; re-raise others
            if "already registered" in str(e).lower():
                return
            raise
    except (ModuleNotFoundError, ImportError):
        # Silently ignore if gymnasium not available
        pass

```

```python
from __future__ import annotations

import torch
import torch.nn as nn
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
from gymnasium.spaces import Box


class ConvLSTMCell(nn.Module):
    """ConvLSTM cell with tanh output gate variant (per DRC spec)."""

    def __init__(self, input_channels: int, hidden_channels: int, kernel_size: int = 3, padding: int = 1):
        super().__init__()
        self.input_channels = input_channels
        self.hidden_channels = hidden_channels
        self.kernel_size = kernel_size
        self.padding = padding

        # Fused conv over [X, h_prev] → 4C (i, f, g, o)
        self.conv = nn.Conv2d(
            input_channels + hidden_channels,
            4 * hidden_channels,
            kernel_size=kernel_size,
            padding=padding,
            bias=True,
        )

        # Forget gate bias += 1.0
        with torch.no_grad():
            # bias layout: [i, f, g, o] chunks
            if self.conv.bias is not None:
                C = hidden_channels
                self.conv.bias[C:2 * C].add_(1.0)

    def forward(self, input_tensor: torch.Tensor, hidden_state: tuple[torch.Tensor, torch.Tensor]) -> tuple[torch.Tensor, torch.Tensor]:
        h_prev, c_prev = hidden_state
        z = torch.cat([input_tensor, h_prev], dim=1)
        gates = self.conv(z)
        i_bar, f_bar, g_bar, o_bar = torch.chunk(gates, 4, dim=1)

        i = torch.sigmoid(i_bar)
        f = torch.sigmoid(f_bar)
        g = torch.tanh(g_bar)
        # Nonstandard: tanh for output gate activation
        o = torch.tanh(o_bar)

        c = f * c_prev + i * g
        h = o * torch.tanh(c)
        return h, c


class DRCStack(nn.Module):
    """Deep Repeating ConvLSTM stack with pool-and-inject and boundary channel.

    Implements L layers repeated for R ticks per forward pass.
    """

    def __init__(
        self,
        encoded_channels: int,
        hidden_channels: int,
        num_layers: int = 3,
        repeats_per_step: int = 3,
        kernel_size: int = 3,
        use_boundary_channel: bool = True,
        use_pool_and_inject: bool = True,
    ) -> None:
        super().__init__()
        self.hidden_channels = int(hidden_channels)
        self.num_layers = int(num_layers)
        self.repeats_per_step = int(repeats_per_step)
        self.kernel_size = int(kernel_size)
        self.use_boundary_channel = bool(use_boundary_channel)
        self.use_pool_and_inject = bool(use_pool_and_inject)

        self.boundary_cache: dict[tuple[int, int, torch.dtype, torch.device], torch.Tensor] = {}

        # Per-layer pool-and-inject 1x1 conv: 2C -> C
        if self.use_pool_and_inject:
            self.pi_layers = nn.ModuleList([
                nn.Conv2d(2 * hidden_channels, hidden_channels, kernel_size=1, bias=True)
                for _ in range(self.num_layers)
            ])
        else:
            self.pi_layers = nn.ModuleList()

        # Build ConvLSTM cells per layer with correct input channels
        self.cells = nn.ModuleList()
        for layer_index in range(self.num_layers):
            in_ch = encoded_channels + hidden_channels  # E_t + PI
            if self.use_boundary_channel:
                in_ch += 1  # boundary
            if layer_index > 0:
                in_ch += hidden_channels  # h^{l-1}
            self.cells.append(
                ConvLSTMCell(in_ch, hidden_channels, kernel_size=self.kernel_size, padding=self.kernel_size // 2)
            )

    def _boundary_channel(self, batch: int, H: int, W: int, device: torch.device, dtype: torch.dtype) -> torch.Tensor:
        key = (H, W, dtype, device)
        b = self.boundary_cache.get(key)
        if b is None:
            t = torch.zeros(1, 1, H, W, device=device, dtype=dtype)
            t[:, :, 0, :] = 1.0
            t[:, :, H - 1, :] = 1.0
            t[:, :, :, 0] = 1.0
            t[:, :, :, W - 1] = 1.0
            self.boundary_cache[key] = t
            b = t
        return b.expand(batch, -1, -1, -1)

    def _pool_and_inject(self, h_prev: torch.Tensor, layer_index: int) -> torch.Tensor:
        if not self.use_pool_and_inject:
            return torch.zeros_like(h_prev)
        # Global mean + max pool → concat along channel → 1x1 conv → broadcast
        B, C, H, W = h_prev.shape
        mean_pool = torch.mean(h_prev, dim=(2, 3), keepdim=True)
        max_pool = torch.amax(h_prev, dim=(2, 3), keepdim=True)
        concat = torch.cat([mean_pool, max_pool], dim=1)  # [B, 2C, 1, 1]
        pi = self.pi_layers[layer_index](concat)  # [B, C, 1, 1]
        return pi.expand(B, C, H, W)

    def init_state(self, batch: int, H: int, W: int, device: torch.device, dtype: torch.dtype):
        h = [torch.zeros(batch, self.hidden_channels, H, W, device=device, dtype=dtype) for _ in range(self.num_layers)]
        c = [torch.zeros(batch, self.hidden_channels, H, W, device=device, dtype=dtype) for _ in range(self.num_layers)]
        return h, c

    def forward(
        self,
        E_t: torch.Tensor,
        state: tuple[list[torch.Tensor], list[torch.Tensor]] | None,
        repeats_override: int | None = None,
    ) -> tuple[torch.Tensor, tuple[list[torch.Tensor], list[torch.Tensor]]]:
        B, _Ce, H, W = E_t.shape
        device = E_t.device
        dtype = E_t.dtype
        R = self.repeats_per_step if repeats_override is None else int(repeats_override)

        if state is None:
            h_list, c_list = self.init_state(B, H, W, device, dtype)
        else:
            h_list, c_list = state

        boundary = self._boundary_channel(B, H, W, device, dtype) if self.use_boundary_channel else None

        for _tick in range(R):
            new_h_list: list[torch.Tensor] = []
            new_c_list: list[torch.Tensor] = []
            prev_layer_h: torch.Tensor | None = None
            for layer_index in range(self.num_layers):
                h_prev = h_list[layer_index]
                c_prev = c_list[layer_index]
                pi = self._pool_and_inject(h_prev, layer_index)
                inputs = [E_t, pi]
                if layer_index > 0 and prev_layer_h is not None:
                    inputs.append(prev_layer_h)
                if boundary is not None:
                    inputs.append(boundary)
                X = torch.cat(inputs, dim=1)
                h_cur, c_cur = self.cells[layer_index](X, (h_prev, c_prev))
                new_h_list.append(h_cur)
                new_c_list.append(c_cur)
                prev_layer_h = h_cur
            h_list, c_list = new_h_list, new_c_list

        # return top-layer hidden
        h_top = h_list[-1]
        return h_top, (h_list, c_list)


class ConvLSTMFeaturesExtractor(BaseFeaturesExtractor):
    """DRC-aligned feature extractor (encoder → DRCStack → projection).

    Matches the repository's policy/training API while implementing DRC wiring.
    """

    def __init__(
        self,
        observation_space: Box,
        features_dim: int = 128,
        conv_channels: int = 32,
        lstm_channels: int = 32,
        num_lstm_layers: int = 3,
        num_repeats: int = 3,
        use_pool_and_inject: bool = True,
        use_skip_connections: bool = False,  # kept for API compatibility
    ):
        super().__init__(observation_space, features_dim)
        assert len(observation_space.shape) == 3, "Expected image observation (C,H,W)"
        in_channels = int(observation_space.shape[0])

        self.encoder_channels = int(conv_channels)
        self.hidden_channels = int(lstm_channels)
        self.num_layers = int(num_lstm_layers)
        self.num_repeats = int(num_repeats)
        self.use_pool_and_inject = bool(use_pool_and_inject)
        self.use_boundary = True
        # Keep for API compatibility
        self._use_skip_connections = bool(use_skip_connections)

        # Two convs then spatial downsample to reduce HxW before DRC
        # Halving spatial size cuts DRC memory/compute by ~4x
        self.encoder = nn.Sequential(
            nn.Conv2d(in_channels, self.encoder_channels, kernel_size=3, padding=1, bias=True),
            nn.Conv2d(self.encoder_channels, self.encoder_channels, kernel_size=3, padding=1, bias=True),
            nn.AvgPool2d(kernel_size=2, stride=2),
        )

        # DRC core
        self.drc = DRCStack(
            encoded_channels=self.encoder_channels,
            hidden_channels=self.hidden_channels,
            num_layers=self.num_layers,
            repeats_per_step=self.num_repeats,
            kernel_size=3,
            use_boundary_channel=True,
            use_pool_and_inject=self.use_pool_and_inject,
        )

        # Projection: flatten → 256 → ReLU → features_dim
        self.proj1 = nn.Linear(self.hidden_channels * 1, 256)
        self.proj_act = nn.ReLU(inplace=True)
        self.proj2 = nn.Linear(256, features_dim)

        self._features_dim = features_dim
        # Expose an attribute named 'convlstm' so the recurrent policy recognizes
        # this extractor as recurrent and will pass/receive hidden states.
        # Keep parity with previous implementation that had a 'convlstm' module.
        self.convlstm = self.drc

    def forward(self, observations: torch.Tensor, hidden_states: list[tuple[torch.Tensor, torch.Tensor]] | None = None) -> tuple[torch.Tensor, list[tuple[torch.Tensor, torch.Tensor]]]:
        # Import profiling lazily
        try:
            from profiling import profile
        except ImportError:
            def profile(_name, _track_memory=True):
                from contextlib import nullcontext
                return nullcontext()

        with profile("convlstm_forward_pass", track_memory=True):
            x = observations
            device_type = x.device.type
            use_amp = device_type in ("cuda", "mps")
            try:
                autocast_ctx = torch.autocast(device_type=device_type, dtype=torch.float16) if use_amp else torch.cpu.amp.autocast(enabled=False)
            except Exception:
                # Fallback if autocast not supported on backend
                class _NullCtx:
                    def __enter__(self):
                        return None
                    def __exit__(self, exc_type, exc, tb):
                        return False
                autocast_ctx = _NullCtx()

            with autocast_ctx:
                # Encode observation
                with profile("convlstm_conv_encoder", track_memory=True):
                    E_t = self.encoder(x)

                # Reformat provided hidden_states to (h_list, c_list)
                state_tuple: tuple[list[torch.Tensor], list[torch.Tensor]] | None = None
                if hidden_states is not None and len(hidden_states) > 0:
                    h_list = [hc[0] for hc in hidden_states]
                    c_list = [hc[1] for hc in hidden_states]
                    state_tuple = (h_list, c_list)

                # Run DRC stack
                with profile("convlstm_drc_stack", track_memory=True):
                    h_top, (h_list_new, c_list_new) = self.drc(E_t, state_tuple, repeats_override=None)

                # Global average pooling over H,W
                with profile("convlstm_global_pooling", track_memory=True):
                    pooled = h_top.mean(dim=(-2, -1))  # [B, C]

                # Projection head
                with profile("convlstm_projection", track_memory=True):
                    z = self.proj1(pooled)
                    z = self.proj_act(z)
                    z = self.proj2(z)

            # Ensure output is float32 for SB3 compatibility
            z = z.float()
            # Pack new hidden states as list of (h, c)
            new_hidden_states = [(h_list_new[i], c_list_new[i]) for i in range(len(h_list_new))]
            return z, new_hidden_states

```

I ran a short, profiled rgb_image training and it OOM’d on MPS due to large ConvLSTM spatial sizes and 128×128 RGB observations. I implemented three fixes and re-ran profiling; training now runs without OOM and is notably faster.

- Root causes:
  - ConvLSTM operated at full 128×128, causing high memory/compute.
  - RGB obs fixed size at 128×128 increased per-step cost.
  - No mixed precision on MPS; convs ran in fp32.

- Changes made:
  - ConvLSTM encoder now downsamples with AvgPool2d(stride=2), cutting H×W by 4× before the DRC stack. File: `models/convlstm.py`.
  - Reduced fixed RGB observation size from 128 to 96. File: `env/ricochet_env.py` (both the observation_space and generator path use 96).
  - Enabled autocast mixed precision in the ConvLSTM feature extractor for cuda/mps and cast output back to float32. File: `models/convlstm.py`.

- Results from profiling (2000 steps, 2 envs, MPS):
  - No more MPS OOM.
  - FPS improved from ~22 to ~44 at the start; overall loop maintains ~14–16 FPS later as PPO updates kick in.
  - Top costs are now model-side: “convlstm_forward_pass” dominates, but env rgb generation is small (~2 s of 158 s total). This indicates env-side rgb rendering isn’t the main bottleneck now; the model compute is.

Recommended next optimizations (optional, depending on your target throughput):
- Reduce `--lstm-channels` and/or `--lstm-layers` or `--lstm-repeats` in `train_agent.py` flags for rgb_image runs (e.g., `--lstm-channels 32`, `--lstm-layers 1–2`, `--lstm-repeats 1`).
- Consider smaller obs size (e.g., 80) if acceptable; adjust `FIXED_PIXEL_SIZE` in `env/ricochet_env.py`.
- If stability allows, increase vectorization `--n-envs` modestly; with downsample + AMP it should scale better.
- For MPS, keep `PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0` when doing heavier runs; you can export it in your shell.

Status: I completed the downsampling, resolution reduction, and mixed precision edits, and verified the improvements via a profiled run.

