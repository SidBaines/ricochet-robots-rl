# Review feedback for research proposal step 1.3
_Exported on 12/09/2025 at 10:54:45 BST from Cursor (1.4.5)_

---

**User**

You are a language model, working as part of a team to implement a research proposal. Please take the time to read the ResearchPlan.md.

You have been tasked with reviewing the work of a colleague who has been tasked with implementing 'step 1.3' of the plan detailed in ResearchPlan.md (note that another colleague has already checked and confirmed that the code is good for the previous steps). You are not to change any code, but instead to review the work and give a list of feedback, ordered roughly from highest importance to lowest. Please go ahead and get started. Be as critical as you like.

---

**Cursor**

I'll scan the environment and tests to review how Step 1.3 (Gym/Gymnasium integration) was implemented, focusing on API correctness, spaces, seeding, determinism, and compatibility.

I’ve reviewed the Step 1.3 Gym/Gymnasium integration in `env/ricochet_env.py`, plus related tests. I’ll focus on API correctness, determinism/seeding, spaces, rendering, and downstream library compatibility.

- Bold = priority.

- **Gymnasium render API compliance**: The class advertises `metadata = {"render_modes": ["ascii"], "render_fps": 4}` but does not accept a `render_mode` argument in `__init__`, nor store `self.render_mode`, and `render()` doesn’t branch on mode or return `None` when not matching the configured mode. The typical Gymnasium pattern is `__init__(..., render_mode: Optional[str] = None)` and `render()` behavior dependent on that. As-is, integration with wrappers or tools expecting the standard pattern may be brittle.

- **Seeding protocol not following Gymnasium conventions**: `reset(seed=...)` swaps in a new `np.random.default_rng(seed)`, but it doesn’t call `super().reset(seed)` nor expose `self.np_random`. Many libraries (including SB3) expect Gym/Gymnasium’s `np_random` seeding convention to ensure uniform determinism and wrapper compatibility. Consider adopting `self.np_random, seed = gymnasium.utils.seeding.np_random(seed)` and returning the final seed in `info` for reproducibility.

- **Missing `close()` and optional `seed()` methods**: While not strictly required, many environments provide `close()` (even as a no-op) and, for legacy compatibility, a `seed()` method. Some tooling calls these defensively.

- **Registration not provided**: Step 1.3 mentions registration; there’s no module-level registration via `gymnasium.envs.registration.register` or an entry point for `gym.make("RicochetRobots-v0")`. Adding a small registration helper or documenting how to instantiate the env directly would improve plug-and-play use with RL libs.

- **Truncation/termination signaling**: The logic sets `terminated` on goal and `truncated` on step limit; that matches Gymnasium 0.26+ five-return API. However, you don’t surface a standardized time-limit key (e.g., `"TimeLimit.truncated"`) in `info`. If users wrap with `TimeLimit`, that wrapper usually injects the key, but here the env is handling truncation itself. Consider aligning with wrapper expectations or documenting that truncation is handled internally.

- **Info consistency and evaluation hooks**: You set `info["success"] = True` on goal. That’s helpful. Consider also exposing a stable success metric in every step’s `info` (e.g., `info["is_success"] = bool`) for callbacks that compute success rate without needing to guard for absent keys. Similarly, including the `seed` used for this episode in `info` would help exact reproduction.

- **Observation-space bounds and semantics**:
  - Image mode uses `[0,1]` with float32 and correct shapes; good.
  - Symbolic mode sets `low=-inf, high=inf`. That’s valid but suboptimal for agents that rely on space bounds for normalization/initialization. Tighter, known bounds (e.g., `[0, H-1]`/`[0, W-1]` for positions, one-hot in `[0,1]`) improve downstream behavior.

- **Performance: recomputing static wall channels each step**: `_board_to_image_obs` iterates every cell and recomputes the four wall channels each step, even though walls don’t change. You could precompute and cache the wall tensors at reset for a given layout (and reuse with `channels_first` transpose), then only rewrite dynamic channels (goal, target marker, robots) on each step. This will matter for larger boards and vectorized rollout.

- **Action validation**: `_decode_action` guards invalid indices and noop misuse; good. In `step()`, you don’t validate action range before the noop branch. It’s fine since action space restricts sampling, but a quick range check up-front would fail fast on user-provided bad actions and give cleaner error messages.

- **Determinism details**: With `fixed_layout`, resets are deterministic. With random generation, using `self._rng` is good. Because solver use is conditional in `ensure_solvable`, reproducibility depends on solver determinism (which seems deterministic given consistent expansion order). Consider documenting that determinism holds given a fixed seed and the current solver settings.

- **Render return type and ergonomics**: `render()` returns a string. Gymnasium typically returns a frame or `None` depending on mode. Returning a string is fine for `'ascii'`, but many tools expect `np.ndarray` for “rgb_array”. If you plan future modes, keep the interface consistent, and consider a `render_mode="ascii"` in `__init__` so the method can validate mode and return the right type.

- **Spaces when Gymnasium missing**: The minimal `_SpacesDummy` helps type usage and local tests pass even without Gymnasium installed. That’s practical, but be aware that users relying on Gymnasium wrappers won’t benefit from them in that configuration. It’s OK as a fallback; document it in the README.

- **Channel semantics clarity**: In image observations, channel 5 marks the current position of the target robot, and robot channels start at 6 by robot id. That’s sensible. Consider documenting this mapping via a public attribute or docstring so consumers can parse observations without reading code.

- **Solver metadata in reset info**: When `ensure_solvable=True`, you include `optimal_length` and `solver_limits`. Good. If you plan to filter levels by difficulty later (curriculum), consider also including the solution action list length only (not the path) and a flag that solvability was verified vs. heuristic cutoff.

- **Type hints and docstrings for public methods**: The env is easy to read, but short docstrings on `reset`, `step`, and `render` describing returns and info keys would help external users.

- **Minor: naming and alignment with Gymnasium docs**: Class name and API are fine. If you later add wrappers or vectorization, consider ensuring `observation_space.dtype` aligns with actual returned dtype across both modes (it does today).

Overall, the implementation is close to spec-compliant and works well with the tests. The highest-impact fixes for broader compatibility are addressing the render API shape (`render_mode`) and adopting the standard seeding protocol (`np_random` via `super().reset(seed)`), plus optional registration for `gym.make`.

- I’ve finished the review and will stop here.

